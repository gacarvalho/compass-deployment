---
version: '3.8'

x-logging: &default-logging
  driver: "json-file"
  options:
    max-file: "5"
    max-size: "10m"

x-healthcheck: &default-healthcheck
  timeout: 45s
  interval: 10s
  retries: 10

services:
  # Serviço do Spark Master
  infra-spark-master:
    image: iamgacarvalho/spark-master-data-in-compass:0.0.3
    container_name: spark-master
    logging:
      <<: *default-logging
    networks:
      hadoop_network:
        aliases:
          - spark-master
    ports:
      - "8084:8082"
      - "7077:7077"
    volumes:
      - ../../mnt/spark/apps:/opt/spark-apps
      - ../../mnt/spark/data:/opt/spark-data
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "8082"]
      <<: *default-healthcheck
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '1.0'
        reservations:
          memory: 2G
          cpus: '0.5'

  # Serviço do Spark Worker
  infra-spark-worker:
    image: iamgacarvalho/spark-worker-data-in-compass:0.0.3
    container_name: spark-worker
    logging:
      <<: *default-logging
    networks:
      hadoop_network:
        aliases:
          - spark-worker
    ports:
      - "8070-8081:8081"
    environment:
      - WORKER_PORT=8081
    volumes:
      - ../../mnt/spark/apps:/opt/spark-apps
      - ../../mnt/spark/data:/opt/spark-data
      - ../../mnt/spark/worker-logs:/opt/spark/logs
    deploy:
      replicas: 2

volumes:
  infra-spark-master:
  infra-spark-worker:
  infra-spark-worker-logs:

networks:
  hadoop_network:
    external: true
    driver: overlay
