üß≠ ‚ô®Ô∏è COMPASS
---

<p align="left">
  <img src="https://img.shields.io/badge/projeto-Compass-blue?style=flat-square" alt="Projeto">
  <img src="https://img.shields.io/badge/vers√£o-1.0.0-blue?style=flat-square" alt="Vers√£o">
  <img src="https://img.shields.io/badge/status-deployed-green?style=flat-square" alt="Status">
  <img src="https://img.shields.io/badge/autor-Gabriel_Carvalho-lightgrey?style=flat-square" alt="Autor">
</p>

O reposit√≥rio **compass-deployment** √© uma solu√ß√£o desenvolvida no contexto do programa Data Master, promovido pela F1rst Tecnologia, com o objetivo de disponibilizar uma plataforma robusta e escal√°vel para captura, processamento e an√°lise de feedbacks de clientes.


![<data-master-compass>](https://github.com/gacarvalho/repo-spark-delta-iceberg/blob/main/header.png?raw=true)

Este documento apresenta a vis√£o geral do projeto, abrangendo desde os objetivos iniciais at√© a descri√ß√£o t√©cnica da arquitetura, fluxos funcionais, tecnologias empregadas, instru√ß√µes para execu√ß√£o e considera√ß√µes finais. A proposta √© oferecer um panorama completo sobre o funcionamento do Compass como produto de analytics voltado √† experi√™ncia do cliente.

- [1. Objetivo do Projeto](#1-objetivo-do-projeto)
  * [1.1 O Projeto Compass](#11-o-projeto-compass)
- [2. Arquitetura da Solu√ß√£o](#2-arquitetura-da-solu√ß√£o)
- [3. Vis√£o Geral da Arquitetura T√©cnica](#3-vis√£o-geral-da-arquitetura-t√©cnica-do-case)
  * [3.1 Descri√ß√£o do Fluxo de Dados](#31-descri√ß√£o-do-fluxo-de-dados)
    + [3.1.1 Fonte (datasource) de Dados](#311-fonte-datasource-de-dados)
    + [3.1.2 Camada de Processamento](#312-camada-de-processamento)
    + [3.1.3 Camada de Armazenamento](#313-camada-de-armazenamento)
    + [3.1.4 Camada de Visualiza√ß√£o e Telemetria (observabilidade)](#314-camada-de-visualiza√ß√£o-e-telemetria-observabilidade)
  * [3.2 Aspectos T√©cnicos do Projeto Compass](#32-aspectos-t√©cnicos-do-projeto-compass)
    + [3.2.1 Tecnologias Utilizadas](#321-tecnologias-utilizadas)
    + [3.2.2 Caracteristicas da Execu√ß√£o do Projeto](#322-caracteristicas-da-execu√ß√£o-do-projeto)
    + [3.2.2.1 Infraestrutura do Projeto Compass](#3221-infraestrutura-do-projeto-compass)
    + [3.2.2.2 Aplica√ß√µes do Projeto Compass](#3222-aplica√ß√µes-do-projeto-compass)
    + [3.2.2.3  Pipeline do Projeto Compass](#3223-pipeline-do-projeto-compass)
- [4. Fluxo Funcional e Jornada do Cliente](#4-fluxo-funcional-e-jornada-do-cliente)
- [5. Compass como produto analytics Santander](#5-compass-como-produto-analytics-santander)
  * [5.1 Regras de Neg√≥cio](#51-regras-de-neg√≥cio)
  * [5.2 Dicion√°rio de Dados](#52-dicion√°rio-de-dados)
  * [5.3 Produtos Compass](#53-produtos-compass)
- [6. Instru√ß√µes para Configura√ß√£o e Execu√ß√£o do Projeto Compass](#6-instru√ß√µes-para-configura√ß√£o-e-execu√ß√£o-do-projeto-compass)
  * [6.1 Pr√©-requisitos](#61-pr√©-requisitos)
    * [Requisitos da M√°quina Local](#requisitos-da-m√°quina-local)
    * [Requisitos de Conectividade](#requisitos-de-conectividade)
    * [Portas Necess√°rias (Protocolos TCP)](#portas-necess√°rias-protocolos-tcp)
    * [Ferramentas Necess√°rias](#ferramentas-necess√°rias)
  * [6.2 Passos para Configura√ß√£o e Execu√ß√£o](#62-passos-de-configura√ß√£o-e-execu√ß√£o-do-projeto-compass)
    * [Deployment do Elastic](#deployment-do-elastic)
    * [Deployment do Kibana](#deployment-do-kibana)
    * [Deployment do Airflow](#deployment-do--airflow)
    * [Deployment do MongoDB](#deployment-do-mongo-db)
    * [Deployment do Hadoop](#deployment-do-hadoop)
    * [Deployment do Grafana](#deployment-do-grafana)
    * [Deployment do Metabase](#deployment-do-metabase)
    * [Vis√£o Final](#vis√£o-final)
- [7. Melhorias no Projeto e Considera√ß√µes Finais](#7-melhorias-do-projeto-e-considera√ß√µes-finais)



# 1. Objetivo do Projeto
---

A idealiza√ß√£o deste case surgiu da necessidade de fortalecer o alinhamento entre o time de neg√≥cios e a Engenharia de Dados, com foco na resolu√ß√£o de desafios pr√°ticos relacionados √† jornada do usu√°rio. A iniciativa teve como ponto de partida uma dor claramente identificada: a aus√™ncia de visibilidade aprofundada sobre a forma como os clientes interagem com os produtos e servi√ßos da empresa. Essa limita√ß√£o comprometia a identifica√ß√£o de gargalos, dificultava a compreens√£o do comportamento dos usu√°rios e tornava menos eficiente a prioriza√ß√£o de a√ß√µes de melhoria com base em dados.

Diante desse cen√°rio, estabeleceu-se como objetivo central o desenvolvimento de uma solu√ß√£o capaz de capturar, tratar e estruturar dados de intera√ß√£o dos usu√°rios, de forma a viabilizar an√°lises confi√°veis e acion√°veis para suporte √† tomada de decis√£o. A proposta n√£o se restringiu √† disponibiliza√ß√£o de informa√ß√µes estruturadas para uso interno; buscou-se tamb√©m criar mecanismos que possibilitassem uma leitura mais ampla do mercado, por meio da compara√ß√£o com padr√µes comportamentais de outras empresas do setor.

A arquitetura concebida foi desenhada com foco em flexibilidade e escalabilidade, permitindo sua aplica√ß√£o em diferentes contextos e ampliando o potencial de gera√ß√£o de valor. Al√©m de atender √†s demandas internas por intelig√™ncia sobre a experi√™ncia do cliente, a solu√ß√£o pode ser estendida para identificar tend√™ncias e pontos de aten√ß√£o em players do mesmo segmento, desde que haja disponibilidade de dados compar√°veis. Essa capacidade amplia a perspectiva anal√≠tica da organiza√ß√£o, contribuindo para uma atua√ß√£o mais informada em estrat√©gias de mercado e compara√ß√µes setoriais relevantes.


## 1.1 O Projeto Compass
---

O Projeto **Data Master Compass** √© uma iniciativa de Engenharia de Dados projetada para capturar e analisar feedbacks de clientes sobre produtos e servi√ßos. O nome **Compass** reflete seu prop√≥sito: orientar o time de neg√≥cios na melhoria cont√≠nua de processos e solu√ß√µes, com base em dados reais.

Ao coletar e interpretar avalia√ß√µes dos usu√°rios, o projeto identifica necessidades e oportunidades de aprimoramento, fortalecendo o compromisso da organiza√ß√£o com a satisfa√ß√£o e fideliza√ß√£o de seus clientes. Essa abordagem n√£o s√≥ refina a experi√™ncia do usu√°rio, como tamb√©m contribui para consolidar a marca como refer√™ncia em seu setor de atua√ß√£o.

A solu√ß√£o centraliza as informa√ß√µes em um Data Lake baseado em HDFS, organizando os dados por data de refer√™ncia e segmento de p√∫blico. Isso proporciona insights valiosos para Product Owners, Product Managers e Gerentes de Projetos, permitindo decis√µes baseadas em evid√™ncias e alinhadas √†s necessidades reais dos usu√°rios.



üß≠ **Exemplo Pr√°tico**

Imagine uma equipe desenvolvendo uma nova funcionalidade para um produto digital, como o acesso a extratos detalhados com mais de 90 dias de transa√ß√µes. Sem feedbacks reais dos usu√°rios, as melhorias podem ser baseadas apenas em suposi√ß√µes internas. O Projeto Compass elimina essa incerteza ao fornecer acesso r√°pido e estruturado √†s avalia√ß√µes dos clientes, substituindo pesquisas demoradas e garantindo que as entregas estejam alinhadas com as expectativas reais.

Agora, imagine que uma Institui√ß√£o Financeira deseja lan√ßar um novo canal de investimentos voltado para o p√∫blico jovem. Por ser um produto in√©dito na organiza√ß√£o, √© essencial entender como esse modelo tem sido recebido no mercado. O Projeto Compass viabiliza a an√°lise das principais cr√≠ticas e elogios dos clientes da concorr√™ncia, oferecendo insights estrat√©gicos para um lan√ßamento mais assertivo e competitivo.

Al√©m disso, times respons√°veis por produtos e servi√ßos diversos podem monitorar continuamente a evolu√ß√£o de suas funcionalidades, acompanhando a satisfa√ß√£o dos usu√°rios por segmento e canal, com avalia√ß√µes classificadas, por exemplo, de 1 a 5 estrelas.

Em resumo, o Projeto Compass √© uma iniciativa estrat√©gica que alinha o desenvolvimento de produtos e servi√ßos √†s necessidades reais dos usu√°rios, impulsionando a excel√™ncia operacional e aprimorando a experi√™ncia do cliente.


>[!NOTE]
> üß≠ **Por que o nome "Compass"?**
> O nome Compass (em portugu√™s, b√∫ssola) foi escolhido por representar a principal miss√£o do projeto: guiar decis√µes estrat√©gicas com base em dados confi√°veis.
> Assim como uma b√∫ssola orienta o caminho em meio √† incerteza, o projeto orienta as equipes de produto, tecnologia e neg√≥cios na identifica√ß√£o de problemas, oportunidades e prioridades nos aplicativos, com base na percep√ß√£o real dos usu√°rios.

# 2. Arquitetura da Solu√ß√£o
---

A arquitetura proposta √© baseada em um ambiente **on-premises**, utilizando tecnologias para armazenamento, processamento e visualiza√ß√£o de dados. A solu√ß√£o √© composta por v√°rias camadas, cada uma com um papel espec√≠fico no fluxo de dados.

![<arquitetura-data-master-compass>](https://github.com/gacarvalho/compass-deployment/blob/compass/infra-3.0.0/img/arquitetura.png?raw=true)

Separando a arquitetura do Compass por componentes, √© poss√≠vel entender que √© composta por quatro componentes principais, cada um respons√°vel por uma etapa espec√≠fica do fluxo de dados:

| **Componente**          | **Descri√ß√£o**                                                                 | **Vers√£o**  |
|-------------------------|-------------------------------------------------------------------------------|-------------|
| **Armazenamento**             | **MONGODB:** Avalia√ß√µes internas de usu√°rios, recebidas via API e canais de feedback. <br> - **ELASTICSEARCH:** M√©tricas aplicacionais armazenadas para an√°lise de performance. <br> - **HDFS:** Utilizado para reten√ß√£o de longo prazo (at√© cinco anos), com suporte a grandes volumes de dados via Apache Hadoop. | MongoDB: 7 <br> Elasticsearch: 8.16.1 <br> Apache Hadoop: 3.1.1 |
| **Processamento**          | Processamento distribu√≠do de dados com Apache Spark, possibilitando an√°lises em larga escala. | Apache Spark 3.5.0 |
| **Visualiza√ß√£o**       | Visualiza√ß√£o de m√©tricas:<br> - T√©cnicas: Grafana.<br> - Funcionais: Metabase. | Grafana, Metabase |
| **Orquestra√ß√£o**        | Orquestra√ß√£o dos fluxos de dados realizada com Apache Airflow.               | Apache Airflow 2.7.2 |


> [!NOTE]
> O reposit√≥rio com a infraestrutura do Hadoop utilizada neste case est√° dispon√≠vel em: [infra-data-master-compass no GitHub](https://github.com/gacarvalho/infra-data-master-compass).Para obter acesso, entre em contato diretamente pelo [LinkedIn](https://www.linkedin.com/in/iamgacarvalho/)




# 3. Vis√£o Geral da Arquitetura T√©cnica do Case
---

Como base da arquitetura, o projeto Compass utiliza alguns recursos para realizar o processo desde a extra√ß√£o dos dados at√© a disponibiliza√ß√£o. O ambiente onde o projeto est√° em execu√ß√£o √© on-premisses e foram divididas em algumas camadas, como:

- **Arquitetura Batch**: Servi√ßos e produtos finais referente a arquitetura de big data on-premisse.
  
| **Arquitetura** | **Camada**                   | **Descri√ß√£o**                                                                                   | **P√∫blico alvo**        |
|-----------------|------------------------------|-------------------------------------------------------------------------------------------------|-------------------------|
| Batch           | Camada de Observabilidade     | Servi√ßos respons√°veis por coletar e monitorar dados de telemetria, fornecendo visibilidade sobre o desempenho e a integridade dos recursos das aplica√ß√µes. | Time Dev, Sustenta√ß√£o   |
| Batch           | Camada de Business Service    | Servi√ßos focados em an√°lise e intelig√™ncia de neg√≥cios, fornecendo insights estrat√©gicos para decis√µes organizacionais por meio de BI e relat√≥rios anal√≠ticos. | Plataforma, Ger√™ncia    |
| Batch           | Camada de Aplica√ß√µes          | Aplica√ß√µes desenvolvidas em PySpark (Python), com artefatos implementados em containers, oferecendo uma abordagem escal√°vel e modular para processamento de dados. | Time Dev                |



## 3.1 Descri√ß√£o do Fluxo de Dados
---

Como parte da arquitetura, vamos ter 3 divis√µes bases, como: Extra√ß√£o de dados, Transforma√ß√£o de Dados e Carga de Dados.

> [!IMPORTANT]
> O case foi estruturado para ser aplicado em qualquer organiza√ß√£o que deseje transformar dados em decis√µes mais estrat√©gicas e orientadas por dados. A proposta √© automatizar a coleta, organiza√ß√£o e an√°lise de informa√ß√µes, proporcionando uma compreens√£o mais profunda das necessidades dos clientes e das tend√™ncias observadas no mercado. A solu√ß√£o √© flex√≠vel e escal√°vel, podendo ser adaptada a diferentes setores e expandida para diversas frentes estrat√©gicas e operacionais.
> Embora a institui√ß√£o Santander tenha sido utilizada como exemplo aplicado, o modelo √© totalmente replic√°vel em outros contextos. Qualquer organiza√ß√£o interessada em conhecer melhor seus usu√°rios, acompanhar a concorr√™ncia e embasar decis√µes com dados reais pode se beneficiar diretamente dessa abordagem.



### 3.1.1 Fonte (Datasource) de Dados

As cole√ß√µes armazenadas em banco de dados representam os dados internos da organiza√ß√£o, utilizados para registrar feedbacks capturados por diferentes canais e que refletem a jornada dos usu√°rios dentro dos aplicativos. Cada conjunto de dados √© alimentado de acordo com a origem da intera√ß√£o.

> [!NOTE]
> Como n√£o dispomos de uma base de dados real de clientes para este case, foi desenvolvido um pipeline no Airflow, denominado dag_e_pipeline_compass_reviews, com o objetivo de inserir dados simulados na cole√ß√£o do MongoDB. Essa abordagem visa criar um cen√°rio mais pr√≥ximo da realidade, permitindo que a simula√ß√£o de dados de intera√ß√£o seja alimentada nos canais, tornando o case mais representativo de um ambiente de produ√ß√£o.

- **Base Interna (MongoDB)**:
    - `Collections` `Aplicativo de Cart√µes`: Aplica√ß√£o m√≥vel da institui√ß√£o utilizada pelos clientes.
    - `Collections` `Aplicativo de Conta`: Aplica√ß√£o m√≥vel da institui√ß√£o para opera√ß√µes banc√°rias.
    - `Collections` `Aplicativo de Conta Internacional`: Aplica√ß√£o m√≥vel de conta em d√≥lar da institui√ß√£o.
    - `Collections` `Outros Aplicativos`: Diversos aplicativos que fornecem dados de avalia√ß√µes - *quando falamos em outros aplicativos, √© uma collections no MongoDB para cada aplicativo*!

As APIs externas s√£o respons√°veis por capturar informa√ß√µes de fontes que est√£o fora do ecossistema da organiza√ß√£o. No projeto, foram utilizadas duas solu√ß√µes distintas para acessar dados p√∫blicos de avalia√ß√µes de usu√°rios em plataformas digitais.

A SERPAPI, uma solu√ß√£o comercial, foi adotada como alternativa ao acesso direto ao Google Play, j√° que esse acesso √© restrito apenas ao propriet√°rio do aplicativo na plataforma. Para obter essas informa√ß√µes diretamente, seria necess√°rio possuir a aplica√ß√£o cadastrada na Google Play Store e contar com uma conta de servi√ßo com permiss√µes de desenvolvedor. Diante dessa limita√ß√£o, a SERPAPI se mostrou uma alternativa vi√°vel e eficaz para a coleta das avalia√ß√µes dispon√≠veis publicamente.

Por outro lado, a API do iTunes √© de acesso gratuito, por√©m sua utiliza√ß√£o pode exigir configura√ß√µes espec√≠ficas na infraestrutura da organiza√ß√£o, como libera√ß√£o de firewall e apoio de equipes respons√°veis pelo consumo de dados externos. Al√©m disso, essa API possui uma limita√ß√£o quanto √† quantidade de avalia√ß√µes recuper√°veis ‚Äî permitindo o acesso apenas √†s 500 mais recentes.

- **Externo da Institui√ß√£o**:
    - `SerpApi`: API utilizada para coletar avalia√ß√µes do **Google Play** `(opcional)`.
    - `itunes.apple.com`: API utilizada para coletar avalia√ß√µes da **Apple Store**.

### 3.1.2 Camada de Processamento 

A Camada de Processamento desempenha um papel essencial no projeto Compass, sendo respons√°vel por tratar, transformar e estruturar os dados de forma eficiente. Essa camada √© composta por tr√™s est√°gios distintos, implementados com Apache Spark, que organizam o fluxo de dados desde a ingest√£o inicial at√© a gera√ß√£o de insights enriquecidos.

- **Processamento**:
    - **`Spark Bronze ‚Äì Ingest√£o`**: Realiza a ingest√£o dos dados brutos e aplica os primeiros tratamentos para padroniza√ß√£o e valida√ß√£o inicial.

    - **`Spark Silver ‚Äì Processamento Intermedi√°rio`**: Armazena e processa dados com hist√≥rico, aplicando transforma√ß√µes de limpeza, padroniza√ß√£o e qualidade que preparam as informa√ß√µes para an√°lises mais avan√ßadas.

    - **`Spark Gold ‚Äì Enriquecimento e Agrega√ß√£o`**: Respons√°vel por agregar e enriquecer os dados tratados, gerando vis√µes anal√≠ticas valiosas para apoio √† tomada de decis√£o.



### 3.1.3 Camada de Armazenamento

A Camada de Armazenamento √© respons√°vel por manter os dados persistidos ao longo de todo o fluxo do projeto Compass, desde sua ingest√£o bruta at√© o consumo final. Essa camada contempla diferentes tecnologias, cada uma com prop√≥sito espec√≠fico, garantindo flexibilidade, desempenho e organiza√ß√£o dos dados em seus respectivos est√°gios de processamento.

Os principais sistemas utilizados incluem:

- **MongoDB**: Armazena dados funcionais estruturados, utilizados principalmente para an√°lises e relat√≥rios - Vis√£o Silver e Gold sempre da √∫ltima atualiza√ß√£o.
- **Hadoop (HDFS)**: Respons√°vel por armazenar dados em diferentes n√≠veis (Bronze, Silver, Gold e Quality), de forma distribu√≠da e organizada por data - Vis√£o hist√≥rica.
- **Elasticsearch**: Voltado √† indexa√ß√£o e consulta de dados t√©cnicos e de monitoramento, permitindo an√°lises r√°pidas e detalhadas de m√©tricas e falhas.

A seguir, s√£o apresentados os detalhes sobre cada tecnologia, seus diret√≥rios, cole√ß√µes e √≠ndices, bem como os respons√°veis por alimentar essas estruturas.

- **Armazenamento**:
  - `MongoDB`: Banco de dados NoSQL para armazenamento estruturado para dados funcionais.
    <details>
      <summary>Informa√ß√µes Detalhada do Armazenamento: MONGODB</summary>
      
      ---
      
      Abaixo est√£o as cole√ß√µes presentes no MongoDB, com informa√ß√µes sobre os dados armazenados e os processos respons√°veis pela alimenta√ß√£o de cada uma delas:
  
      | **Collection**                          | **Descri√ß√£o**                                          | **Quem Alimenta**                              |
      |-----------------------------------------|--------------------------------------------------------|------------------------------------------------|
      | dt_d_view_gold_agg_compass              | Camada de agrega√ß√£o de dados hist√≥ricos e enriquecidos  |  <ul><li>Processos de agrega√ß√£o e an√°lise do Compass</li> <li>  DAG: dag_d_pipeline_compass_reviews. </li> <li> JOB: GOLD_APP_GOLD_AGGREGATE_REVIEWS_SANTANDER    </li> |
      | dt_d_view_silver_historical_compass     | Camada intermedi√°ria de dados hist√≥ricos               | <ul><li> Processos de pr√©-processamento e agrega√ß√£o do Compass </li> <li>  DAG: dag_d_pipeline_compass_reviews. </li> <li>  JOB: GOLD_APP_GOLD_AGGREGATE_REVIEWS_SANTANDE </li> </ul> |
    
    </details>

  - `Hadoop`: Sistema distribu√≠do para armazenamento e processamento de dados.

    
    <details>
      <summary>Informa√ß√µes Detalhada do Armazenamento: HADOOP</summary>

      ---
      A camada Bronze armazena dados brutos coletados de diferentes fontes. Esses dados ainda n√£o passaram por processamento ou transforma√ß√£o. Subdiret√≥rios por aplicativo: `banco-santander-br_pf`, `santander-select-global_pf`, `santander-way_pf`. Abaixo est√° a estrutura detalhada:

      > Caminho Base Bronze: `/santander/bronze/compass/reviews/`
      
      
      | **Plataforma**     | **Caminho**                                       | **Subdiret√≥rios por Aplicativo**                                                                | **Organiza√ß√£o**                                 |
      |--------------------|---------------------------------------------------|------------------------------------------------------------------------------------------------|------------------------------------------------|
      | **Apple Store**     | `/santander/bronze/compass/reviews/appleStore/`   | <ul><li> `banco-santander-br_pf/`</li> <li>`santander-select-global_pf/`</li> <li>`santander-way_pf/`</li></ul>                     | Subdiret√≥rios por data de carga(`odate=YYYYMMDD`)      |
      | **Google Play**     | `/santander/bronze/compass/reviews/googlePlay/`   | <ul><li>`banco-santander-br_pf/` </li><li>`santander-select-global_pf/`</li> <li>`santander-way_pf/` </li></ul>                     | Subdiret√≥rios por data de carga(`odate=YYYYMMDD`)      |
      | **MongoDB**         | `/santander/bronze/compass/reviews/mongodb/`      | <ul><li>`banco-santander-br_pf/` </li><li>`santander-select-global_pf/`</li> <li>`santander-way_pf/` </li>                     | Subdiret√≥rios por data de carga (`odate=YYYYMMDD`)      |

      ---
      
      A camada **Silver** cont√©m dados processados e transformados a partir da camada Bronze. Esses dados s√£o mais estruturados e prontos para an√°lise.
      
      > Caminho Base Silver: `/santander/silver/compass/reviews/`
      
      
      
      | **Plataforma**     | **Caminho**                                       | **Subdiret√≥rios por Aplicativo**           | **Organiza√ß√£o**                                 |
      |--------------------|---------------------------------------------------|--------------------------------------------|------------------------------------------------|
      | **Apple Store**     | `/santander/silver/compass/reviews/appleStore/`   | Dados processados da Apple Store.         | Subdiret√≥rios por data de carga (`odate=YYYYMMDD`)      |
      | **Google Play**     | `/santander/silver/compass/reviews/googlePlay/`   | Dados processados do Google Play.         | Subdiret√≥rios por data de carga (`odate=YYYYMMDD`)      |
      | **MongoDB**         | `/santander/silver/compass/reviews/mongodb/`      | Dados processados do MongoDB.             | Subdiret√≥rios por data de carga (`odate=YYYYMMDD`)      |
      | **Falhas**          | `/santander/silver/compass/reviews_fail/`         | Dados que falharam no processamento.      | Subdiret√≥rios por data de carga (`odate=YYYYMMDD`)      |
      
      ---
      
      A camada **Gold** cont√©m dados agregados e prontos para consumo final. Esses dados s√£o utilizados para gera√ß√£o de relat√≥rios, dashboards e an√°lises avan√ßadas.
      > Caminho Base Gold: `/santander/gold/compass/reviews/`
      
      | **Tipo de Dado**          | **Caminho**                                       | **Descri√ß√£o**                                                                                   | **Organiza√ß√£o**                                 |
      |---------------------------|---------------------------------------------------|------------------------------------------------------------------------------------------------|------------------------------------------------|
      | **Agrega√ß√£o de Reviews**  | `/santander/gold/compass/reviews/apps_santander_aggregate/` | Dados agregados dos aplicativos do Santander.                                                  | Subdiret√≥rios por data de carga (`odate=YYYYMMDD`)      |
      | **Falhas no Processamento** | `/santander/gold/compass/reviews_fail/`           | Dados que falharam no processamento final.                                                     | Subdiret√≥rios por data de carga (`odate=YYYYMMDD`)      |
      
      ---
      
      
      A camada **Quality** cont√©m dados relacionados √† qualidade dos dados, como padr√µes de valida√ß√£o e m√©tricas de qualidade.
      > Caminho Base Quality: `/santander/quality/compass/reviews/`
      
      | **Tipo de Dado**          | **Caminho**                                       | **Descri√ß√£o**                                                                                   | **Organiza√ß√£o**                                 |
      |---------------------------|---------------------------------------------------|------------------------------------------------------------------------------------------------|------------------------------------------------|
      | **Padr√µes de Valida√ß√£o**  | `/santander/quality/compass/reviews/pattern/`     | Padr√µes de valida√ß√£o aplicados aos dados.                                                      | Subdiret√≥rios por plataforma (ex: `pattern/`, `schema/`) |
      
    
    </details>

  - `Elasticsearch`: O **Elasticsearch** √© usado para indexa√ß√£o e busca de dados t√©cnicos. Abaixo est√£o os √≠ndices dispon√≠veis, com seus objetivos e respons√°veis pela ingest√£o dos dados.

     <details>
      <summary>Informa√ß√µes Detalhada do Armazenamento: ELASTICSEARCH</summary>

      ---

      Os √≠ndices abaixo s√£o utilizados para monitoramento t√©cnico e an√°lise de performance dos processos de ingest√£o e transforma√ß√£o de dados no Compass:

      
      | **√çndice**                         | **Objetivo**                                  | **Quem Alimenta** |
      |-------------------------------------|-----------------------------------------------|-------------------|
      | **compass_dt_datametrics**          | Dados t√©cnicos de m√©tricas de performance     | <ul><li> DAG: `dag_d_pipeline_compass_review` </li> <li>JOB: Todos JOBS SPARK (group_ingestion, group_jobs_silver, group_jobs_gold)</li></ul> |
      | **compass_dt_datametrics_fail**     | Dados de falhas nas m√©tricas de performance   | <ul><li> DAG: `dag_d_pipeline_compass_reviews` </li> <li> JOB: Todos JOBS SPARK (group_ingestion, group_jobs_silver, group_jobs_gold) </li></ul> |
    
    </details>



### 3.1.4 Camada de Visualiza√ß√£o e Telemetria (observabilidade)

- `Metabase`: Ferramenta de Business Intelligence (BI) para an√°lise de dados.
  <details>
    <summary>Informa√ß√µes Detalhada do Dashboard: METABASE </summary>

    O Metabase √© uma ferramenta de Business Intelligence (BI) que permite a an√°lise de dados de forma intuitiva e visual. Ele facilita a cria√ß√£o de dashboards interativos e relat√≥rios sem a necessidade de conhecimento avan√ßado em queries.

    - **Objetivo do Metabase:**  O principal objetivo do Metabase √© fornecer uma interface amig√°vel para que usu√°rios de neg√≥cio possam acessar, visualizar e analisar dados sem depend√™ncia de equipes t√©cnicas. Ele permite a tomada de decis√µes baseada em dados de forma √°gil e eficiente.

    - **Por que utilizar o Metabase?** 
        - Interface intuitiva: N√£o requer conhecimento avan√ßado em queries.
        - Open-source e extens√≠vel: Pode ser personalizado conforme necessidade.
        - Integra√ß√£o com diversas fontes de dados: Suporte para bancos SQL e NoSQL.
        - Cria√ß√£o r√°pida de dashboards: Permite visualizar KPIs e m√©tricas facilmente.
        - Automatiza√ß√£o de relat√≥rios: Gera√ß√£o autom√°tica de relat√≥rios e alertas por e-mail.       

    - **Dashboards  (link de acesso):** Os dashboards criados no Metabase fornecem uma vis√£o detalhada dos principais indicadores e m√©tricas da organiza√ß√£o.

    | **Categoria**                     | **M√©tricas**             | **Ambiente** | **Link de acesso**
    |-----------------------------------|--------------------------|--------------|----------------------
    | Observabilidade Aplica√ß√£o         | Aplica√ß√£o (neg√≥cio)      | Pro-Produ√ß√£o | [Dashboard Compass - PRO - Data - Metabase](http://00.000.000.00:8085/setup)


  - **Metodologia e boas pr√°ticas:** Utilizando as boas pr√°ticas, o dashboard foi dividido em 3 vis√µes: (1) vis√£o gerencial, (2) vis√£o macro por ano-mes e (3) vis√£o granular.

    A vis√£o (1) √© dedicada para a vis√£o gerencial estruturada com vis√µes gr√°ficas estraturada em:

      - M√©dia da experi√™ncia do cliente atual
      - Segmenta√ß√£o do(s) canais Santander PF e PJ 
      - Nota m√©dia do(s) aplicativos Santander - hist√≥rico
      - Volumetria de avalia√ß√µes dos apps Santander - total
      - Volume por canais e segmento
      - Volumetria de avalia√ß√µes nos canais Santander por ano-mes
      - Volume por origem extra√ß√£o e segmento
      - Volumetria de avalia√ß√µes dos canais Santander por origem

    J√° a vis√£o (2) √© dedicada para a vis√£o macro gerencial estruturado em tabela com vis√µes das seguintes informa√ß√µes:

      - App nome
      - App Source
      - Periodo Referencia
      - Segmento
      - Nota M√©dia
      - Avalia√ß√µes Totais
      - Coment√°rios Positivos
      - Coment√°rios Negativos

    E a vis√£o (3) j√° √© com a menor granularidade, sendo os eventos de feedbacks dos clientes, estruturado em tabela nas seguintes vis√µes:
  
      - Titulo
      - Snippet (conte√∫do da avalia√ß√£o)
      - App Source
      - App
      - Segmento
      - Nota
      - Timestamp da avalia√ß√£o
      - Periodo Rereferencia 
  - **Tabela de m√©tricas utilizadas:**

    | **Componente**              | **Categoria**            | Vis√£o | **Tipo de Painel**        | **Nome da m√©trica**                         | **Unidade**  | **Descri√ß√£o** | **Query Metrica** | **Fonte**
    |-----------------------------|--------------------------|-------|-------------------|---------------------------------------------|--------------|---------------|-----------------------------------|----------------------------
    | Nota m√©dia das avalia√ß√µes   | Indicador                | Display: Progresso  | Dashboard     | M√©dia da experi√™ncia do cliente atual       | 1 a 5        | Nota m√©dia das avalia√ß√µes dos clientes de 1 a 5 de acordo filtro selecionado| `[ {"$sort":{"periodo_referencia":-1}}, {"$project":{"app_nome":"$app_nome","app_source":"$app_source","periodo_referencia":"$periodo_referencia","nota_media":{"$round":["$nota_media",0]},"avaliacoes_total":"$avaliacoes_total","comentarios_positivos":"$comentarios_positivos","comentarios_negativos":"$comentarios_negativos","segmento":"$segmento"}}, {"$limit":1048575}, {"$match":{"$and":[{"nota_media":{"$gte":1}},{"nota_media":{"$lte":5}}]}}, {"$sort":{"periodo_referencia":1,"app_nome":1,"app_source":1}}, {"$project":{"_id":"$_id","app_nome":"$app_nome","app_source":"$app_source","periodo_referencia":"$periodo_referencia","nota_media":"$nota_media","avaliacoes_total":"$avaliacoes_total","comentarios_positivos":"$comentarios_positivos","comentarios_negativos":"$comentarios_negativos","segmento":"$segmento"}}, {"$limit":1048575}, {"$match":{"$and":[{"nota_media":{"$gte":1}},{"nota_media":{"$lte":5}}]}}, {"$group":{"_id":{"periodo_referencia":"$periodo_referencia","segmento":"$segmento"},"avg_nota_media":{"$avg":"$nota_media"},"app_nome":{"$first":"$app_nome"},"app_source":{"$first":"$app_source"}}}, {"$sort":{"_id":1}}, {"$project":{"_id":false,"periodo_referencia":"$_id.periodo_referencia","segmento":"$_id.segmento","avg":"$avg_nota_media","app_nome":1,"app_source":1}}, { "$match": { "$expr": { "$eq": [ "$periodo_referencia", { "$max": "$periodo_referencia" } ] } } }, { "$sort": { "periodo_referencia": -1 } }, { "$project": { "_id": false, "avg": "$avg" } }, { "$limit": 1 } ]` | MongoDB
    | Volumetria de reclama√ß√µes por segmento   | Indicador   | Display: Pizza  |Dashboard     | Segmenta√ß√£o do(s) canais Santander - PF e PJ ~| PF, PJ + volumetria        | Volumetria de reclama√ß√µes por segmento x volumetria + porcentagem | `[ {"$sort":{"periodo_referencia":-1}}, {"$project":{"app_nome":"$app_nome","app_source":"$app_source","periodo_referencia":"$periodo_referencia","nota_media":{"$round":["$nota_media",0]},"avaliacoes_total":"$avaliacoes_total","comentarios_positivos":"$comentarios_positivos","comentarios_negativos":"$comentarios_negativos","segmento":"$segmento"}}, {"$limit":1048575}, {"$match":{"$and":[{"nota_media":{"$gte":1}},{"nota_media":{"$lte":5}}]}}, {"$sort":{"periodo_referencia":1,"app_nome":1,"app_source":1}}, {"$project":{"_id":"$_id","app_nome":"$app_nome","app_source":"$app_source","periodo_referencia":"$periodo_referencia","nota_media":"$nota_media","avaliacoes_total":"$avaliacoes_total","comentarios_positivos":"$comentarios_positivos","comentarios_negativos":"$comentarios_negativos","segmento":"$segmento"}}, {"$limit":1048575}, {"$match":{"$and":[{"nota_media":{"$gte":1}},{"nota_media":{"$lte":5}}]}}, {"$group":{"_id":{"periodo_referencia":"$periodo_referencia","segmento":"$segmento"},"avg_nota_media":{"$avg":"$nota_media"},"app_nome":{"$first":"$app_nome"},"app_source":{"$first":"$app_source"}}}, {"$sort":{"_id":1}}, {"$project":{"_id":false,"periodo_referencia":"$_id.periodo_referencia","segmento":"$_id.segmento","avg":"$avg_nota_media","app_nome":1,"app_source":1}}, { "$match": { "$and": [ { "$and": [ { "avg": { "$gte": 1 } }, { "avg": { "$lte": 5 } } ] }, { "$or": [ { "segmento": "PF" }, { "segmento": "PJ" } ] } ] } }, { "$sort": { "periodo_referencia": -1 } }, { "$project": { "_id": false, "periodo_referencia": "$periodo_referencia", "segmento": "$segmento", "avg": "$avg", "app_nome": "$app_nome", "app_source": "$app_source" } }, { "$limit": 1048575 } ]` | MongoDB
    | Nota m√©dia dos aplicativos Santander por ano m√™s   | Indicador   | Display: Barra  |Dashboard     | Nota m√©dia do(s) aplicativos Santander - historico ~| M√©dia da nota por ano m√™s       | Nota rela√ß√£o aplicativos Santader por ano m√™s de acordo filtro selecionado| `[ {"$sort":{"periodo_referencia":-1}}, {"$project":{"app_nome":"$app_nome","app_source":"$app_source","periodo_referencia":"$periodo_referencia","nota_media":{"$round":["$nota_media",0]},"avaliacoes_total":"$avaliacoes_total","comentarios_positivos":"$comentarios_positivos","comentarios_negativos":"$comentarios_negativos","segmento":"$segmento"}}, {"$limit":1048575}, {"$match":{"$and":[{"nota_media":{"$gte":1}},{"nota_media":{"$lte":5}}]}}, {"$sort":{"periodo_referencia":1,"app_nome":1,"app_source":1}}, {"$project":{"_id":"$_id","app_nome":"$app_nome","app_source":"$app_source","periodo_referencia":"$periodo_referencia","nota_media":"$nota_media","avaliacoes_total":"$avaliacoes_total","comentarios_positivos":"$comentarios_positivos","comentarios_negativos":"$comentarios_negativos","segmento":"$segmento"}}, {"$limit":1048575}, {"$match":{"$and":[{"nota_media":{"$gte":1}},{"nota_media":{"$lte":5}}]}}, {"$group":{"_id":{"periodo_referencia":"$periodo_referencia","segmento":"$segmento"},"avg_nota_media":{"$avg":"$nota_media"},"app_nome":{"$first":"$app_nome"},"app_source":{"$first":"$app_source"}}}, {"$sort":{"_id":1}}, {"$project":{"_id":false,"periodo_referencia":"$_id.periodo_referencia","segmento":"$_id.segmento","avg":"$avg_nota_media","app_nome":1,"app_source":1}}, { "$match": { "$and": [ { "avg": { "$gte": 1 } }, { "avg": { "$lte": 5 } } ] } }, { "$sort": { "periodo_referencia": -1 } }, { "$project": { "_id": false, "periodo_referencia": "$periodo_referencia", "segmento": "$segmento", "avg": "$avg", "app_nome": "$app_nome", "app_source": "$app_source" } }, { "$limit": 1048575 } ]` | MongoDB
    | Volumetria de avalia√ß√µes totais   | Indicador   | Display: Indicador  |Dashboard     | Volumetria de avalia√ß√µes dos apps Santander total ~ | Volumetria totais de avalia√ß√µes      | Volumetria totais de avalia√ß√µes de acordo filtro selecionado| `[ {"$sort":{"periodo_referencia":1}}, {"$project":{"_id":"$_id","app_nome":"$app_nome","app_source":"$app_source","periodo_referencia":"$periodo_referencia","nota_media":"$nota_media","nota_tendencia":"$nota_tendencia","avaliacoes_total":"$avaliacoes_total","comentarios_positivos":"$comentarios_positivos","comentarios_negativos":"$comentarios_negativos","segmento":"$segmento"}}, {"$limit":1048575}, {"$match":{"$and":[{"nota_media":{"$gte":1}},{"nota_media":{"$lte":5}}]}}, {"$sort":{"periodo_referencia":-1}}, {"$project":{"_id":"$_id","app_nome":"$app_nome","app_source":"$app_source","periodo_referencia":"$periodo_referencia","nota_media":"$nota_media","nota_tendencia":"$nota_tendencia","avaliacoes_total":"$avaliacoes_total","comentarios_positivos":"$comentarios_positivos","comentarios_negativos":"$comentarios_negativos","segmento":"$segmento"}}, {"$limit":1048575}, {"$group":{"_id":{"periodo_referencia":"$periodo_referencia","segmento":"$segmento","app_nome":"$app_nome","app_source":"$app_source"},"avg_nota_media":{"$avg":"$nota_media"},"avg_nota_tendencia":{"$avg":"$nota_tendencia"},"total_avaliacoes":{"$sum":"$avaliacoes_total"}}}, {"$sort":{"_id":1}}, {"$project":{"_id":false,"periodo_referencia":"$_id.periodo_referencia","segmento":"$_id.segmento","app_nome":"$_id.app_nome","app_source":"$_id.app_source","avg_nota_media":"$avg_nota_media","avg_nota_tendencia":"$avg_nota_tendencia","total_avaliacoes":"$total_avaliacoes"}}, { "$group": { "_id": null, "sum": { "$sum": "$total_avaliacoes" } } }, { "$sort": { "_id": 1 } }, { "$project": { "_id": false, "sum": true } } ]` | MongoDB
    | Volumetria de avalia√ß√µes totais agregados por canais e segmento   | Indicador   | Display: Pizza  |Dashboard     | Volume por canais e segmento ~ | Volumetria totais de avalia√ß√µes agregado por cenais e segmento    | Volumetria totais de avalia√ß√µes agregado de acordo filtro selecionado | `[ {"$sort":{"periodo_referencia":1}}, {"$project":{"_id":"$_id","app_nome":"$app_nome","app_source":"$app_source","periodo_referencia":"$periodo_referencia","nota_media":"$nota_media","nota_tendencia":"$nota_tendencia","avaliacoes_total":"$avaliacoes_total","comentarios_positivos":"$comentarios_positivos","comentarios_negativos":"$comentarios_negativos","segmento":"$segmento"}}, {"$limit":1048575}, {"$match":{"$and":[{"nota_media":{"$gte":1}},{"nota_media":{"$lte":5}}]}}, {"$sort":{"periodo_referencia":-1}}, {"$project":{"_id":"$_id","app_nome":"$app_nome","app_source":"$app_source","periodo_referencia":"$periodo_referencia","nota_media":"$nota_media","nota_tendencia":"$nota_tendencia","avaliacoes_total":"$avaliacoes_total","comentarios_positivos":"$comentarios_positivos","comentarios_negativos":"$comentarios_negativos","segmento":"$segmento"}}, {"$limit":1048575}, {"$group":{"_id":{"periodo_referencia":"$periodo_referencia","segmento":"$segmento","app_nome":"$app_nome","app_source":"$app_source"},"avg_nota_media":{"$avg":"$nota_media"},"avg_nota_tendencia":{"$avg":"$nota_tendencia"},"total_avaliacoes":{"$sum":"$avaliacoes_total"}}}, {"$sort":{"_id":1}}, {"$project":{"_id":false,"periodo_referencia":"$_id.periodo_referencia","segmento":"$_id.segmento","app_nome":"$_id.app_nome","app_source":"$_id.app_source","avg_nota_media":"$avg_nota_media","avg_nota_tendencia":"$avg_nota_tendencia","total_avaliacoes":"$total_avaliacoes"}}, { "$sort": { "periodo_referencia": -1 } }, { "$project": { "_id": false, "periodo_referencia": "$periodo_referencia", "segmento": "$segmento", "app_nome": "$app_nome", "app_source": "$app_source", "total_avaliacoes": "$total_avaliacoes" } }, { "$limit": 1048575 } ]` | MongoDB
    | Volumetria de avalia√ß√µes totais agregados por canais e segmento   | Indicador   | Display: Barra  |Dashboard     | Volumetria de avalia√ß√µes nos Canais Santander por ano-mes ~ | Volumetria totais de avalia√ß√µes agregado por cenais e segmento    | Volumetria totais de avalia√ß√µes agregado de acordo filtro selecionado selecionado | `[ {"$sort":{"periodo_referencia":1}}, {"$project":{"_id":"$_id","app_nome":"$app_nome","app_source":"$app_source","periodo_referencia":"$periodo_referencia","nota_media":"$nota_media","nota_tendencia":"$nota_tendencia","avaliacoes_total":"$avaliacoes_total","comentarios_positivos":"$comentarios_positivos","comentarios_negativos":"$comentarios_negativos","segmento":"$segmento"}}, {"$limit":1048575}, {"$match":{"$and":[{"nota_media":{"$gte":1}},{"nota_media":{"$lte":5}}]}}, {"$sort":{"periodo_referencia":-1}}, {"$project":{"_id":"$_id","app_nome":"$app_nome","app_source":"$app_source","periodo_referencia":"$periodo_referencia","nota_media":"$nota_media","nota_tendencia":"$nota_tendencia","avaliacoes_total":"$avaliacoes_total","comentarios_positivos":"$comentarios_positivos","comentarios_negativos":"$comentarios_negativos","segmento":"$segmento"}}, {"$limit":1048575}, {"$group":{"_id":{"periodo_referencia":"$periodo_referencia","segmento":"$segmento","app_nome":"$app_nome","app_source":"$app_source"},"avg_nota_media":{"$avg":"$nota_media"},"avg_nota_tendencia":{"$avg":"$nota_tendencia"},"total_avaliacoes":{"$sum":"$avaliacoes_total"}}}, {"$sort":{"_id":1}}, {"$project":{"_id":false,"periodo_referencia":"$_id.periodo_referencia","segmento":"$_id.segmento","app_nome":"$_id.app_nome","app_source":"$_id.app_source","avg_nota_media":"$avg_nota_media","avg_nota_tendencia":"$avg_nota_tendencia","total_avaliacoes":"$total_avaliacoes"}}, { "$sort": { "periodo_referencia": -1 } }, { "$project": { "_id": false, "periodo_referencia": "$periodo_referencia", "segmento": "$segmento", "app_nome": "$app_nome", "app_source": "$app_source", "total_avaliacoes": "$total_avaliacoes" } }, { "$limit": 1048575 } ]` | MongoDB
    | Volumetria agregada por origem de extra√ß√£o e segmento PF/PJ   | Indicador   | Display: Pizza  |Dashboard     | Volume por Origem Extracao e Segmento ~ | Volumetria agregada por origem e segmento dos clientes    | Volumetria agregada por origem e segmento de acordo filtro selecionado | `[ {"$sort":{"periodo_referencia":1}}, {"$project":{"_id":"$_id","app_nome":"$app_nome","app_source":"$app_source","periodo_referencia":"$periodo_referencia","nota_media":"$nota_media","nota_tendencia":"$nota_tendencia","avaliacoes_total":"$avaliacoes_total","comentarios_positivos":"$comentarios_positivos","comentarios_negativos":"$comentarios_negativos","segmento":"$segmento"}}, {"$limit":1048575}, {"$match":{"$and":[{"nota_media":{"$gte":1}},{"nota_media":{"$lte":5}}]}}, {"$sort":{"periodo_referencia":-1}}, {"$project":{"_id":"$_id","app_nome":"$app_nome","app_source":"$app_source","periodo_referencia":"$periodo_referencia","nota_media":"$nota_media","nota_tendencia":"$nota_tendencia","avaliacoes_total":"$avaliacoes_total","comentarios_positivos":"$comentarios_positivos","comentarios_negativos":"$comentarios_negativos","segmento":"$segmento"}}, {"$limit":1048575}, {"$group":{"_id":{"periodo_referencia":"$periodo_referencia","segmento":"$segmento","app_nome":"$app_nome","app_source":"$app_source"},"avg_nota_media":{"$avg":"$nota_media"},"avg_nota_tendencia":{"$avg":"$nota_tendencia"},"total_avaliacoes":{"$sum":"$avaliacoes_total"}}}, {"$sort":{"_id":1}}, {"$project":{"_id":false,"periodo_referencia":"$_id.periodo_referencia","segmento":"$_id.segmento","app_nome":"$_id.app_nome","app_source":"$_id.app_source","avg_nota_media":"$avg_nota_media","avg_nota_tendencia":"$avg_nota_tendencia","total_avaliacoes":"$total_avaliacoes"}}, { "$sort": { "periodo_referencia": -1 } }, { "$project": { "_id": false, "periodo_referencia": "$periodo_referencia", "segmento": "$segmento", "app_nome": "$app_nome", "app_source": "$app_source", "total_avaliacoes": "$total_avaliacoes" } }, { "$limit": 1048575 } ]` | MongoDB
    | Volumetria agregada por canais vs origem   | Indicador   | Display: Linha  |Dashboard     | Volumetria de avalia√ß√µes dos Canais Santander por Origem ~ | Volumetria agregada por canal e origem de extra√ß√£o   | Volumetria agregada por canal e origem de acordo com filtro selecionado | `[ {"$sort":{"periodo_referencia":1}}, {"$project":{"_id":"$_id","app_nome":"$app_nome","app_source":"$app_source","periodo_referencia":"$periodo_referencia","nota_media":"$nota_media","nota_tendencia":"$nota_tendencia","avaliacoes_total":"$avaliacoes_total","comentarios_positivos":"$comentarios_positivos","comentarios_negativos":"$comentarios_negativos","segmento":"$segmento"}}, {"$limit":1048575}, {"$match":{"$and":[{"nota_media":{"$gte":1}},{"nota_media":{"$lte":5}}]}}, {"$sort":{"periodo_referencia":-1}}, {"$project":{"_id":"$_id","app_nome":"$app_nome","app_source":"$app_source","periodo_referencia":"$periodo_referencia","nota_media":"$nota_media","nota_tendencia":"$nota_tendencia","avaliacoes_total":"$avaliacoes_total","comentarios_positivos":"$comentarios_positivos","comentarios_negativos":"$comentarios_negativos","segmento":"$segmento"}}, {"$limit":1048575}, {"$group":{"_id":{"periodo_referencia":"$periodo_referencia","segmento":"$segmento","app_nome":"$app_nome","app_source":"$app_source"},"avg_nota_media":{"$avg":"$nota_media"},"avg_nota_tendencia":{"$avg":"$nota_tendencia"},"total_avaliacoes":{"$sum":"$avaliacoes_total"}}}, {"$sort":{"_id":1}}, {"$project":{"_id":false,"periodo_referencia":"$_id.periodo_referencia","segmento":"$_id.segmento","app_nome":"$_id.app_nome","app_source":"$_id.app_source","avg_nota_media":"$avg_nota_media","avg_nota_tendencia":"$avg_nota_tendencia","total_avaliacoes":"$total_avaliacoes"}}, {"$project":{"_id":false,"periodo_referencia":"$periodo_referencia","segmento":"$segmento","app_nome":"$app_nome","app_source":"$app_source","avg_nota_media":"$avg_nota_media","avg_nota_tendencia":"$avg_nota_tendencia","total_avaliacoes":"$total_avaliacoes"}}, {"$limit":1048575}, { "$sort": { "periodo_referencia": -1, "app_source": 1 } }, { "$project": { "_id": false, "periodo_referencia": "$periodo_referencia", "segmento": "$segmento", "app_nome": "$app_nome", "app_source": "$app_source", "avg_nota_media": "$avg_nota_media", "avg_nota_tendencia": "$avg_nota_tendencia", "total_avaliacoes": "$total_avaliacoes" } }, { "$limit": 1048575 } ]` | MongoDB
    | Vis√£o agregada (macro) por Fonte, Canal e Segmento   | Tabela Agregada   | Display: Tabela  |Agregada     | Dt D View Gold Agg Compass ~ | Agregada por ano m√™s, segmento e nota m√©dia.   | Vis√£o agregada por Fonte de Origem, Canais, Segmento (PF, PJ) e quebrado por nota m√©dia, avalia√ß√µes totais, coment√°rios positivos e coment√°rios negativos. | `[ { "$project": { "_id": "$_id", "app_nome": "$app_nome", "app_source": "$app_source", "periodo_referencia": "$periodo_referencia", "segmento": "$segmento", "nota_media": "$nota_media", "avaliacoes_total": "$avaliacoes_total", "comentarios_positivos": "$comentarios_positivos", "comentarios_negativos": "$comentarios_negativos" } }, { "$limit": 1048575 } ]` | MongoDB
    | Vis√£o detalhada  | Tabela Anal√≠tica   | Display: Tabela  |Anal√≠tica     | Compass - Visao detalhada, Ordenado por iso_date descendente, segmento ascendente, app ascendente, e app_source ascendente | Vis√£o granular das avalia√ß√µes dos clientes.   | Vis√£o detalhada na menor granulidade com as avalia√ß√µes dos clientes, disponibilizando o TITULO (descritivo da avalia√ß√£o ou nome do cliente), SNIPPET (corpo da avalia√ß√£o), APP_SOURCE (fonte de origem), APP, SEGMENTO, RATING (nota da avalia√ß√£o do cliente), ISO_DATE (timestamp da avalia√ß√£o) e PERIODO_REFERENCIA (ano m√™s da avalia√ß√£o) | `[ {"$match":{"$and":[{"rating":{"$gte":1}},{"rating":{"$lte":5}}]}}, {"$sort":{"iso_date":-1,"app_source":1,"app":1}}, {"$project":{"_id":"$_id","title":"$title","snippet":"$snippet","app_source":"$app_source","app":"$app","segmento":"$segmento","rating":"$rating","iso_date":"$iso_date"}}, {"$limit":1048575}, { "$sort": { "iso_date": -1, "segmento": 1, "app": 1, "app_source": 1 } }, { "$project": { "_id": false, "title": "$title", "snippet": "$snippet", "app_source": "$app_source", "app": "$app", "segmento": "$segmento", "rating": "$rating", "iso_date": "$iso_date", "periodo_referencia": { "$substrCP": [ "$iso_date", { "$subtract": [ 1, 1 ] }, 7 ] } } }, { "$limit": 1048575 } ]` | MongoDB
    
    


  </details>
  
- `Grafana`: Plataforma para monitoramento e visualiza√ß√£o de m√©tricas operacionais.
  <details>
    <summary>Informa√ß√µes Detalhada do Dashboard: GRAFANA </summary>

    O Grafana √© uma plataforma de monitoramento e observabilidade utilizada para visualizar m√©tricas, logs e traces em tempo real. Ele permite a cria√ß√£o de dashboards din√¢micos, integrando diferentes fontes de dados para um acompanhamento eficiente da infraestrutura e aplica√ß√µes.

  - **Objetivo do Grafa:** O Grafana foi projetado para fornecer uma interface intuitiva e centralizada para monitoramento de sistemas e an√°lise de m√©tricas. Ele √© ideal para equipes de SRE, DevOps e engenharia de dados, permitindo a detec√ß√£o r√°pida de problemas e otimiza√ß√£o do desempenho de aplica√ß√µes e servidores.

  - **Por que utilizar o Grafana?**

    -  Monitoramento - Ideal para an√°lise cont√≠nua de m√©tricas e logs.
    - Integra√ß√£o com diversas fontes de dados ‚Äì Compat√≠vel com Prometheus, InfluxDB, Elasticsearch, MySQL, PostgreSQL, entre outros.
    - Dashboards altamente personaliz√°veis ‚Äì Suporte a pain√©is interativos, gr√°ficos avan√ßados e filtros din√¢micos.
    - Alertas inteligentes ‚Äì Configura√ß√£o de notifica√ß√µes autom√°ticas via Slack, PagerDuty, e-mail, entre outros.
  
  - Dashboards (link de acesso): Os dashboards criados no Metabase fornecem uma vis√£o detalhada dos principais indicadores e m√©tricas da organiza√ß√£o.
    
    | **Categoria**                     | **M√©tricas**             | **Ambiente** | **Link de acesso**
    |-----------------------------------|--------------------------|--------------|----------------------
    | Observabilidade Aplica√ß√£o         | Aplica√ß√£o (dev)      | Pro-Produ√ß√£o | [Dashboard Compass - PRO - Data - Grafana](http://00.000.000.00:4000/d/eeex6c5w2x9fkb/compass-operacao-aplicacional?orgId=1&from=now-30d&to=now&timezone=browser))
    | Observabilidade Sustenta√ß√£o        | Sustenta√ß√£o         | Pro-Produ√ß√£o | [Dashboard Compass - PRO - Data - Grafana](http://00.000.000.00:4000/d/fef83ot67ctmoe/compass-sustentacao?orgId=1&from=now-30d&to=now&timezone=browser))

    

  - **Metolodogia e boas pr√°ticas:** O dashboard est√° estruturado em um padr√£o que dever√° ser mantido, garantindo a replica√ß√£o, organiza√ß√£o e adi√ß√£o de novas m√©tricas e componentes, pertmindo que os pain√©is respondam as perguntas sobre a sa√∫de dos sistemas que integram o projeto Compass.

    A vis√£o do Grafana foi dividida em 2 (duas) categorias, Dashboard de Aplica√ß√µes e Dashboard de Sustenta√ß√£o - **Dashboard de Aplica√ß√µes**

    O Dashboard de Aplica√ß√µes foram separados em alguns componentes para entender a volumetria de apps que rodaram e falharam nas √∫ltimas 24 horas e indicadores historicos de acordo com o filtro de timestamp selecionado, sendo composto por:
    
    - App Finish per layer
    - Valid Data Percentage
    - Applications Fail per layer
    - Invalid Data Percentage
    - Event Count of the Bronze Layer [historical]
    - Applications Completed per layer [historical]
    - Applications Fail per layer [historical]
    - Event Quality of the Bronze Layer [historical]
    - Event Quality of the Silver Layer [historical]
    - Event Quality of the Gold Layer [historical]
  
    | **Componente**      | **Categoria**            | Vis√£o                         | **Tipo de Painel**        | **Nome da m√©trica**                           | **Unidade**         | **Descri√ß√£o**                                                                                                                                                             | **Query Metrica**                                                                                | **Fonte**
    |---------------------|--------------------------|-------------------------------|---------------------------|-----------------------------------------------|---------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|----------------------------
    | Aplica√ß√µes Spark    | Totais de Sucessos       | Display: Estado               | Dashboard                 | App Finish per layer                          | Numero Total        | Exibe total de aplica√ß√µes que rodaram com sucesso nas √∫ltimas 24 horas, exibindo por camada Bronze, Silver e Gold                                                         | ``                                                                                               | ElasticSearch
    | Dados Validos       | Porcentagem Sucesso      | Display: Medidor              | Dashboard                 | Valid Data Percentage                         | Percentagem         | Exibe como est√° a qualidade de dados em porcentagem da ingest√£o e tratamento das cargas das √∫ltimas 24 horas de dados validos, exibindo por camada Bronze, Silver e Gold  | ``                                                                                               | ElasticSearch
    | Aplica√ß√µes Spark    | Totais de Falhas         | Display: Estado               | Dashboard                 | App Fail Finish per layer                     | Numero Total        | Exibe total de aplica√ß√µes que rodaram com falha nas √∫ltimas 24 horas, exibindo por camada Bronze, Silver e Gold                                                           | ``                                                                                               | ElasticSearch
    | Dados Invalidos     | Porcentagem Falha        | Display: Medidor              | Dashboard                 | Invalid Data Percentage                       | Percentagem         | Exibe como est√° a qualidade de dados em porcentagem da ingest√£o e tratamento das cargas das √∫ltimas 24 horas de dados invalidos, exibindo por camada Bronze, Silver e Gold| ``                                                                                               | ElasticSearch
    | Volumetria de dados | Totais de eventos        | Display: Medidor de Barras    | Dashboard                 | Count events: <camada: bronze,silver,gold>    | Numero Total        | Exibe a quantidade de dados processados por camada, desde a camada Bronze at√© a Gold                                                                                      | ``                                                                                               | ElasticSearch
    | Aplica√ß√µes Spark    | Totais de Sucessos       | Display: S√©ries Temporais     | Dashboard                 | App Finish per layer [historical]             | Numero Total        | Exibe total de aplica√ß√µes que rodaram com sucesso por timestamp (filtro) selecionado, exibindo por camada Bronze, Silver e Gold                                           | ``                                                                                               | ElasticSearch
    | Data Quality        | Totais de dados Invalidos| Display: S√©ries Temporais     | Dashboard                 | Event Quality of the Bronze Layer [historical]| Numero Total        | Exibe total de dados inv√°lidos encontrados para: Duplicados, Nulos e Consist√™ncia de Dados inv√°lidos para a camada Bronze                                                 | ``                                                                                               | ElasticSearch
    | Data Quality        | Totais de dados Invalidos| Display: S√©ries Temporais     | Dashboard                 | Event Quality of the Bronze Layer [historical]| Numero Total        | Exibe total de dados inv√°lidos encontrados para: Duplicados, Nulos e Consist√™ncia de Dados inv√°lidos para a camada Silver                                                 | ``                                                                                               | ElasticSearch
    | Data Quality        | Totais de dados Invalidos| Display: S√©ries Temporais     | Dashboard                 | Event Quality of the Bronze Layer [historical]| Numero Total        | Exibe total de dados inv√°lidos encontrados para: Duplicados, Nulos e Consist√™ncia de Dados inv√°lidos para a camada Gold                                                   | ``                                                                                               | ElasticSearch

    **Dashboard Sustenta√ß√£o**

    J√° o Dashboard de Sustenta√ß√£o foi estruturado para ter poucos componentes e sendo composto com apenas indicadores necess√°rios para entender se h√° problemas e qual problema, ajudando em uma an√°lise pr√©via:
    
    - Applications Fail per Priority [total]
    - Applications Fail per Prioruty [historical]
    - Application fail Table [historical]
      

    | **Componente**                     | **Categoria**            | Vis√£o                         | **Tipo de Painel**        | **Nome da m√©trica**                           | **Unidade**         | **Descri√ß√£o**                                                                                                                                                             | **Query Metrica**                                                                                | **Fonte**
    |------------------------------------|--------------------------|-------------------------------|---------------------------|-----------------------------------------------|---------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|----------------------------
    | Aplica√ß√µes Spark por prioridade    | Totais de Falhas         | Display: Medidor de Barras    | Dashboard                 | Applications fail per priority [total]        | Numero Total        | Exibe total de aplica√ß√µes que falharam de acordo com o tipo de prioridade, que pode ir de 0 a 2 que poder√° ser listado no dashboard, quanto menor a prioridade (exemplo: 0), mais crit√≠co √© o impacto para o pipeline                                                         | ``                                                                                               | ElasticSearch
    | Aplica√ß√µes Spark por camada        | Totais de Falhas         | Display: S√©ries Temporais     | Dashboard                 | Applications fail per priority [historical]   | Numero Total        | Exibe total de aplica√ß√µes que falharam de acordo com o tipo de prioridade, que pode ir de 0 a 2 que poder√° ser listado no dashboard, quanto menor a prioridade (exemplo: 0), mais crit√≠co √© o impacto para o pipeline de acordo com a camada (bronze, silver ou gold)                                                      | ``                                                                                               | ElasticSearch
    | Tabela de Falhas das aplica√ß√µes Spark | Detalhes das falhas   | Display: Tabela               | Dashboard                 | N/A                                           | Registro            | Tabela com os registros das aplica√ß√µes que falharam, exibindo: Timestamp, Layer, JOB, Priority, Projeto. Tower e Error                                                      | ``                                                                                               | ElasticSearch

  </details>

## 3.2 Aspectos T√©cnicos do Projeto Compass
---
Nesta se√ß√£o, ser√° apresentada a arquitetura t√©cnica do Projeto Compass, detalhando seu funcionamento desde a infraestrutura at√© a camada aplicacional. O objetivo √© fornecer uma vis√£o abrangente do que est√° sendo executado, como os processos acontecem e as raz√µes por tr√°s das escolhas feitas, garantindo uma compreens√£o clara sobre a opera√ß√£o e a arquitetura do sistema.

### 3.2.1 Tecnologias Utilizadas

Como base principal, as tecnologias utilizadas foram necess√°rias para atender o fluxo de dados, desde a coleta at√© a disponibiliza√ß√£o das informa√ß√µes.

- **MongoDB:** Utilizado para duas finalidades principais:
    - Armazenamento de cole√ß√µes contendo dados brutos provenientes dos Canais Santander.
    - Manuten√ß√£o de cole√ß√µes estruturadas nas camadas silver e gold, que servem como base para an√°lises no Metabase.
- **Hadoop HDFS:** Respons√°vel pelo armazenamento hist√≥rico dos dados, abrangendo desde a camada bronze (ingest√£o) at√© a gold, al√©m de suportar servi√ßos de data quality.
- **ElasticSearch:** Utilizado para armazenamento de m√©tricas t√©cnicas e dados relacionados ao desempenho das aplica√ß√µes.
- **Apache Spark:** Ferramenta principal para processamento distribu√≠do de dados em larga escala.
- **Apache Airflow:** Respons√°vel pela orquestra√ß√£o das execu√ß√µes dos cont√™ineres Spark, garantindo o fluxo automatizado das cargas de trabalho.
- **Metabase:** Ferramenta de Business Intelligence utilizada pelo time de neg√≥cios para an√°lise de dados e gera√ß√£o de insights.
- **Grafana:** Solu√ß√£o dedicada √† observabilidade t√©cnica, permitindo o monitoramento detalhado dos sistemas e m√©tricas operacionais.
- **SerpApi:** API opcional na arquitetura, utilizada para extra√ß√£o de dados de avalia√ß√µes da Google Play Store.
- **iTunes API:** API externa utilizada para coleta de informa√ß√µes da Apple Store.
- **GitHub Actions:** Empregado para automa√ß√£o de testes unit√°rios, build de imagens e publica√ß√£o no Docker Hub.
- **Docker Hub:** Reposit√≥rio utilizado para armazenamento e versionamento das imagens Docker das aplica√ß√µes Spark e da infraestrutura.

> [!NOTE]
> O projeto Compass foi concebido para ser executado inicialmente em um ambiente on-premises. Embora solu√ß√µes em nuvem, como Azure e AWS, ofere√ßam vantagens significativas, como escalabilidade e alta disponibilidade, sua ado√ß√£o exclusiva pode gerar depend√™ncia de fornecedores espec√≠ficos. Para mitigar esse risco, a escolha por tecnologias open-source proporciona maior flexibilidade, permitindo a execu√ß√£o local e facilitando a migra√ß√£o para a nuvem quando necess√°rio, sem comprometer a autonomia do sistema.


### 3.2.2 Caracteristicas da Execu√ß√£o do Projeto

O projeto Compass √© executado em uma infraestrutura on-premises, onde os servi√ßos s√£o instanciados localmente em cont√™ineres baseados em imagens Docker. Para garantir a gest√£o eficiente da execu√ß√£o desses cont√™ineres, foi necess√°ria a ado√ß√£o de uma ferramenta de orquestra√ß√£o, sendo o Docker Swarm a solu√ß√£o escolhida para este ambiente.

O Docker Swarm foi escolhido como ferramenta de orquestra√ß√£o no projeto Compass devido √† sua simplicidade operacional, integra√ß√£o nativa com Docker e adequa√ß√£o ao ambiente on-premises. Diferente de solu√ß√µes mais complexas, como Kubernetes, o Swarm permite a cria√ß√£o e o gerenciamento de clusters de forma mais direta, reduzindo o tempo de configura√ß√£o e facilitando a administra√ß√£o dos servi√ßos conteinerizados.

A escolha tamb√©m considerou a necessidade de baixa sobrecarga computacional, j√° que o Swarm √© mais leve e n√£o exige um alto consumo de recursos, tornando-se uma alternativa vi√°vel para infraestrutura local. Al√©m disso, seu mecanismo de balanceamento de carga autom√°tico e alta disponibilidade garante a distribui√ß√£o eficiente das cargas de trabalho, melhorando a resili√™ncia dos servi√ßos sem a necessidade de configura√ß√µes avan√ßadas.


### 3.2.2.1 **Infraestrutura do Projeto Compass**

Nessa sess√£o, ser√° descrito a infraestrutura para atender a demanda do projeto Compass, utilizada para gerenciar um ambiente Hadoop distribu√≠do. A configura√ß√£o permite a orquestra√ß√£o dos servi√ßos essenciais do Hadoop, incluindo Namenode, Datanode, History Server, Resource Manager e Node Manager.


| **Configura√ß√£o**        | **Servi√ßo**            | **Imagem**                                                   | **Portas**           | **Volumes**                               | **Vari√°veis de Ambiente**      | **Replicas** | **Healthcheck**                                           |
|-------------------------|------------------------|--------------------------------------------------------------|----------------------|-------------------------------------------|---------------------------------|--------------|-----------------------------------------------------------|
| **Configura√ß√£o Hadoop** | **Namenode**            | `iamgacarvalho/hadoop-namenode-data-in-compass:2.0.0`        | `32763:9870`         | `/mnt/hadoop/namenode:/data/hdfs/name`    | `CLUSTER_NAME: hadoop_cluster`  | 1            | `nc -z localhost 9870`                                    |
| **Configura√ß√£o Hadoop** | **Datanode**            | `iamgacarvalho/hadoop-datanode-data-in-compass:2.0.0`        | `9854-9864:9864`     | `/mnt/hadoop/datanode:/data/hdfs/data`    | `SERVICE_PRECONDITION: namenode:9870` | 1            | `nc -z localhost 9864`                                    |
| **Configura√ß√£o Hadoop** | **History Server**      | `iamgacarvalho/hadoop-historyserver-data-in-compass:2.0.0`   | `8188:8188`          | -                                         | `SERVICE_PRECONDITION: namenode:9870` | 1            | `nc -z localhost 8188`                                    |
| **Configura√ß√£o Hadoop** | **Resource Manager**    | `iamgacarvalho/hadoop-resourcemanager-data-in-compass:2.0.0` | `8088:8088`          | -                                         | `SERVICE_PRECONDITION: namenode:9870` | 1            | `nc -z localhost 8088`                                    |
| **Configura√ß√£o Hadoop** | **Node Manager**        | `iamgacarvalho/hadoop-nodemanager-data-in-compass:2.0.0`     | `8032-8042:8042`     | -                                         | `SERVICE_PRECONDITION: namenode:9870` | 3            | `nc -z localhost 8042`                                    |
| **Configura√ß√£o Spark**  | **Spark Master**        | `iamgacarvalho/spark-master-data-in-compass:3.0.0`           | `8084:8082`<br>`7077:7077` | `/mnt/spark/apps:/opt/spark-apps`<br>`/mnt/spark/data:/opt/spark-data` | -                             | 1            | `nc -z localhost 8082`                                    |
| **Configura√ß√£o Spark**  | **Spark Worker**        | `iamgacarvalho/spark-worker-data-in-compass:3.0.0`           | `8090-8100:8081`     | `/mnt/spark/apps:/opt/spark-apps`<br>`/mnt/spark/data:/opt/spark-data`<br>`/mnt/spark/worker-logs:/opt/spark/logs` | `WORKER_PORT=8081`            | 2            | `nc -z localhost 8081`                                    |
| **Configura√ß√£o Grafana**  | **Grafana**            | `grafana/grafana:latest`                                     | `4000:3000`          | `/mnt/grafana_data:/var/lib/grafana`      | `GF_SECURITY_ADMIN_USER=admin`<br>`GF_SECURITY_ADMIN_PASSWORD=admin123`<br>`GF_INSTALL_PLUGINS=grafana-mongodb-datasource`<br>`GF_PLUGINS_PREINSTALL=grafana-clock-panel` | 2            | N√£o configurado, mas a disponibilidade pode ser verificada pela porta `3000` |
| **Configura√ß√£o Elastic**  | **Elasticsearch**       | `docker.elastic.co/elasticsearch/elasticsearch:8.16.1`       | `9200:9200`<br>`9300:9300` | `/mnt/es_data:/usr/share/elasticsearch/data`<br>`/mnt/certs:/usr/share/elasticsearch/config/certs` | `ES_JAVA_OPTS=-Xms4g -Xmx4g`<br>`ELASTIC_PASSWORD=data-@a1`<br>`xpack.security.enabled=true`<br>`xpack.security.transport.ssl.key=/usr/share/elasticsearch/config/certs/es-node.key`<br>`xpack.security.transport.ssl.certificate=/usr/share/elasticsearch/config/certs/es-node.crt`<br>`xpack.security.transport.ssl.certificate_authorities=/usr/share/elasticsearch/config/certs/ca.crt` | 1            | N√£o configurado, mas pode ser monitorado na porta `9200` |
| **Configura√ß√£o Kibana**  | **Kibana**             | `docker.elastic.co/kibana/kibana:8.16.1`                    | `5601:5601`          | -                                         | `ELASTICSEARCH_HOSTS=http://elasticsearch:9200`<br>`ELASTICSEARCH_USERNAME=kibana_user_service`<br>`ELASTICSEARCH_PASSWORD=data-@a1`<br>`XPACK_SECURITY_ENCRYPTIONKEY=eqyW5iPqa8ghok7RqY7eFluG+dqvXBczFEU+HhlDLFM=`<br>`XPACK_ENCRYPTEDSAVEDOBJECTS_ENCRYPTIONKEY=eqyW5iPqa8ghok7RqY7eFluG+dqvXBczFEU+HhlDLFM=`<br>`XPACK_REPORTING_ENCRYPTIONKEY=eqyW5iPqa8ghok7RqY7eFluG+dqvXBczFEU+HhlDLFM=` | 1            | `curl -f http://localhost:5601` (intervalo: 30s, 3 tentativas) |
| **Configura√ß√£o MongoDB**  | **MongoDB**             | `mongo:7`                                                    | `27017:27017`        | `/mnt/mongodb:/data/db`<br>`/mnt/mongodb_configData:/data/configdb`<br>`/mnt/mongodb_init/init-mongo.js:/docker-entrypoint-initdb.d/init-mongo.js` | `MONGO_INITDB_ROOT_USERNAME=${MONGO_USER_ADMIN}`<br>`MONGO_INITDB_ROOT_PASSWORD=${MONGO_PASS_ADMIN}` | 1            | N√£o configurado, mas pode ser monitorado na porta `27017` |
| **Configura√ß√£o Metabase**  | **Metabase**            | `metabase/metabase:latest`                                    | `8085:3000`          | `/mnt/metabase:/metabase.db`             | `MB_PASSWORD_RESET=true`      | 1            | N√£o configurado, mas pode ser monitorado na porta `3000` |

---

**Configura√ß√£o de Rede:** A infraestrutura utiliza uma rede **overlay externa** para comunica√ß√£o entre os cont√™ineres:

```yaml
networks:
  hadoop_network:
    external: true
    driver: overlay
```

**Persist√™ncia de Dados:** Volumes persistentes para o Namenode e Datanode:

```yaml
volumes:
  infra-namenode:
  infra-datanode:
  infra-spark-master:
  infra-spark-worker:
  infra-spark-worker-logs:
  grafana_data:
  elasticsearch_yml:
  certs:
  es_data:
  mongodb_data:
  mongodb_configdb_data:
  business-metabase:
```
> [!IMPORTANT]
> YAML do Docker Swarm das tecnologias citadas acima: [Arquivos YAML no reposit√≥rio](https://github.com/gacarvalho/compass-deployment/tree/compass/infra-3.0.0/services/batch_layer)


#### 3.2.2.2 **Aplica√ß√µes do Projeto Compass**

As aplica√ß√µes respons√°veis por realizar as ingest√µes, transforma√ß√µes e carga das informa√ß√µes est√£o desenvolvidas na tecnologia Apache Spark voltadas para arquitetura Batch. O Apache Spark foi escolhido devido √† sua alta performance e escalabilidade, caracter√≠sticas essenciais para lidar com grandes volumes de dados no ambiente do Projeto Compass. 

A arquitetura Batch foi escolhida para garantir alta confiabilidade, escalabilidade e efici√™ncia no processamento de grandes volumes de dados, executando em um schedule di√°rio. Embora o processamento em tempo real (Streaming) seja uma alternativa vi√°vel para outros cen√°rios, o foco do projeto √© consolidar dados de forma estruturada, assegurando a consist√™ncia necess√°ria para que os times de neg√≥cios possam acompanhar e analisar as necessidades e desafios dos clientes de forma precisa e estrat√©gica.

> [!IMPORTANT]
> Para acessar os reposit√≥rios das aplica√ß√µes abaixo, favor entrar em contato para libera√ß√£o do acesso ao reposit√≥rio!

‚ô®Ô∏è **Aplica√ß√µes - Ingest√µes de dados**

As aplica√ß√µes para ingest√µes de dados foram desenvolvidas para realizar captura de informa√ß√µes em 2 ambientes, um deles √© o ambiente interno do Banco Santander, j√° o outro ambiente √© externo, obtendo informa√ß√µes de duas APIs distintas. 

---

`üì¶ artefato` `iamgacarvalho/dmc-app-ingestion-reviews-mongodb-hdfs-compass`
<details>
  <summary>Informa√ß√µes detalhada do artefato iamgacarvalho/dmc-app-ingestion-reviews-mongodb-hdfs-compass </summary> 
  
  - **Vers√£o:** `1.0.1`
  - **Reposit√≥rio:** [GitHub](https://github.com/gacarvalho/mongodb/)  
  - **Imagem Docker:** [Docker Hub](https://hub.docker.com/repository/docker/iamgacarvalho/dmc-app-ingestion-reviews-mongodb-hdfs-compass/tags/1.0.1/sha256-4b406055b4cabd7b2b2e5395eb6f7f1062f104f8080a2bef5d25f2c350bdf43f)  
  - **Descri√ß√£o:**  Coleta avalia√ß√µes de clientes do Banco Santander armazenadas no **MongoDB**, processa os dados e os armazena no **HDFS** em formato **Parquet**.
  - **Par√¢metros:** 

    ```shell
      /app/repo_extc_mongodb.py $CONFIG_ENV $PARAM1 $PARAM2 $PARAM3
    ```

      - `$CONFIG_ENV` (`Pre`, `Pro`) ‚Üí Define o ambiente: `Pre` (Pr√©-Produ√ß√£o), `Pro` (Produ√ß√£o).
      - `$PARAM1` (`nome-do-canal-ou-app`). ‚Üí Nome do canal/app no MongoDB. Para novos, use h√≠fen (-).
      - `$PARAM2` (`pf`,`pj`). ‚Üí Indicador do segmento do cliente. `PF` (Pessoa F√≠sica), `PJ` (Pessoa Juridica)
</details>

---

`üì¶ artefato` `iamgacarvalho/dmc-app-ingestion-reviews-apple-store-hdfs-compass` 
<details>
  <summary>Informa√ß√µes detalhada do artefato iamgacarvalho/dmc-app-ingestion-reviews-apple-store-hdfs-compass </summary> 
  
  - **Vers√£o:** `1.0.1`
  - **Reposit√≥rio:** [GitHub](https://github.com/gacarvalho/apple-store)  
  - **Imagem Docker:** [Docker Hub](https://hub.docker.com/repository/docker/iamgacarvalho/dmc-app-ingestion-reviews-apple-store-hdfs-compass/tags/1.0.1/sha256-8a038d0998e0cb11267936b87cb277f10dc210a928571feb14ccba20c8cd807b)  
  - **Descri√ß√£o:**  Coleta avalia√ß√µes de clientes nos canais via API do Itunes na **Apple Store**, realizando a ingest√£o e os armazenando no **HDFS** em formato **Parquet**.
  - **Par√¢metros:** 

    ```shell
      /app/repo_extc_apple_store.py $CONFIG_ENV $PARAM1 $PARAM2 $PARAM3
    ```

      - `$CONFIG_ENV` (`Pre`, `Pro`) ‚Üí Define o ambiente: `Pre` (Pr√©-Produ√ß√£o), `Pro` (Produ√ß√£o).
      - `$PARAM1` (`id-review-localizado-na-url-do-app`). ‚Üí Identificado (n√∫mero) do aplicativo na Apple Store, podendo ser localizado na URL da loja Apple Store, exemplo: `https://apps.apple.com/br/app/santander-way/id1154266372`, nesse caso, o ID que vai no parametro √©: `1154266372`.
      - `$PARAM2` (`nome-do-canal-ou-app`). ‚Üí Nome do canal/app na Apple Store. Para novos, use h√≠fen (-).
      - `$PARAM3` (`pf`,`pj`). ‚Üí Indicador do segmento do cliente. `PF` (Pessoa F√≠sica), `PJ` (Pessoa Juridica)

</details>

---

`üì¶ artefato` `iamgacarvalho/dmc-app-ingestion-reviews-google-play-hdfs-compass` 
<details>
  <summary>Informa√ß√µes detalhada do artefato iamgacarvalho/dmc-app-ingestion-reviews-google-play-hdfs-compass </summary> 
  
  - **Vers√£o:** `1.0.1`
  - **Reposit√≥rio:** [GitHub](https://github.com/gacarvalho/google-play)  
  - **Imagem Docker:** [Docker Hub](https://hub.docker.com/repository/docker/iamgacarvalho/dmc-app-ingestion-reviews-google-play-hdfs-compass/tags/1.0.1/sha256-df992cb185f7a17ed0d40306e91d50139553e17e5c2a4d900579a0d42b804d9e)  
  - **Descri√ß√£o:**  Coleta avalia√ß√µes de clientes do Banco Santander armazenadas no  **Google Play**, processa os dados e os armazena no **HDFS** em formato **Parquet**.
  - **Par√¢metros:** 

    ```shell
      /app/repo_extc_google_play.py $CONFIG_ENV $PARAM1 $PARAM2 $PARAM3
    ```

      - `$CONFIG_ENV` (`Pre`, `Pro`) ‚Üí Define o ambiente: `Pre` (Pr√©-Produ√ß√£o), `Pro` (Produ√ß√£o).
      - `$PARAM1` (`name-review-localizado-na-url-do-app`). ‚Üí Identificado (string) do aplicativo do Google Play, podendo ser localizado na URL na loja do Google Play, exemplo: `https://play.google.com/store/apps/details?id=br.com.santander.way&hl=pt_BR&pli=1`, nesse caso, o ID que vai no parametro √©: `br.com.santander.way`.
      - `$PARAM2` (`nome-do-canal-ou-app`). ‚Üí Nome do canal/app no Google Play. Para novos, use h√≠fen (-).
      - `$PARAM3` (`pf`,`pj`). ‚Üí Indicador do segmento do cliente. `PF` (Pessoa F√≠sica), `PJ` (Pessoa Juridica)

</details>

---

‚ô®Ô∏è **Aplica√ß√µes - Transforma√ß√µes de dados**

As aplica√ß√µes respons√°veis pela transforma√ß√£o dos dados realizar√£o a leitura conforme a fonte de extra√ß√£o. No caso do motor que alimenta a silver da Apple Store, ele processar√° apenas as ingest√µes relacionadas a essa plataforma. Por exemplo, suponha que haja 15 aplicativos sendo ingeridos e armazenados na bronze, 5 aplicativos da Apple Store, 5 provenientes do MongoDB (base interna) e 5 do Google Play. Nesse cen√°rio, a silver da Apple Store consumir√° exclusivamente os dados ingeridos da Apple Store, garantindo que apenas informa√ß√µes relevantes dessa fonte sejam processadas. 

`üì¶ artefato` `iamgacarvalho/dmc-app-silver-reviews-apple-store` 
<details>
  <summary>Informa√ß√µes detalhada do artefato iamgacarvalho/dmc-app-silver-reviews-apple-store </summary> 

  - **Vers√£o:** `1.0.1`
  - **Reposit√≥rio:** [GitHub](https://github.com/gacarvalho/apple-store-processing-historical)  
  - **Imagem Docker:** [Docker Hub](https://hub.docker.com/repository/docker/iamgacarvalho/dmc-app-silver-reviews-apple-store/tags/1.0.1/sha256-a35d88d3c69b78abcecfff0a53906201fab48bdd8b2e5579057e935f58b6fe41)  
  - **Descri√ß√£o:**  Coleta avalia√ß√µes de clientes nos canais via API do Itunes na **Apple Store** ingeridos no Data Lake, realizando a ingest√£o a partir da camada Bronze, processando e aplicando tratamento de dados e armazenando no **HDFS** em formato **Parquet**.

  - **Par√¢metros:** 
    ```shell
      /app/repo_trfmation_apple_store.py $CONFIG_ENV 
    ```
      - `$CONFIG_ENV` (`Pre`, `Pro`) ‚Üí Define o ambiente: `Pre` (Pr√©-Produ√ß√£o), `Pro` (Produ√ß√£o).
  - **Pipeline:**
    - **Descri√ß√£o:** Processar avalia√ß√µes de clientes da Apple Store (camada Bronze ‚Üí Silver), garantindo: filtro espec√≠fico para dados Apple Store, normaliza√ß√£o e enriquecimento de metadados, valida√ß√£o de qualidade conforme regras de neg√≥cio e rastreabilidade completa dos dados
    - **Fonte de Dados:** <br> `/santander/bronze/compass/reviews/appleStore/*_pf` 
                          <br> `/santander/bronze/compass/reviews/appleStore/*_pj`
                          <br> `/santander/silver/compass/reviews/appleStore/`
    - **Filtro:** Apenas dados com appleStore no path e terminados em _pf ou _pj.                   
    - **Destino:** `/santander/silver/compass/reviews/appleStore/` 
    - **Tipo de processo:** Batch (di√°rio)

  - **Fluxo de Dados:**
    - **Extra√ß√£o:** Leitura de dados PF/PJ particionados por data de carga `odate` em Parquet
    - **Transforma√ß√£o e Fun√ß√µes:** PySpark <br> 
      1.  `remove_accents(s)`: Remove acentos de uma string, utilizando a biblioteca unidecode. Esta fun√ß√£o √© registrada como uma UDF (User Defined Function) no Spark para ser aplicada em colunas de DataFrames. **Par√¢metros:** `s` (str): A string da qual os acentos ser√£o removidos. **Retorno:** (str): A string sem acentos.

        ```python
        remove_accents(s: str) -> str
        ```

        No exemplo abaixo √© poss√≠vel ver como a funcionalidade se aplica em um caso real:

        ```python
        Exemplo: remove_accents("S√£o Paulo") # Retorna: "Sao Paulo"
        ```

      2.  `processing_reviews(df: DataFrame)`: Realiza transforma√ß√µes no DataFrame de reviews, selecionando colunas espec√≠ficas, converte nomes para mai√∫sculas e removendo acentos. Renomeia colunas para um formato consistente. **Par√¢metros:** `df` (DataFrame): O DataFrame de reviews a ser processado. **Retorno:** (DataFrame): O DataFrame transformado.

          ```python
          processed_df = processing_reviews(df)
          processed_df.show()
          ```

      3.  `get_schema(df, schema)`: Assegura que o DataFrame esteja em conformidade com um esquema predefinido, convertendo os tipos das colunas para os tipos especificados no esquema. **Par√¢metros:** `df` (DataFrame): O DataFrame a ser ajustado. `schema` (StructType): O esquema de destino. **Retorno:** (DataFrame): O DataFrame em conformidade com o esquema.

          ```python
          aligned_df = get_schema(df, schema)
          aligned_df.printSchema()
          ```

      4.  `processing_old_new(spark: SparkSession, df: DataFrame)`: Compara os dados de reviews novos com os dados hist√≥ricos, identificando e registrando mudan√ßas nas avalia√ß√µes ao longo do tempo. Cria uma coluna chamada `historical_data` para armazenar o hist√≥rico de mudan√ßas. **Par√¢metros:** `spark` (SparkSession): A sess√£o Spark ativa. `df` (DataFrame): O DataFrame com os novos dados de reviews. **Retorno:** (DataFrame): O DataFrame com o hist√≥rico de mudan√ßas.

          ```python
          historical_df = processing_old_new(spark, df)
          historical_df.show()
          ```

      5.  `read_source_parquet(spark, path)`: L√™ um arquivo Parquet do caminho especificado, extraindo informa√ß√µes de "app" e "segmento" do nome do arquivo. Retorna `None` se o arquivo n√£o existir ou se n√£o houver dados. **Par√¢metros:** `spark` (SparkSession): A sess√£o Spark ativa. `path` (str): O caminho para o arquivo Parquet. **Retorno:** (DataFrame | None): O DataFrame lido ou `None` em caso de falha.

          ```python
          source_df = read_source_parquet(spark, file_path)
          if source_df:
              source_df.show()
          ```

      6.  `save_dataframe(df, path, label)`: Salva um DataFrame no formato Parquet no caminho especificado. Verifica se o DataFrame possui dados antes de salvar, e caso n√£o possua, envia um log de warning. Verifica e cria o diret√≥rio de destino se necess√°rio. Lida com poss√≠veis erros durante o processo de salvamento. **Par√¢metros:** `df` (DataFrame): O DataFrame a ser salvo. `path` (str): O caminho para salvar o DataFrame. `label` (str): Uma etiqueta para os logs. **Retorno:** None.

          ```python
          save_dataframe(df, save_path, data_label)
          ```

      7.  `path_exists() -> bool`: Verifica se um determinado caminho existe no HDFS. Verifica se o caminho possui parti√ß√µes no formato "odate=\*". **Retorno:** (bool): True caso o caminho exista, e false caso n√£o exista.

          ```python
          if path_exists():
              print("O caminho existe")
          else:
              print("O caminho n√£o existe")
          ```

      8.  `save_metrics(metrics_json, df)`: Salva m√©tricas no Elasticsearch. Conecta-se ao Elasticsearch usando vari√°veis de ambiente. Lida com erros de decodifica√ß√£o JSON e erros de conex√£o. **Par√¢metros:** `metrics_json` (str): As m√©tricas no formato JSON. `df` (DataFrame): O DataFrame associado √†s m√©tricas. **Retorno:** None.

          ```python
          save_metrics(metrics, data_df)
          ```

      9.  `save_metrics_job_fail(metrics_json)`: Salva m√©tricas de falhas de jobs no Elasticsearch. Similar a `save_metrics`, mas para um √≠ndice diferente. **Par√¢metros:** `metrics_json` (str): As m√©tricas de falha no formato JSON. **Retorno:** None.

          ```python
          save_metrics_job_fail(failure_metrics)
          ```

      10. `log_error(e, df)`: Gera e salva m√©tricas de erro no Elasticsearch. Extrai informa√ß√µes de segmento do DataFrame. Formata informa√ß√µes de erro e as envia para `save_metrics_job_fail`. **Par√¢metros:** `e` (Exception): A exce√ß√£o que ocorreu. `df` (DataFrame): O DataFrame associado ao erro. **Retorno:** None.

          ```python
          try:
              # C√≥digo que pode gerar um erro
          except Exception as error:
              log_error(error, df)
          ```

    - **Valida√ß√£o:** 
    
        1.  `validate_ingest(spark: SparkSession, df: DataFrame) -> tuple`: Valida dados de ingest√£o, comparando com hist√≥rico e verificando qualidade. **Retorna** DataFrames de dados v√°lidos e inv√°lidos, e resultados da valida√ß√£o. 
    
            - **Duplicatas:** Identifica registros duplicados por "id".
            - **Nulos:** Verifica nulos em colunas cr√≠ticas.
            - **Tipos:** Garante consist√™ncia de tipos.

            C√≥digo de retorno na valida√ß√£o:

            > `200`: Sucesso (Nenhum problema encontrado) <br>
            > `400`: Erro nos dados (Valores nulos ou tipos inv√°lidos) <br>
            > `409`: Conflito de dados (Registros duplicados encontrados)



    - **Carga:** Escrita em HDFS (Parquet):
    
      1. Caminho principal (dados v√°lidos) `/santander/silver/compass/reviews/appleStore/odate={datePath}/` 
      2. Caminho de falha `/santander/silver/compass/reviews_fail/appleStore/odate={datePath}/`

    - **M√©tricas:** A fun√ß√£o `collect_metrics` coleta um conjunto abrangente de m√©tricas para fornecer uma vis√£o detalhada do processo de ingest√£o e valida√ß√£o de dados. As m√©tricas s√£o estruturadas em um objeto JSON, facilitando o consumo por sistemas de monitoramento e an√°lise.


      * **Informa√ß√µes da Aplica√ß√£o:**
          * `application_id`: Identificador √∫nico da aplica√ß√£o Spark.
          * `owner`: Detalhes do propriet√°rio da aplica√ß√£o (sigla, projeto, camada do Lake).
          * `source`: Detalhes sobre a fonte dos dados (`app`, `search`).
      * **Contagem de Registros:**
          * `valid_data`: Contagem e porcentagem de registros v√°lidos.
          * `invalid_data`: Contagem e porcentagem de registros inv√°lidos.
          * `total_records`: Contagem total de registros processados.
      * **Desempenho do Processamento:**
          * `total_processing_time`: Tempo total de processamento em minutos.
          * `memory_used`: Uso de mem√≥ria em megabytes.
          * `stages`: M√©tricas detalhadas dos est√°gios de execu√ß√£o do Spark.
      * **Resultados da Valida√ß√£o:**
          * `validation_results`: Resultados detalhados de cada valida√ß√£o (duplicatas, nulos, tipos).
          * `success_count`: N√∫mero de valida√ß√µes bem-sucedidas.
          * `error_count`: N√∫mero de valida√ß√µes com erros.
          * `type_client`: Lista de segmentos √∫nicos dos clientes.
      * **Timestamps:**
          * `_ts`: Timestamps de in√≠cio e t√©rmino do processamento.
          * `timestamp`: Timestamp da gera√ß√£o das m√©tricas.

      **Formato do JSON:**

      As m√©tricas s√£o estruturadas em um objeto JSON com a seguinte estrutura geral:

      ```json
      {
        "application_id": "...",
        "owner": {
          "sigla": "...",
          "projeto": "...",
          "layer_lake": "..."
        },
        "valid_data": {
          "count": ...,
          "percentage": ...
        },
        "invalid_data": {
          "count": ...,
          "percentage": ...
        },
        "total_records": ...,
        "total_processing_time": "...",
        "memory_used": ...,
        "stages": { ... },
        "validation_results": { ... },
        "success_count": ...,
        "error_count": ...,
        "type_client": "...",
        "source": {
          "app": "...",
          "search": "..."
        },
        "_ts": {
          "compass_start_ts": "...",
          "compass_end_ts": "..."
        },
        "timestamp": "..."
      }
      ```

  Este JSON pode ser utilizado para monitorar o desempenho do pipeline de dados, identificar problemas de qualidade de dados e otimizar o processo de ingest√£o. J√° para as falhas o JSON √© estruturado e enviado para o indice no Elastic Search de aplica√ß√µes com falhas.

  * **Informa√ß√µes do erro:**
    * `timestamp`: Timestamp da gera√ß√£o das m√©tricas.
    * `layer`: Camada referencia onde ocorreu o erro.
    * `project`: Projeto respons√°vel pela aplica√ß√£o com erro.
    * `job`: Job do pipeline que est√° em execu√ß√£o e que falhou.
    * `priority`: Prioridade do erro, quanto menor, mais impacto no pipeline e na vis√£o cliente, considera que de 0 a 2 √© o imapacto cr√≠tico, superior a isso, h√° impacto mas o fluxo segue normal. Exemplo: `Falha de 0-2` -> Erro ao capturar dados da API ou erro ao gravar no path destino.  `Falha de 3-4` -> Erro ao enviar as m√©tricas.
    * `tower`: Torre da sigla respons√°vel pelo alerta.
    * `client`: Segmento impactado, considerando PF (pessoa f√≠sica) e/ou PJ (pessoa juridica).
    * `error`: log do erro da aplica√ß√£o.
            

      ```json
        {
            "timestamp": "...",
            "layer": "silver",
            "project": "compass",
            "job": "google_play_reviews",
            "priority": "0",
            "tower": "SBBR_COMPASS",
            "client": "[...]",
            "error": "..."
        }
      ```

</details>

---

`üì¶ artefato` `iamgacarvalho/dmc-app-silver-reviews-google-play` 
<details>
  <summary>Informa√ß√µes detalhada do artefato iamgacarvalho/dmc-app-silver-reviews-google-play </summary> 
  
  - **Vers√£o:** `1.0.1`
  - **Reposit√≥rio:** [GitHub](https://github.com/gacarvalho/google-play-processing-historical)  
  - **Imagem Docker:** [Docker Hub](https://hub.docker.com/repository/docker/iamgacarvalho/dmc-app-silver-reviews-google-play/tags/1.0.1/sha256-3b68861761c0059f6ecb60253086b0f9bef78fa079ea8e5b1a5f44b9da82b252)  
  - **Descri√ß√£o:**  Coleta avalia√ß√µes de clientes nos canais via API SERAPI que se origina do **Google Play** que foi ingerido no Data Lake, realizando a ingest√£o a partir da camada Bronze, processando e aplicando tratamento de dados e armazenando no HDFS em formato Parquet.

  - **Par√¢metros:** 
    ```shell
      /app/repo_trfmation_google_play.py.py $CONFIG_ENV 
    ```
      - `$CONFIG_ENV` (`Pre`, `Pro`) ‚Üí Define o ambiente: `Pre` (Pr√©-Produ√ß√£o), `Pro` (Produ√ß√£o).
  - **Pipeline:**
    - **Descri√ß√£o:** Processar avalia√ß√µes de clientes dao Google Play (camada Bronze ‚Üí Silver), garantindo: filtro espec√≠fico para dados Google Play, normaliza√ß√£o e enriquecimento de metadados, valida√ß√£o de qualidade conforme regras de neg√≥cio e rastreabilidade completa dos dados
    - **Fonte de Dados:** <br> `/santander/bronze/compass/reviews/googlePlay/*_pf` 
                          <br> `/santander/bronze/compass/reviews/googlePlay/*_pj`
                          <br> `/santander/silver/compass/reviews/googlePlay/`
    - **Filtro:** Apenas dados com google Play no path e terminados em _pf ou _pj.                   
    - **Destino:** `/santander/silver/compass/reviews/googlePlay/` 
    - **Tipo de processo:** Batch (di√°rio)

  - **Fluxo de Dados:**
    - **Extra√ß√£o:** Leitura de dados PF/PJ particionados por data de carga `odate` em Parquet
    - **Transforma√ß√£o e Fun√ß√µes:** PySpark <br> 
      1.  `remove_accents(s)`: Remove acentos de uma string, utilizando a biblioteca unidecode. Esta fun√ß√£o √© registrada como uma UDF (User Defined Function) no Spark para ser aplicada em colunas de DataFrames. **Par√¢metros:** `s` (str): A string da qual os acentos ser√£o removidos. **Retorno:** (str): A string sem acentos.

        ```python
        remove_accents(s: str) -> str
        ```

        No exemplo abaixo √© poss√≠vel ver como a funcionalidade se aplica em um caso real:

        ```python
        Exemplo: remove_accents("S√£o Paulo") # Retorna: "Sao Paulo"
        ```

      2.  `processing_reviews(df: DataFrame)`: Realiza transforma√ß√µes no DataFrame de reviews, selecionando colunas espec√≠ficas, converte nomes para mai√∫sculas e removendo acentos. Renomeia colunas para um formato consistente. **Par√¢metros:** `df` (DataFrame): O DataFrame de reviews a ser processado. **Retorno:** (DataFrame): O DataFrame transformado.

          ```python
          processed_df = processing_reviews(df)
          processed_df.show()
          ```

      3.  `get_schema(df, schema)`: Assegura que o DataFrame esteja em conformidade com um esquema predefinido, convertendo os tipos das colunas para os tipos especificados no esquema. **Par√¢metros:** `df` (DataFrame): O DataFrame a ser ajustado. `schema` (StructType): O esquema de destino. **Retorno:** (DataFrame): O DataFrame em conformidade com o esquema.

          ```python
          aligned_df = get_schema(df, schema)
          aligned_df.printSchema()
          ```

      4.  `processing_old_new(spark: SparkSession, df: DataFrame)`: Compara os dados de reviews novos com os dados hist√≥ricos, identificando e registrando mudan√ßas nas avalia√ß√µes ao longo do tempo. Cria uma coluna chamada `historical_data` para armazenar o hist√≥rico de mudan√ßas. **Par√¢metros:** `spark` (SparkSession): A sess√£o Spark ativa. `df` (DataFrame): O DataFrame com os novos dados de reviews. **Retorno:** (DataFrame): O DataFrame com o hist√≥rico de mudan√ßas.

          ```python
          historical_df = processing_old_new(spark, df)
          historical_df.show()
          ```

      5.  `read_source_parquet(spark, path)`: L√™ um arquivo Parquet do caminho especificado, extraindo informa√ß√µes de "app" e "segmento" do nome do arquivo. Retorna `None` se o arquivo n√£o existir ou se n√£o houver dados. **Par√¢metros:** `spark` (SparkSession): A sess√£o Spark ativa. `path` (str): O caminho para o arquivo Parquet. **Retorno:** (DataFrame | None): O DataFrame lido ou `None` em caso de falha.

          ```python
          source_df = read_source_parquet(spark, file_path)
          if source_df:
              source_df.show()
          ```

      6.  `save_dataframe(df, path, label)`: Salva um DataFrame no formato Parquet no caminho especificado. Verifica se o DataFrame possui dados antes de salvar, e caso n√£o possua, envia um log de warning. Verifica e cria o diret√≥rio de destino se necess√°rio. Lida com poss√≠veis erros durante o processo de salvamento. Um tratamento adicional que a fun√ß√£o realiza √© verificar se o dataframe tem a coluna `historical_data`, se n√£o tiver, a fun√ß√£o cria a coluna com o schema correto com dado nulo.
      ```python
        if "historical_data" not in df.columns:
            df = df.withColumn(
                "historical_data",
                lit(None).cast("array<struct<title:string,snippet:string,app:string,rating:string,iso_date:string>>")
            )
      ```
      
      **Par√¢metros:** `df` (DataFrame): O DataFrame a ser salvo. `path` (str): O caminho para salvar o DataFrame. `label` (str): Uma etiqueta para os logs. **Retorno:** None.

          ```python
          save_dataframe(df, save_path, data_label)
          ```

      7.  `path_exists() -> bool`: Verifica se um determinado caminho existe no HDFS. Verifica se o caminho possui parti√ß√µes no formato "odate=\*". **Retorno:** (bool): True caso o caminho exista, e false caso n√£o exista.

          ```python
          if path_exists():
              print("O caminho existe")
          else:
              print("O caminho n√£o existe")
          ```

      8.  `save_metrics(metrics_json, df)`: Salva m√©tricas no Elasticsearch. Conecta-se ao Elasticsearch usando vari√°veis de ambiente. Lida com erros de decodifica√ß√£o JSON e erros de conex√£o. **Par√¢metros:** `metrics_json` (str): As m√©tricas no formato JSON. `df` (DataFrame): O DataFrame associado √†s m√©tricas. **Retorno:** None.

          ```python
          save_metrics(metrics, data_df)
          ```

      9.  `save_metrics_job_fail(metrics_json)`: Salva m√©tricas de falhas de jobs no Elasticsearch. Similar a `save_metrics`, mas para um √≠ndice diferente. **Par√¢metros:** `metrics_json` (str): As m√©tricas de falha no formato JSON. **Retorno:** None.

          ```python
          save_metrics_job_fail(failure_metrics)
          ```

      10. `log_error(e, df)`: Gera e salva m√©tricas de erro no Elasticsearch. Extrai informa√ß√µes de segmento do DataFrame. Formata informa√ß√µes de erro e as envia para `save_metrics_job_fail`. **Par√¢metros:** `e` (Exception): A exce√ß√£o que ocorreu. `df` (DataFrame): O DataFrame associado ao erro. **Retorno:** None.

          ```python
          try:
              # C√≥digo que pode gerar um erro
          except Exception as error:
              log_error(error, df)
          ```

    - **Valida√ß√£o:** 
    
        1.  `validate_ingest(spark: SparkSession, df: DataFrame) -> tuple`: Valida dados de ingest√£o, comparando com hist√≥rico e verificando qualidade. **Retorna** DataFrames de dados v√°lidos e inv√°lidos, e resultados da valida√ß√£o. 
    
            - **Duplicatas:** Identifica registros duplicados por "id".
            - **Nulos:** Verifica nulos em colunas cr√≠ticas.
            - **Tipos:** Garante consist√™ncia de tipos.

            C√≥digo de retorno na valida√ß√£o:

            > `200`: Sucesso (Nenhum problema encontrado) <br>
            > `400`: Erro nos dados (Valores nulos ou tipos inv√°lidos) <br>
            > `409`: Conflito de dados (Registros duplicados encontrados)



    - **Carga:** Escrita em HDFS (Parquet):
    
      1. Caminho principal (dados v√°lidos) `/santander/silver/compass/reviews/googlePlay/odate={datePath}/` 
      2. Caminho de falha `/santander/silver/compass/reviews_fail/googlePlay/odate={datePath}/`

    - **M√©tricas:** A fun√ß√£o `collect_metrics` coleta um conjunto abrangente de m√©tricas para fornecer uma vis√£o detalhada do processo de ingest√£o e valida√ß√£o de dados. As m√©tricas s√£o estruturadas em um objeto JSON, facilitando o consumo por sistemas de monitoramento e an√°lise.


      * **Informa√ß√µes da Aplica√ß√£o:**
          * `application_id`: Identificador √∫nico da aplica√ß√£o Spark.
          * `owner`: Detalhes do propriet√°rio da aplica√ß√£o (sigla, projeto, camada do Lake).
          * `source`: Detalhes sobre a fonte dos dados (`app`, `search`).
      * **Contagem de Registros:**
          * `valid_data`: Contagem e porcentagem de registros v√°lidos.
          * `invalid_data`: Contagem e porcentagem de registros inv√°lidos.
          * `total_records`: Contagem total de registros processados.
      * **Desempenho do Processamento:**
          * `total_processing_time`: Tempo total de processamento em minutos.
          * `memory_used`: Uso de mem√≥ria em megabytes.
          * `stages`: M√©tricas detalhadas dos est√°gios de execu√ß√£o do Spark.
      * **Resultados da Valida√ß√£o:**
          * `validation_results`: Resultados detalhados de cada valida√ß√£o (duplicatas, nulos, tipos).
          * `success_count`: N√∫mero de valida√ß√µes bem-sucedidas.
          * `error_count`: N√∫mero de valida√ß√µes com erros.
          * `type_client`: Lista de segmentos √∫nicos dos clientes.
      * **Timestamps:**
          * `_ts`: Timestamps de in√≠cio e t√©rmino do processamento.
          * `timestamp`: Timestamp da gera√ß√£o das m√©tricas.

      **Formato do JSON:**

      As m√©tricas s√£o estruturadas em um objeto JSON com a seguinte estrutura geral:

      ```json
      {
        "application_id": "...",
        "owner": {
          "sigla": "...",
          "projeto": "...",
          "layer_lake": "..."
        },
        "valid_data": {
          "count": ...,
          "percentage": ...
        },
        "invalid_data": {
          "count": ...,
          "percentage": ...
        },
        "total_records": ...,
        "total_processing_time": "...",
        "memory_used": ...,
        "stages": { ... },
        "validation_results": { ... },
        "success_count": ...,
        "error_count": ...,
        "type_client": "...",
        "source": {
          "app": "...",
          "search": "..."
        },
        "_ts": {
          "compass_start_ts": "...",
          "compass_end_ts": "..."
        },
        "timestamp": "..."
      }
      ```

    Este JSON pode ser utilizado para monitorar o desempenho do pipeline de dados, identificar problemas de qualidade de dados e otimizar o processo de ingest√£o. J√° para as falhas o JSON √© estruturado e enviado para o indice no Elastic Search de aplica√ß√µes com falhas.

      * **Informa√ß√µes do erro:**
        * `timestamp`: Timestamp da gera√ß√£o das m√©tricas.
        * `layer`: Camada referencia onde ocorreu o erro.
        * `project`: Projeto respons√°vel pela aplica√ß√£o com erro.
        * `job`: Job do pipeline que est√° em execu√ß√£o e que falhou.
        * `priority`: Prioridade do erro, quanto menor, mais impacto no pipeline e na vis√£o cliente, considera que de 0 a 2 √© o imapacto cr√≠tico, superior a isso, h√° impacto mas o fluxo segue normal. Exemplo: `Falha de 0-2` -> Erro ao capturar dados da API ou erro ao gravar no path destino.  `Falha de 3-4` -> Erro ao enviar as m√©tricas.
        * `tower`: Torre da sigla respons√°vel pelo alerta.
        * `client`: Segmento impactado, considerando PF (pessoa f√≠sica) e/ou PJ (pessoa juridica).
        * `error`: log do erro da aplica√ß√£o.
            

      ```json
        {
            "timestamp": "...",
            "layer": "silver",
            "project": "compass",
            "job": "google_play_reviews",
            "priority": "0",
            "tower": "SBBR_COMPASS",
            "client": "[...]",
            "error": "..."
        }
      ```

</details>

---

`üì¶ artefato` `iamgacarvalho/dmc-app-silver-reviews-mongodb` 
<details>
  <summary>Informa√ß√µes detalhada do artefato iamgacarvalho/dmc-app-silver-reviews-mongodb </summary> 

  - **Vers√£o:** `1.0.1`
  - **Reposit√≥rio:** [GitHub](https://github.com/gacarvalho/mongodb-processing-historical)  
  - **Imagem Docker:** [Docker Hub](https://hub.docker.com/repository/docker/iamgacarvalho/dmc-app-silver-reviews-mongodb/tags/1.0.1/sha256-6138a44faa031c50a8f8b7b4e75db092a8d03a62a0124b9e4414f999788e0d69)  
  - **Descri√ß√£o:**  Coleta avalia√ß√µes de clientes nos canais via base de dados **MongoDB** ingeridos no Data Lake, realizando a ingest√£o a partir da camada Bronze, processando e aplicando tratamento de dados e armazenando no HDFS em formato Parquet.

    ```shell
      /app/repo_trfmation_mongodb.py $CONFIG_ENV 
    ```
      - `$CONFIG_ENV` (`Pre`, `Pro`) ‚Üí Define o ambiente: `Pre` (Pr√©-Produ√ß√£o), `Pro` (Produ√ß√£o).
  - **Pipeline:**
    - **Descri√ß√£o:** Processar avalia√ß√µes de clientes dos canais Santander que ser√° armazenados na base interna Santander (camada Bronze ‚Üí Silver), garantindo: filtro espec√≠fico para dados da base interna Santander (MongoDB), normaliza√ß√£o e enriquecimento de metadados, valida√ß√£o de qualidade conforme regras de neg√≥cio e rastreabilidade completa dos dados
    - **Fonte de Dados:** <br> `/santander/bronze/compass/reviews/mongodb/*_pf` 
                          <br> `/santander/bronze/compass/reviews/mongodb/*_pj`
                          <br> `/santander/silver/compass/reviews/mongodb/`
    - **Filtro:** Apenas dados com mongodb no path e terminados em _pf ou _pj.                   
    - **Destino:** `/santander/silver/compass/reviews/mongodb/` 
    - **Tipo de processo:** Batch (di√°rio)

  - **Fluxo de Dados:**
    - **Extra√ß√£o:** Leitura de dados PF/PJ particionados por data de carga `odate` em Parquet
    - **Transforma√ß√£o e Fun√ß√µes:** PySpark <br> 
      1.  `remove_accents(s)`: Remove acentos de uma string, utilizando a biblioteca unidecode. Esta fun√ß√£o √© registrada como uma UDF (User Defined Function) no Spark para ser aplicada em colunas de DataFrames. **Par√¢metros:** `s` (str): A string da qual os acentos ser√£o removidos. **Retorno:** (str): A string sem acentos.

        ```python
        remove_accents(s: str) -> str
        ```

        No exemplo abaixo √© poss√≠vel ver como a funcionalidade se aplica em um caso real:

        ```python
        Exemplo: remove_accents("S√£o Paulo") # Retorna: "Sao Paulo"
        ```

      2.  `processing_reviews(df: DataFrame)`: Realiza transforma√ß√µes no DataFrame de reviews, selecionando colunas espec√≠ficas, converte nomes para mai√∫sculas e removendo acentos. Renomeia colunas para um formato consistente. **Par√¢metros:** `df` (DataFrame): O DataFrame de reviews a ser processado. **Retorno:** (DataFrame): O DataFrame transformado.

          ```python
          processed_df = processing_reviews(df)
          processed_df.show()
          ```

      3.  `get_schema(df, schema)`: Assegura que o DataFrame esteja em conformidade com um esquema predefinido, convertendo os tipos das colunas para os tipos especificados no esquema. **Par√¢metros:** `df` (DataFrame): O DataFrame a ser ajustado. `schema` (StructType): O esquema de destino. **Retorno:** (DataFrame): O DataFrame em conformidade com o esquema.

          ```python
          aligned_df = get_schema(df, schema)
          aligned_df.printSchema()
          ```

      4.  `processing_old_new(spark: SparkSession, df: DataFrame)`: Compara os dados de reviews novos com os dados hist√≥ricos, identificando e registrando mudan√ßas nas avalia√ß√µes ao longo do tempo. Cria uma coluna chamada `historical_data` para armazenar o hist√≥rico de mudan√ßas. **Par√¢metros:** `spark` (SparkSession): A sess√£o Spark ativa. `df` (DataFrame): O DataFrame com os novos dados de reviews. **Retorno:** (DataFrame): O DataFrame com o hist√≥rico de mudan√ßas.

          ```python
          historical_df = processing_old_new(spark, df)
          historical_df.show()
          ```

      5.  `read_source_parquet(spark, path)`: L√™ um arquivo Parquet do caminho especificado, extraindo informa√ß√µes de "app" e "segmento" do nome do arquivo. Retorna `None` se o arquivo n√£o existir ou se n√£o houver dados. **Par√¢metros:** `spark` (SparkSession): A sess√£o Spark ativa. `path` (str): O caminho para o arquivo Parquet. **Retorno:** (DataFrame | None): O DataFrame lido ou `None` em caso de falha.

          ```python
          source_df = read_source_parquet(spark, file_path)
          if source_df:
              source_df.show()
          ```

      6.  `save_dataframe(df, path, label)`: Salva um DataFrame no formato Parquet no caminho especificado. Verifica se o DataFrame possui dados antes de salvar, e caso n√£o possua, envia um log de warning. Verifica e cria o diret√≥rio de destino se necess√°rio. Lida com poss√≠veis erros durante o processo de salvamento. **Par√¢metros:** `df` (DataFrame): O DataFrame a ser salvo. `path` (str): O caminho para salvar o DataFrame. `label` (str): Uma etiqueta para os logs. **Retorno:** None.

          ```python
          save_dataframe(df, save_path, data_label)
          ```

      7.  `path_exists() -> bool`: Verifica se um determinado caminho existe no HDFS. Verifica se o caminho possui parti√ß√µes no formato "odate=\*". **Retorno:** (bool): True caso o caminho exista, e false caso n√£o exista.

          ```python
          if path_exists():
              print("O caminho existe")
          else:
              print("O caminho n√£o existe")
          ```

      8.  `save_metrics(metrics_json, df)`: Salva m√©tricas no Elasticsearch. Conecta-se ao Elasticsearch usando vari√°veis de ambiente. Lida com erros de decodifica√ß√£o JSON e erros de conex√£o. **Par√¢metros:** `metrics_json` (str): As m√©tricas no formato JSON. `df` (DataFrame): O DataFrame associado √†s m√©tricas. **Retorno:** None.

          ```python
          save_metrics(metrics, data_df)
          ```

      9.  `save_metrics_job_fail(metrics_json)`: Salva m√©tricas de falhas de jobs no Elasticsearch. Similar a `save_metrics`, mas para um √≠ndice diferente. **Par√¢metros:** `metrics_json` (str): As m√©tricas de falha no formato JSON. **Retorno:** None.

          ```python
          save_metrics_job_fail(failure_metrics)
          ```

      10. `log_error(e, df)`: Gera e salva m√©tricas de erro no Elasticsearch. Extrai informa√ß√µes de segmento do DataFrame. Formata informa√ß√µes de erro e as envia para `save_metrics_job_fail`. **Par√¢metros:** `e` (Exception): A exce√ß√£o que ocorreu. `df` (DataFrame): O DataFrame associado ao erro. **Retorno:** None.

          ```python
          try:
              # C√≥digo que pode gerar um erro
          except Exception as error:
              log_error(error, df)
          ```

    - **Valida√ß√£o:** 
    
        1.  `validate_ingest(spark: SparkSession, df: DataFrame) -> tuple`: Valida dados de ingest√£o, comparando com hist√≥rico e verificando qualidade. **Retorna** DataFrames de dados v√°lidos e inv√°lidos, e resultados da valida√ß√£o. 
    
            - **Duplicatas:** Identifica registros duplicados por "id".
            - **Nulos:** Verifica nulos em colunas cr√≠ticas.
            - **Tipos:** Garante consist√™ncia de tipos.

            C√≥digo de retorno na valida√ß√£o:

            > `200`: Sucesso (Nenhum problema encontrado) <br>
            > `400`: Erro nos dados (Valores nulos ou tipos inv√°lidos) <br>
            > `409`: Conflito de dados (Registros duplicados encontrados)



    - **Carga:** Escrita em HDFS (Parquet):
    
      1. Caminho principal (dados v√°lidos) `/santander/silver/compass/reviews/mongodb/odate={datePath}/` 
      2. Caminho de falha `/santander/silver/compass/reviews_fail/mongodb/odate={datePath}/`

    - **M√©tricas:** A fun√ß√£o `collect_metrics` coleta um conjunto abrangente de m√©tricas para fornecer uma vis√£o detalhada do processo de ingest√£o e valida√ß√£o de dados. As m√©tricas s√£o estruturadas em um objeto JSON, facilitando o consumo por sistemas de monitoramento e an√°lise.


      * **Informa√ß√µes da Aplica√ß√£o:**
          * `application_id`: Identificador √∫nico da aplica√ß√£o Spark.
          * `owner`: Detalhes do propriet√°rio da aplica√ß√£o (sigla, projeto, camada do Lake).
          * `source`: Detalhes sobre a fonte dos dados (`app`, `search`).
      * **Contagem de Registros:**
          * `valid_data`: Contagem e porcentagem de registros v√°lidos.
          * `invalid_data`: Contagem e porcentagem de registros inv√°lidos.
          * `total_records`: Contagem total de registros processados.
      * **Desempenho do Processamento:**
          * `total_processing_time`: Tempo total de processamento em minutos.
          * `memory_used`: Uso de mem√≥ria em megabytes.
          * `stages`: M√©tricas detalhadas dos est√°gios de execu√ß√£o do Spark.
      * **Resultados da Valida√ß√£o:**
          * `validation_results`: Resultados detalhados de cada valida√ß√£o (duplicatas, nulos, tipos).
          * `success_count`: N√∫mero de valida√ß√µes bem-sucedidas.
          * `error_count`: N√∫mero de valida√ß√µes com erros.
          * `type_client`: Lista de segmentos √∫nicos dos clientes.
      * **Timestamps:**
          * `_ts`: Timestamps de in√≠cio e t√©rmino do processamento.
          * `timestamp`: Timestamp da gera√ß√£o das m√©tricas.

      **Formato do JSON:**

      As m√©tricas s√£o estruturadas em um objeto JSON com a seguinte estrutura geral:

      ```json
      {
        "application_id": "...",
        "owner": {
          "sigla": "...",
          "projeto": "...",
          "layer_lake": "..."
        },
        "valid_data": {
          "count": ...,
          "percentage": ...
        },
        "invalid_data": {
          "count": ...,
          "percentage": ...
        },
        "total_records": ...,
        "total_processing_time": "...",
        "memory_used": ...,
        "stages": { ... },
        "validation_results": { ... },
        "success_count": ...,
        "error_count": ...,
        "type_client": "...",
        "source": {
          "app": "...",
          "search": "..."
        },
        "_ts": {
          "compass_start_ts": "...",
          "compass_end_ts": "..."
        },
        "timestamp": "..."
      }
      ```

    Este JSON pode ser utilizado para monitorar o desempenho do pipeline de dados, identificar problemas de qualidade de dados e otimizar o processo de ingest√£o. J√° para as falhas o JSON √© estruturado e enviado para o indice no Elastic Search de aplica√ß√µes com falhas.

      * **Informa√ß√µes do erro:**
        * `timestamp`: Timestamp da gera√ß√£o das m√©tricas.
        * `layer`: Camada referencia onde ocorreu o erro.
        * `project`: Projeto respons√°vel pela aplica√ß√£o com erro.
        * `job`: Job do pipeline que est√° em execu√ß√£o e que falhou.
        * `priority`: Prioridade do erro, quanto menor, mais impacto no pipeline e na vis√£o cliente, considera que de 0 a 2 √© o imapacto cr√≠tico, superior a isso, h√° impacto mas o fluxo segue normal. Exemplo: `Falha de 0-2` -> Erro ao capturar dados da API ou erro ao gravar no path destino.  `Falha de 3-4` -> Erro ao enviar as m√©tricas.
        * `tower`: Torre da sigla respons√°vel pelo alerta.
        * `client`: Segmento impactado, considerando PF (pessoa f√≠sica) e/ou PJ (pessoa juridica).
        * `error`: log do erro da aplica√ß√£o.
            


      ```json
        {
            "timestamp": "...",
            "layer": "silver",
            "project": "compass",
            "job": "mongodb_reviews",
            "priority": "0",
            "tower": "SBBR_COMPASS",
            "client": "[...]",
            "error": "..."
        }
      ```

</details>

---

‚ô®Ô∏è **Aplica√ß√µes - Dados Agregados**


A aplica√ß√£o respons√°vel por realizar os dados agregados √© a encarregada de alimentar a camada Gold do Data Lake. Seu principal objetivo √© consumir os dados tratados da camada Silver, provenientes de diferentes origens de ingest√£o, como a Base Interna Santander (MongoDB), Google Play e Apple Store.

A agrega√ß√£o tem como prop√≥sito oferecer ao time de neg√≥cio uma vis√£o consolidada e estrat√©gica que permita responder a perguntas-chave, tais como:

  - Qual a m√©dia de experi√™ncia do cliente nos √∫ltimos 3 a 9 meses?
  - Tivemos evolu√ß√µes na experi√™ncia do cliente ap√≥s a disponibiliza√ß√£o de uma nova feature para o segmento X?
  - Qual fonte de origem (Google Play, Apple Store, Base Interna) possui maior volume de reclama√ß√µes?
  - O volume de avalia√ß√µes aumentou ap√≥s uma a√ß√£o de marketing ou lan√ßamento de um novo canal?
  - Como est√° o desempenho dos canais digitais (ex: Santander Way, Santander Select) em termos de avalia√ß√£o?
  - Qual segmento de cliente (PF ou PJ) est√° mais engajado nas avalia√ß√µes?
  - Houve melhora na nota m√©dia ap√≥s a√ß√µes corretivas ou atualiza√ß√µes espec√≠ficas nos aplicativos?
  - Em quais meses tivemos picos negativos de avalia√ß√£o e o que pode ter causado isso?
  - Qual canal apresenta maior volume de intera√ß√µes negativas e pode demandar aten√ß√£o priorit√°ria?
  - A experi√™ncia do cliente est√° acima ou abaixo da meta institucional (ex: meta 5.0)?
  - Qual foi o impacto de determinada campanha ou evento no volume e na nota das avalia√ß√µes?
  - Estamos evoluindo de forma consistente ou estagnada na percep√ß√£o do cliente ao longo dos anos?
  - A distribui√ß√£o de avalia√ß√µes por canal est√° equilibrada ou concentrada em poucos aplicativos?
  - Existe correla√ß√£o entre a origem da avalia√ß√£o (ex: Google Play) e a nota atribu√≠da?
  - Quais s√£o os per√≠odos com baixa volumetria de avalia√ß√µes que podem indicar falta de engajamento?
  - Os clientes que avaliam via App Store tendem a dar notas mais baixas do que os do Google Play?
  - Qual a tend√™ncia de crescimento do volume de avalia√ß√µes nos √∫ltimos trimestres?
  - Os dados internos (MongoDB) refletem a mesma percep√ß√£o dos clientes que usam as plataformas externas?
  - Existe sazonalidade nas avalia√ß√µes que pode influenciar a an√°lise (ex: final de ano, datas comerciais)?


`üì¶ artefato` `iamgacarvalho/dmc-reviews-aggregate-apps-santander` 
<details>
  <summary>Informa√ß√µes detalhada do artefato iamgacarvalho/dmc-reviews-aggregate-apps-santander </summary> 

  - **Vers√£o:** `1.0.1`
  - **Reposit√≥rio:** [GitHub](https://github.com/gacarvalho/reviews-aggregate-apps-santander)  
  - **Imagem Docker:** [Docker Hub](https://hub.docker.com/repository/docker/iamgacarvalho/dmc-reviews-aggregate-apps-santander/tags/1.0.1/sha256-58173fc5e2bc379e19dc5496c1da79f1ccaac0535a5ab5ae27430f64050f98ac)  
  - **Descri√ß√£o:**  Coleta avalia√ß√µes de clientes de diversos  canais ingeridos no Data Lake, realizando a ingest√£o a partir da camada Silver, processando, agregando as informa√ß√µes e armazenando no **HDFS** em formato **Parquet**.

  - **Par√¢metros:** 
    ```shell
      /app/repo_agg_all_apps_gold.py $CONFIG_ENV 
    ```
      - `$CONFIG_ENV` (`Pre`, `Pro`) ‚Üí Define o ambiente: `Pre` (Pr√©-Produ√ß√£o), `Pro` (Produ√ß√£o).
  - **Pipeline:**
    - **Descri√ß√£o:** Processar avalia√ß√µes de clientes de diversos canais (camada Silver ‚Üí Gold), garantindo: agrega√ß√£o dos dados conforme regras de neg√≥cio.

    - **Fonte de Dados:** <br> `/santander/silver/compass/reviews/googlePlay` 
                          <br> `/santander/silver/compass/reviews/mongodb`
                          <br> `/santander/silver/compass/reviews/appleStore`
    - **Destino:** `/santander/gold/compass/reviews/apps_santander_aggregate/` 
    - **Tipo de processo:** Batch (di√°rio)

  - **Fluxo de Dados:**
    - **Extra√ß√£o:** Leitura de dados particionados por data de carga `odate` em Parquet
    - **Transforma√ß√£o e Fun√ß√µes:** PySpark <br> 

      1.  `processing_reviews(df)`: 
      
      Realiza a leitura e transforma√ß√£o do DataFrame de reviews, executando as seguintes etapas:

        * Sele√ß√£o de colunas espec√≠ficas relevantes para o processamento.
        * Convers√£o dos nomes das colunas para mai√∫sculas, garantindo uniformidade.
        * Adi√ß√£o de novas colunas utilizando express√µes regulares (regex) para extrair informa√ß√µes relevantes dos dados.
        * Uni√£o de DataFrames provenientes de diferentes origens em um √∫nico DataFrame consolidado.

      **Par√¢metros:**

      * `df` (DataFrame): O DataFrame de reviews a ser processado.

      **Retorno:**

      * (DataFrame): O DataFrame transformado, pronto para as pr√≥ximas etapas de processamento.

          ```python
          processed_df = processing_reviews(df)
          processed_df.show()
          ```


      2. `get_schema(df, schema)`: Assegura que o DataFrame esteja em conformidade com um esquema predefinido, convertendo os tipos das colunas para os tipos especificados no esquema. **Par√¢metros:** `df` (DataFrame): O DataFrame a ser ajustado. `schema` (StructType): O esquema de destino. **Retorno:** (DataFrame): O DataFrame em conformidade com o esquema.

          ```python
          aligned_df = get_schema(df, schema)
          aligned_df.printSchema()
          ```

      3. `save_reviews(reviews_df, directory)`: Salva os dados do DataFrame no formato Parquet no diret√≥rio que foi passado via `directory` **Par√¢metros:** `reviews_df` (DataFrame): O DataFrame a ser ajustado. `directory` diret√≥rio a ser gravado.

          ```python
          save_reviews(df, path)
          ```

      4. `write_to_mongo(dados_feedback, table_id, overwrite=False)`:Escreve dados em uma cole√ß√£o MongoDB, com a op√ß√£o de sobrescrever a cole√ß√£o. **Par√¢metros:** `dados_feedback` (dict): Dados a ser gravados na collections do MongoDB,  `table_id` collections destino a ser gravada e `overwrite` Se True, sobrescreve a cole√ß√£o, excluindo todos os documentos antes de inserir novos dados. 

          ```python
          # Converte o DataFrame do PySpark em uma lista de dicion√°rios (JSON)
          data = [json.loads(row) for row in df.toJSON().collect()]
          collection_name = "dt_d_view_gold_agg_compass"
          write_to_mongo(data, collection_name, overwrite=True)
          ```
      
    - **Valida√ß√£o:** 
    
        1.  `validate_ingest(spark: SparkSession, df: DataFrame) -> tuple`: Valida dados de ingest√£o, comparando com hist√≥rico e verificando qualidade. **Retorna** DataFrames de dados v√°lidos e inv√°lidos, e resultados da valida√ß√£o. 
    
            - **Duplicatas:** Identifica registros duplicados por "id".
            - **Nulos:** Verifica nulos em colunas cr√≠ticas.
            - **Tipos:** Garante consist√™ncia de tipos.

            C√≥digo de retorno na valida√ß√£o:

            > `200`: Sucesso (Nenhum problema encontrado) <br>
            > `400`: Erro nos dados (Valores nulos ou tipos inv√°lidos) <br>
            > `409`: Conflito de dados (Registros duplicados encontrados)



    - **Carga:** Escrita em HDFS (Parquet):
    
      1. Caminho principal (dados v√°lidos) `/santander/gold/compass/reviews/apps_santander_aggregate/odate={datePath}/` 
      2. Caminho de falha `/santander/gold/compass/reviews_fail/apps_santander_aggregate/odate={datePath}/`

    - **M√©tricas:** A fun√ß√£o `collect_metrics` coleta um conjunto abrangente de m√©tricas para fornecer uma vis√£o detalhada do processo de ingest√£o e valida√ß√£o de dados. As m√©tricas s√£o estruturadas em um objeto JSON, facilitando o consumo por sistemas de monitoramento e an√°lise.


      * **Informa√ß√µes da Aplica√ß√£o:**
          * `application_id`: Identificador √∫nico da aplica√ß√£o Spark.
          * `owner`: Detalhes do propriet√°rio da aplica√ß√£o (sigla, projeto, camada do Lake).
          * `source`: Detalhes sobre a fonte dos dados (`app`, `search`).
      * **Contagem de Registros:**
          * `valid_data`: Contagem e porcentagem de registros v√°lidos.
          * `invalid_data`: Contagem e porcentagem de registros inv√°lidos.
          * `total_records`: Contagem total de registros processados.
      * **Desempenho do Processamento:**
          * `total_processing_time`: Tempo total de processamento em minutos.
          * `memory_used`: Uso de mem√≥ria em megabytes.
          * `stages`: M√©tricas detalhadas dos est√°gios de execu√ß√£o do Spark.
      * **Resultados da Valida√ß√£o:**
          * `validation_results`: Resultados detalhados de cada valida√ß√£o (duplicatas, nulos, tipos).
          * `success_count`: N√∫mero de valida√ß√µes bem-sucedidas.
          * `error_count`: N√∫mero de valida√ß√µes com erros.
          * `type_client`: Lista de segmentos √∫nicos dos clientes.
      * **Timestamps:**
          * `_ts`: Timestamps de in√≠cio e t√©rmino do processamento.
          * `timestamp`: Timestamp da gera√ß√£o das m√©tricas.

      **Formato do JSON:**

      As m√©tricas s√£o estruturadas em um objeto JSON com a seguinte estrutura geral:

      ```json
      {
        "application_id": "...",
        "owner": {
          "sigla": "...",
          "projeto": "...",
          "layer_lake": "..."
        },
        "valid_data": {
          "count": ...,
          "percentage": ...
        },
        "invalid_data": {
          "count": ...,
          "percentage": ...
        },
        "total_records": ...,
        "total_processing_time": "...",
        "memory_used": ...,
        "stages": { ... },
        "validation_results": { ... },
        "success_count": ...,
        "error_count": ...,
        "type_client": "...",
        "source": {
          "app": "...",
          "search": "..."
        },
        "_ts": {
          "compass_start_ts": "...",
          "compass_end_ts": "..."
        },
        "timestamp": "..."
      }
      ```

  Este JSON pode ser utilizado para monitorar o desempenho do pipeline de dados, identificar problemas de qualidade de dados e otimizar o processo de ingest√£o. J√° para as falhas o JSON √© estruturado e enviado para o indice no Elastic Search de aplica√ß√µes com falhas.

  * **Informa√ß√µes do erro:**
    * `timestamp`: Timestamp da gera√ß√£o das m√©tricas.
    * `layer`: Camada referencia onde ocorreu o erro.
    * `project`: Projeto respons√°vel pela aplica√ß√£o com erro.
    * `job`: Job do pipeline que est√° em execu√ß√£o e que falhou.
    * `priority`: Prioridade do erro, quanto menor, mais impacto no pipeline e na vis√£o cliente, considera que de 0 a 2 √© o imapacto cr√≠tico, superior a isso, h√° impacto mas o fluxo segue normal. Exemplo: `Falha de 0-2` -> Erro ao capturar dados da API ou erro ao gravar no path destino.  `Falha de 3-4` -> Erro ao enviar as m√©tricas.
    * `tower`: Torre da sigla respons√°vel pelo alerta.
    * `client`: Segmento impactado, considerando PF (pessoa f√≠sica) e/ou PJ (pessoa juridica).
    * `error`: log do erro da aplica√ß√£o.
            

      ```json
        {
            "timestamp": "...",
            "layer": "gold",
            "project": "compass",
            "job": "aggregate_apps_reviews",
            "priority": "0",
            "tower": "SBBR_COMPASS",
            "client": "[PF, PJ, NA]",
            "error": "..."
        }
      ```

</details>


---

‚ô®Ô∏è **Aplica√ß√µes - Valida√ß√µes de Qualidade**


A aplica√ß√£o respons√°vel por realizar as qualidade de dados operam como um agente de qualidade do pipeline para reviews de aplicativos, provenientes de diferentes fontes (Google Play, MongoDB e Apple Store). Ele realiza as seguintes tarefas principais:

  - Volumetria
  - Schema
  - Pattern


No exemplo abaixo, √© poss√≠vel observar que a valida√ß√£o de volumetria foi realizada com sucesso, por√©m, caiu em rejeitados no schema, exibindo o schema atual e o schema que deveria ser estruturado, al√©m de apontar o caminho no HDFS que o dado foi rejeitado por data de carga (odate).

![<data-master-compass>](https://github.com/gacarvalho/compass-deployment/blob/compass/infra-3.0.0/img/validador_data_quality.png?raw=true)

`üì¶ artefato` `iamgacarvalho/dmc-quality-pipeline-compass` 
<details>
  <summary>Informa√ß√µes detalhada do artefato iamgacarvalho/dmc-quality-pipeline-compass </summary> 

  - **Vers√£o:** `1.0.1`
  - **Reposit√≥rio:** [GitHub](https://github.com/gacarvalho/quality-pipeline-compass)  
  - **Imagem Docker:** [Docker Hub](https://hub.docker.com/repository/docker/iamgacarvalho/dmc-quality-pipeline-compass/tags/1.0.1/sha256-a089704d2d12d1816d85246347e9604d082d605229d95116aaff145f1be990ba)  

    ```shell
      /app/app-code-compass-quality-pipeline.py $CONFIG_ENV $PARAM1
    ```
      - `$CONFIG_ENV` (`Pre`, `Pro`) ‚Üí Define o ambiente: `Pre` (Pr√©-Produ√ß√£o), `Pro` (Produ√ß√£o).
      - `$PARAM1` (`bronze`, `SILVER`) ‚Üí Define a camada do data laker a ser validado: `bronze` (Camada do Data Lake com dados brutos), `silver` (Camada do Data Lake com dados j√° tratados).
  - **Pipeline:**
    - **Descri√ß√£o:** Este pipeline de dados realiza a valida√ß√£o e processamento de reviews de aplicativos, coletadas de diversas fontes (Google Play, MongoDB e Apple Store), com o objetivo de garantir a qualidade e consist√™ncia dos dados. O processo inicia com a leitura dos dados brutos (camada Bronze) ou pr√©-processados (camada Silver) armazenados no HDFS em formato Parquet. Em seguida, os dados s√£o validados em rela√ß√£o a esquemas predefinidos e padr√µes espec√≠ficos para cada fonte, identificando e segregando registros inv√°lidos. Os dados validados s√£o ent√£o transformados e enriquecidos, preparando-os para an√°lise posterior. As m√©tricas de processamento e os registros inv√°lidos s√£o persistidos no HDFS, respectivamente, para monitoramento e rastreabilidade.
    - **Fonte de Dados:** 
    Definindo caminhos para cada camada. Vari√°vel wildcard:

      - Para `"bronze"`, wildcard recebe o valor `*/`.
      - Para `"silver"`, wildcard recebe uma string vazia `("")`.

      - **Caminhos em paths:** Substitu√≠ `*/` por `{wildcard}` nos caminhos das fontes. Isso permite que o comportamento do caminho mude dinamicamente conforme o valor de type_processing. Exemplo de Caminhos Gerados:

          - Se `type_processing` for `bronze` e date_ref for "2024-12-08", os caminhos ser√£o:
        
            `/santander/bronze/compass/reviews/googlePlay/*/odate=2024-12-08`
            
          - Se type_processing for `silver` e date_ref for "2024-12-08", os caminhos ser√£o:            

            `/santander/silver/compass/reviews/googlePlay/odate=2024-12-08`

    ```python
      paths = {
            "google_play": f"{base_path}/{type_processing}/compass/reviews/googlePlay/{wildcard}odate={date_ref}",
            "mongodb": f"{base_path}/{type_processing}/compass/reviews/mongodb/{wildcard}odate={date_ref}",
            "apple_store": f"{base_path}/{type_processing}/compass/reviews/appleStore/{wildcard}odate={date_ref}",
        }
    ```
    - **Destino:** <br>
    
      `/santander/quality/compass/reviews/schema/odate={datePath}` <br>
      `/santander/quality/compass/reviews/pattern/google_play/odate={datePath}` <br>
      `/santander/quality/compass/reviews/pattern/apple_store/odate={datePath}` <br>
      `/santander/quality/compass/reviews/pattern/internal_databases/odate={datePath}` <br>

    - **Tipo de processo:** Batch (di√°rio)

  - **Fluxo de Dados:**
    - **Extra√ß√£o:** Leitura de dados PF/PJ particionados por data de carga `odate` em Parquet
    - **Valida√ß√£o leitura da origem e carga:** PySpark

      1.  `read_parquet_data(spark, path)`: L√™ dados de um arquivo Parquet e trata erros de leitura.
          ```python
          read_parquet_data(spark: SparkSession, path: str) -> DataFrame
          ```
          **Par√¢metros:**
          * `spark` (SparkSession): A sess√£o Spark utilizada para ler o arquivo.
          * `path` (str): O caminho do arquivo Parquet a ser lido.
          **Retorno:**
          * (DataFrame): Um DataFrame contendo os dados lidos do arquivo Parquet.
          **Exce√ß√µes:**
          * Levanta uma exce√ß√£o `Exception` se ocorrer um erro durante a leitura do arquivo Parquet.
          ```python
          Exemplo: df = read_parquet_data(spark, "/caminho/para/arquivo.parquet")
          ```

      2.  `validate_dataframes(dataframes, layer)`: Valida se todos os DataFrames em um dicion√°rio possuem dados e realiza a uni√£o deles.
          ```python
          validate_dataframes(dataframes: dict, layer: str) -> tuple[DataFrame, DataFrame, DataFrame]
          ```
          **Par√¢metros:**
          * `dataframes` (dict): Um dicion√°rio onde as chaves s√£o os nomes das fontes de dados e os valores s√£o os DataFrames correspondentes.
          * `layer` (str): A camada de processamento ("bronze" ou "silver").
          **Retorno:**
          * (tuple[DataFrame, DataFrame, DataFrame]): Uma tupla contendo os DataFrames unidos para google_play, mongodb e apple_store.
          **Exce√ß√µes:**
          * Levanta uma exce√ß√£o `ValueError` se alguma das fontes de dados estiver vazia.
          ```python
          Exemplo: google_df, mongo_df, apple_df = validate_dataframes(dataframes, "bronze")
          ```

      3.  `validate_source_load(spark, date_ref, type_processing)`: Valida o processo de carga de dados de diferentes fontes (Google Play, MongoDB, Apple Store).
          ```python
          validate_source_load(spark: SparkSession, date_ref: str, type_processing: str) -> tuple[DataFrame, DataFrame, DataFrame]
          ```
          **Par√¢metros:**
          * `spark` (SparkSession): A sess√£o Spark utilizada para processar os dados.
          * `date_ref` (str): A data de refer√™ncia para os dados.
          * `type_processing` (str): O tipo de processamento ("bronze" ou "silver").
          **Retorno:**
          * (tuple[DataFrame, DataFrame, DataFrame]): Uma tupla contendo os DataFrames unidos para google_play, mongodb e apple_store.
          **Exce√ß√µes:**
          * Levanta uma exce√ß√£o `ValueError` se o `type_processing` for inv√°lido ou se ocorrer um erro de valida√ß√£o.
          * Levanta uma exce√ß√£o `Exception` se ocorrer um erro inesperado durante o processamento dos dados.
          ```python
          Exemplo: google_df, mongo_df, apple_df = validate_source_load(spark, "2024-12-08", "bronze")
          ```

      -   **Valida√ß√£o de schemas:** PySpark

      4.  `simplify_schema(schema)`: Simplifica um esquema de DataFrame, tratando tipos compostos.
          ```python
          simplify_schema(schema: StructType or ArrayType or DataType) -> StructType or ArrayType or DataType
          ```
          **Par√¢metros:**
          * `schema` (StructType or ArrayType or DataType): O esquema a ser simplificado.
          **Retorno:**
          * (StructType or ArrayType or DataType): O esquema simplificado.
          ```python
          Exemplo: simplified_schema = simplify_schema(df.schema)
          ```

      5.  `compare_schemas(actual_schema, expected_schema)`: Compara dois esquemas de DataFrame, levando em conta tipos compostos.
          ```python
          compare_schemas(actual_schema: StructType, expected_schema: StructType) -> bool
          ```
          **Par√¢metros:**
          * `actual_schema` (StructType): O esquema real do DataFrame.
          * `expected_schema` (StructType): O esquema esperado do DataFrame.
          **Retorno:**
          * (bool): `True` se os esquemas forem iguais, `False` caso contr√°rio.
          ```python
          Exemplo: schemas_match = compare_schemas(df.schema, expected_schema)
          ```

      6.  `validate_schema(spark, df, source_name)`: Valida o esquema de um DataFrame comparando com o esquema esperado para uma fonte espec√≠fica.
          ```python
          validate_schema(spark: SparkSession, df: DataFrame, source_name: str) -> DataFrame
          ```
          **Par√¢metros:**
          * `spark` (SparkSession): A sess√£o Spark utilizada para criar o DataFrame de resultados.
          * `df` (DataFrame): O DataFrame a ser validado.
          * `source_name` (str): O nome da fonte de dados.
          **Retorno:**
          * (DataFrame): Um DataFrame contendo os resultados da valida√ß√£o do esquema.
          **Exce√ß√µes:**
          * Levanta uma exce√ß√£o `ValueError` se a fonte fornecida n√£o estiver no dicion√°rio de esquemas esperados ou se o esquema for inv√°lido.
          ```python
          Exemplo: schema_validation_result = validate_schema(spark, df, "google_play_bronze")
          ```

      -   **Valida√ß√£o Pattern:** PySpark

      7.  `validated_pattern_google_play(df)`: Valida o DataFrame com base na estrutura e padr√µes fornecidos para o Google Play.
          ```python
          validated_pattern_google_play(df: DataFrame) -> DataFrame
          ```
          **Par√¢metros:**
          * `df` (DataFrame): O DataFrame a ser validado.
          **Retorno:**
          * (DataFrame): O DataFrame com as colunas "validation" e "failed_Columns".
          ```python
          Exemplo: validated_df = validated_pattern_google_play(df)
          ```

      8.  `validated_pattern_apple_store(df)`: Valida o DataFrame com base na estrutura e padr√µes fornecidos para a Apple Store.
          ```python
          validated_pattern_apple_store(df: DataFrame) -> DataFrame
          ```
          **Par√¢metros:**
          * `df` (DataFrame): O DataFrame a ser validado.
          **Retorno:**
          * (DataFrame): O DataFrame com as colunas "validation" e "failed_columns".
          ```python
          Exemplo: validated_df = validated_pattern_apple_store(df)
          ```

      9.  `validated_pattern_mongodb(df)`: Valida o DataFrame com base na estrutura e padr√µes fornecidos para o MongoDB.
          ```python
          validated_pattern_mongodb(df: DataFrame) -> DataFrame
          ```
          **Par√¢metros:**
          * `df` (DataFrame): O DataFrame a ser validado.
          **Retorno:**
          * (DataFrame): O DataFrame com as colunas "validation" e "failed_columns".
          ```python
          Exemplo: validated_df = validated_pattern_mongodb(df)
          ```

      -   **Persist√™ncia de dados:** PySpark e MongoDB

      10. `save_reviews(reviews_df, directory)`: Salva os dados do DataFrame no formato Parquet no diret√≥rio especificado.
          ```python
          save_reviews(reviews_df: DataFrame, directory: str) -> None
          ```
          **Par√¢metros:**
          * `reviews_df` (DataFrame): DataFrame PySpark contendo as avalia√ß√µes.
          * `directory` (str): Caminho do diret√≥rio onde os dados ser√£o salvos.
          **Retorno:**
          * `None`
          ```python
          Exemplo: save_reviews(df, "/caminho/para/salvar")
          ```

      11. `save_dataframe(df, path, label)`: Salva o DataFrame em formato parquet e loga a opera√ß√£o.
          ```python
          save_dataframe(df: DataFrame, path: str, label: str) -> None
          ```
          **Par√¢metros:**
          * `df` (DataFrame): DataFrame a ser salvo.
          * `path` (str): Caminho do diret√≥rio onde os dados ser√£o salvos.
          * `label` (str): Label para o log.
          **Retorno:**
          * `None`
          ```python
          Exemplo: save_dataframe(df, "/caminho/para/salvar", "reviews")
          ```

      12. `write_to_mongo(dados_feedback, table_id, overwrite=False)`: Escreve dados em uma cole√ß√£o MongoDB, com a op√ß√£o de sobrescrever a cole√ß√£o.
          ```python
          write_to_mongo(dados_feedback: dict or list, table_id: str, overwrite: bool = False) -> None
          ```
          **Par√¢metros:**
          * `dados_feedback` (dict or list): Dados a serem inseridos na cole√ß√£o (um √∫nico dicion√°rio ou uma lista de dicion√°rios).
          * `table_id` (str): Nome da cole√ß√£o onde os dados ser√£o inseridos.
          * `overwrite` (bool): Se True, sobrescreve a cole√ß√£o, excluindo todos os documentos antes de inserir novos dados.
          **Retorno:**
          * `None`
          ```python
          Exemplo: write_to_mongo(metrics, "dt_datametrics_compass")
          ```

      13. `save_metrics(metrics_json)`: Salva as m√©tricas no MongoDB.
          ```python
          save_metrics(metrics_json: str) -> None
          ```
          **Par√¢metros:**
          * `metrics_json` (str): String JSON contendo as m√©tricas.
          **Retorno:**
          * `None`
          ```python
          Exemplo: save_metrics('{"metric": "value"}')
          ```

      14. `save_metrics_job_fail(metrics_json)`: Salva as m√©tricas de falha no MongoDB.
          ```python
          save_metrics_job_fail(metrics_json: str) -> None
          ```
          **Par√¢metros:**
          * `metrics_json` (str): String JSON contendo as m√©tricas de falha.
          **Retorno:**
          * `None`
          ```python
          Exemplo: save_metrics_job_fail('{"error": "message"}')
          ```

</details>

---

‚ô®Ô∏è **Aplica√ß√£o - Renten√ß√£o/expurgo de dados**


A aplica√ß√£o respons√°vel por realizar o expurgo dos dados √© uma aplica√ß√£o Spark que realiza a limpeza autom√°tica de parti√ß√µes antigas no HDFS com base em uma data limite configur√°vel. Ele identifica parti√ß√µes no formato data de carga odate=YYYYMMDD e remove aquelas fora do intervalo de dias desejado. Em caso de erro durante qualquer etapa (Spark, HDFS ou MongoDB), o script envia m√©tricas detalhadas de falha para uma base MongoDB, incluindo timestamp, contexto e mensagem do erro.


`üì¶ artefato` `iamgacarvalho/iamgacarvalho/dmc-expurge-partitions-hdfs` 
<details>
  <summary>Informa√ß√µes detalhada do artefato iamgacarvalho/iamgacarvalho/dmc-expurge-partitions-hdfs </summary> 

  - **Vers√£o:** `1.0.1`
  - **Reposit√≥rio:** [GitHub](https://github.com/gacarvalho/expurge-partitions-hdfs-compass)  
  - **Imagem Docker:** [Docker Hub](https://hub.docker.com/repository/docker/iamgacarvalho/dmc-expurge-partitions-hdfs/tags/1.0.0/sha256-e78cdb9d002ec2273ef464606b8b7e7d6d6a7dc4136a66868be703315201cac4)  

    ```shell
      /app/app-code-compass-expurge-partitions-hdfs.py $CONFIG_ENV $PARAM1 $PARAM2"
    ```
      - `$CONFIG_ENV` (`Pre`, `Pro`) ‚Üí Define o ambiente: `Pre` (Pr√©-Produ√ß√£o), `Pro` (Produ√ß√£o).
      - `$PARAM1` (`/santander/bronze/compass/reviews/appleStore/banco-santander-br/`, <br> `/santander/gold/compass/reviews/apps_santander_aggregate/`) ‚Üí Define o path que ter√° o expurgo dos dados. 
      - `$PARAM2` (`7`, `1825`) ‚Üí Define o n√∫mero de dias que manter√° os dados dentro do Data Lake.

  - **Pipeline:**
    - **Descri√ß√£o:** A aplica√ß√£o em Spark, foi desenvolvido com o prop√≥sito de realizar o expurgo automatizado de parti√ß√µes antigas armazenadas em um diret√≥rio HDFS. Sua fun√ß√£o √© identificar e remover parti√ß√µes que estejam fora de um intervalo de datas definido pelo usu√°rio, com o objetivo de liberar espa√ßo e manter a estrutura do HDFS organizada e eficiente. A aplica√ß√£o inicia criando uma sess√£o Spark configurada para suportar leitura de arquivos Parquet e a inclus√£o de depend√™ncias externas. Em seguida, ela valida os par√¢metros de entrada fornecidos via linha de comando, que incluem o ambiente de execu√ß√£o, o diret√≥rio base no HDFS e a quantidade de dias cujos dados devem ser preservados. Com essas informa√ß√µes, o script calcula a data limite com base na data atual e no n√∫mero de dias a manter, e utiliza comandos HDFS para listar todas as parti√ß√µes existentes dentro do diret√≥rio especificado. Cada parti√ß√£o √© avaliada de acordo com seu nome, que deve seguir o padr√£o de data de carga odate=YYYYMMDD. Se a data extra√≠da estiver fora do intervalo permitido, a parti√ß√£o √© removida do HDFS por meio de um comando hdfs dfs -rm -r, sempre com tratamento de exce√ß√µes para garantir a estabilidade da execu√ß√£o. Al√©m disso, em caso de qualquer erro durante o processo ‚Äî seja na cria√ß√£o da sess√£o Spark, na leitura das parti√ß√µes ou na tentativa de remo√ß√£o ‚Äî, o script registra a falha em uma estrutura de m√©tricas com informa√ß√µes detalhadas, como timestamp, nome do job, grupo respons√°vel e mensagem do erro. Esses dados s√£o salvos em uma cole√ß√£o espec√≠fica dentro do MongoDB, cuja conex√£o √© configurada por vari√°veis de ambiente seguras, com usu√°rio, senha, host, porta e nome do banco. Ao final da execu√ß√£o, o HDFS permanece apenas com as parti√ß√µes desejadas, e qualquer falha ocorrida durante o processo √© devidamente registrada para rastreabilidade e monitoramento operacional.


    - **Fonte de Dados:** 
    Pode ser definido pelo par√¢metro `$PARM1`

      - `/santander/bronze/compass/reviews/appleStore/banco-santander-br/`
      - `/santander/bronze/compass/reviews/appleStore/santander-way/`
      - `/santander/bronze/compass/reviews/appleStore/santander-selectglobal/`
      - `/santander/bronze/compass/reviews/googlePlay/banco-santander-br/`
      - `/santander/bronze/compass/reviews/googlePlay/santander-way/`
      - `/santander/bronze/compass/reviews/googlePlay/santander-selectglobal/`
      - `/santander/bronze/compass/reviews/mongodb/banco-santander-br/`
      - `/santander/bronze/compass/reviews/mongodb/reviews-santander-way/`
      - `/santander/bronze/compass/reviews/mongodb/santander-selectGlobal/`
      - ` /santander/silver/compass/reviews/appleStore/`
      - `/santander/silver/compass/reviews/googlePlay/`
      - `/santander/silver/compass/reviews/mongodb/`
      - `/santander/gold/compass/reviews/apps_santander_aggregate/`


    - **Tipo de processo:** Batch (Semanal)

  - **Fluxo de Dados:**
    - **Extra√ß√£o:** Leitura de dados PF/PJ particionados por data de carga `odate` em Parquet
    - **Valida√ß√£o leitura da origem e carga:** PySpark

      1. `read_parquet_data(spark, path)`

      L√™ dados de um diret√≥rio Parquet e trata falhas de leitura.

      ```python
      read_parquet_data(spark: SparkSession, path: str) -> DataFrame
      ```

      **Par√¢metros:**

      - `spark` (SparkSession): Sess√£o Spark usada para processar os dados.
      - `path` (str): Caminho no HDFS para leitura do diret√≥rio particionado.

      **Retorno:**

      - (DataFrame): Retorna um DataFrame com os dados do diret√≥rio informado.

      **Exce√ß√µes:**

      - Lan√ßa uma `Exception` em caso de falha na leitura.

      ```python
      Exemplo: df = read_parquet_data(spark, "/santander/bronze/compass/reviews/appleStore/")
      ```

      2. `get_partition_folders(path)`

      Retorna a lista de parti√ß√µes v√°lidas dentro de um diret√≥rio do HDFS.

      ```python
      get_partition_folders(path: str) -> List[str]
      ```

      **Par√¢metros:**

      - `path` (str): Caminho base do diret√≥rio particionado.

      **Retorno:**

      - (List[str]): Lista de parti√ß√µes no formato `odate=YYYYMMDD`.

      **Exce√ß√µes:**

      - Retorna lista vazia se ocorrer erro ao listar parti√ß√µes.

      ```python
      Exemplo: partitions = get_partition_folders("/santander/bronze/compass/reviews/googlePlay/")
      ```

      3. `filter_old_partitions(partitions, days_to_keep)`

      Filtra parti√ß√µes com data anterior √† data limite.

      ```python
      filter_old_partitions(partitions: List[str], days_to_keep: int) -> List[str]
      ```

      **Par√¢metros:**

      - `partitions` (List[str]): Lista de parti√ß√µes no formato `odate=YYYYMMDD`.
      - `days_to_keep` (int): Quantidade de dias a serem mantidos.

      **Retorno:**

      - (List[str]): Lista de parti√ß√µes que devem ser expurgadas.

      ```python
      Exemplo: expired = filter_old_partitions(partitions, 7)
      ```

      4. `delete_partition(partition_path)`

      Deleta parti√ß√µes expiradas diretamente do HDFS.

      ```python
      delete_partition(partition_path: str) -> bool
      ```

      **Par√¢metros:**

      - `partition_path` (str): Caminho completo da parti√ß√£o a ser removida.

      **Retorno:**

      - (bool): Retorna `True` se a remo√ß√£o for bem-sucedida, `False` caso contr√°rio.

      **Exce√ß√µes:**

      - Erros s√£o capturados e logados, mas n√£o interrompem o processo.

      ```python
      Exemplo: delete_partition("/santander/bronze/compass/reviews/appleStore/odate=20230101")
      ```


      5. `log_error_to_mongo(data)`

      Persiste erro ocorrido durante o processo no MongoDB.

      ```python
      log_error_to_mongo(data: Dict[str, Any]) -> None
      ```

      **Par√¢metros:**

      - `data` (dict): Estrutura contendo o erro, nome do job, timestamp, grupo e outros metadados.

      **Retorno:**

      - None. O erro √© salvo na cole√ß√£o Mongo definida pelas vari√°veis de ambiente.

      ```python
      Exemplo:
      log_error_to_mongo({
          "timestamp": "2024-09-08T23:45:00",
          "job_name": "EXPURGE_BRONZE",
          "path": "/santander/bronze/compass/reviews/appleStore/",
          "message": "Erro ao ler Parquet",
          "status": "FAIL"
      })
      ```


      **Fluxo:**

      - L√™ argumentos (`env`, `path`, `days_to_keep`) via `sys.argv`.
      - Cria uma sess√£o Spark.
      - L√™ os dados do diret√≥rio informado.
      - Identifica parti√ß√µes a serem expurgadas.
      - Remove parti√ß√µes expiradas.
      - Em caso de erro, registra no MongoDB com metadados.


</details>

---
#### 3.2.2.3 **Pipeline do Projeto Compass**

A orquestra√ß√£o dos fluxos de ingest√£o, transforma√ß√£o e carga das informa√ß√µes √© realizada por meio do Apache Airflow, ferramenta escolhida pela sua flexibilidade, escalabilidade e capacidade de monitoramento de pipelines de dados. O pipeline desenvolvido no Airflow permite o agendamento e controle dos jobs Spark, garantindo a execu√ß√£o ordenada e confi√°vel das etapas do processo de dados dentro do Projeto Compass.

Cada DAG (Directed Acyclic Graph) representa um pipeline espec√≠fico de neg√≥cio, contendo tarefas interdependentes que asseguram o tratamento correto dos dados desde a origem at√© os destinos finais, como o Data Lake ou sistemas consumidores. Essa abordagem permite maior governan√ßa, rastreabilidade e facilidade de manuten√ß√£o da arquitetura de dados, al√©m de suportar a integra√ß√£o com outras ferramentas e sistemas do ecossistema Big Data.

> [!NOTE]
> O pipeline segue um padr√£o: `dag_<schedule>_pipeline_<projeto>_reviews`. **Legendas schedule:** `d`: Di√°rio,`s`: Semanal, `m`: Mensal, `e`: Eventual, 

| Nome da DAG                              | Descri√ß√£o                                                                                                                                          | JOBS                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |
|------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| `dag_d_pipeline_compass_reviews`         | Pipeline di√°ria respons√°vel por manter o pipeline principal do Projeto Compass, garantindo que a ingest√£o at√© a disponibiliza√ß√£o da carga final seja entregue ao cliente final. | `MONGO_INGESTION_SANTANDER-WAY`<br>`MONGO_INGESTION_BANCO-SANTANDER-BR`<br>`MONGO_INGESTION_SANTANDER-SELECT-GLOBAL`<br>`APPLE_INGESTION_SANTANDER-WAY`<br>`APPLE_INGESTION_BANCO-SANTANDER-BR`<br>`APPLE_INGESTION_SANTANDER-SELECT-GLOBAL`<br>`GOOGLE_INGESTION_BR.COM.SANTANDER.WAY`<br>`GOOGLE_INGESTION_COM.SANTANDER.APP`<br>`GOOGLE_INGESTION_COM.SANTANDER.SELECTGLOBAL`<br>`SILVER_APP_SILVER_APPLE_STORE`<br>`SILVER_APP_SILVER_GOOGLE_PLAY`<br>`SILVER_APP_SILVER_INTERNAL_BASE`<br>`GOLD_APP_GOLD_AGGREGATE_REVIEWS_SANTANDER`<br>`B_QUALITY_PIPELINE_APP_REVIEWS_SANTANDER`<br>`S_QUALITY_PIPELINE_APP_REVIEWS_SANTANDER` |
| `dag_s_pipeline_expurge_compass_reviews` | Pipeline semanal respons√°vel por realizar expurgo dos dados nas camadas Bronze, Silver e Gold.                                                      | `B_EXPURGE_APPLE_STORE_HDFS_HISTORY_BRONZE_APPLE_STORE_APP_SANTANDER_BR`<br>`B_EXPURGE_APPLE_STORE_HDFS_HISTORY_BRONZE_APPLE_STORE_APP_SANTANDER_WAY`<br>`B_EXPURGE_APPLE_STORE_HDFS_HISTORY_BRONZE_APPLE_STORE_APP_SANTANDER_SELECT_GLOBAL`<br>`B_EXPURGE_GOOGLE_PLAY_HDFS_HISTORY_BRONZE_GOOGLE_PLAY_APP_SANTANDER_BR`<br>`B_EXPURGE_GOOGLE_PLAY_HDFS_HISTORY_BRONZE_GOOGLE_PLAY_APP_SANTANDER_WAY`<br>`B_EXPURGE_GOOGLE_PLAY_HDFS_HISTORY_BRONZE_GOOGLE_PLAY_APP_SANTANDER_SELECT_GLOBAL`<br>`B_EXPURGE_MONGODB_HDFS_HISTORY_BRONZE_INTERNAL_BASE_APP_SANTANDER_BR`<br>`B_EXPURGE_MONGODB_HDFS_HISTORY_BRONZE_INTERNAL_BASE_APP_SANTANDER_WAY`<br>`B_EXPURGE_MONGODB_HDFS_HISTORY_BRONZE_INTERNAL_BASE_APP_SANTANDER_SELECT_GLOBAL`<br>`S_EXPURGE_APP_HDFS_HISTORY_SILVER_APPLE_STORE`<br>`S_EXPURGE_APP_HDFS_HISTORY_SILVER_GOOGLE_PLAY`<br>`S_EXPURGE_APP_HDFS_HISTORY_SILVER_INTERNAL_BASE`<br>`G_EXPURGE_APP_HDFS_HISTORY_GOLD_AGGREGATE` |


# 4. Fluxo Funcional e Jornada do Cliente

A solu√ß√£o foi projetada para atender ao time de neg√≥cio, proporcionando uma vis√£o estrat√©gica das principais dores dos clientes e da concorr√™ncia. Ela permite an√°lises em diferentes n√≠veis de granularidade, desde indicadores agregados, como a distribui√ß√£o das avalia√ß√µes e notas (de 0 a 5) por segmento e canal, at√© um n√≠vel mais detalhado, possibilitando o acompanhamento do hist√≥rico de avalia√ß√µes de clientes espec√≠ficos dentro de um determinado segmento. 


![<fluxo-funcional>](https://github.com/gacarvalho/compass-deployment/blob/compass/infra-3.0.0/img/fluxo%20de%20negocios.jpg?raw=true)



Com os dados de extra√ß√£o pelo Projeto Compass, ser√° poss√≠vel unificar e enriquecer as principais dores dos clientes com dados externos ‚Äî como avalia√ß√µes, coment√°rios e feedbacks coletados em plataformas p√∫blicas, como Apple Store, Google Play, Reclame Aqui, entre outras.

Essa integra√ß√£o permitir√° uma vis√£o mais hol√≠stica da experi√™ncia do usu√°rio, combinando dados internos (transacionais, comportamentais e operacionais) com insumos externos, possibilitando:

  - Identifica√ß√£o mais precisa de pontos de fric√ß√£o ao longo da jornada do cliente;
  - Prioriza√ß√£o de melhorias com base na percep√ß√£o real dos usu√°rios;
  - Antecipa√ß√£o de problemas recorrentes, mesmo antes de serem reportados via canais formais;
  - Alinhamento estrat√©gico com o time de Produto, garantindo que evolu√ß√µes sejam orientadas por dados e focadas em gerar valor;
  - Monitoramento cont√≠nuo da reputa√ß√£o da marca nas plataformas externas, refor√ßando a governan√ßa da experi√™ncia do cliente.

Com isso, o Projeto Compass se posiciona como uma iniciativa estrat√©gica, permitindo que a companhia avance para uma atua√ß√£o proativa, centrada no cliente e orientada por dados.

# 5. Compass como produto analytics Santander

---

O projeto Compass como Produto tem como objetivo fornecer uma solu√ß√£o robusta e escal√°vel para o Santander, utilizando Engenharia de Dados para desenvolver um fluxo que permita identificar as principais necessidades e desafios dos seus clientes. Esse fluxo busca n√£o apenas atender as demandas internas do banco, mas tamb√©m possui o potencial de expandir sua abrang√™ncia, permitindo escalar a busca para entender as "dores" dos concorrentes do Santander no mercado.


## 5.1 Regras de Neg√≥cio

Como premissa central do Projeto Compass, o objetivo √© consolidar uma base estruturada com as principais dores dos clientes em rela√ß√£o aos produtos do Santander. Essa base permitir√° a gera√ß√£o de insights valiosos e a an√°lise de oportunidades de melhoria nos diferentes canais de atendimento e relacionamento, contribuindo diretamente para o aumento da principalidade do cliente com a institui√ß√£o.

A seguir, est√£o descritas em formato de tabela as principais regras de neg√≥cio e crit√©rios de aceite que orientam a execu√ß√£o do Projeto Compass.

> [!NOTE]
> A maior parte das regras funcionais implementadas neste pipeline dizem respeito √† estrutura final dos dados e aos filtros aplicados para garantir integridade m√≠nima. 
> Como estamos lidando com dados semi-estruturados (coment√°rios, avalia√ß√µes, etc.), n√£o h√° muitas outras regras funcionais a serem aplicadas. 
> O tratamento √© limitado pela aus√™ncia de um esquema r√≠gido, o que impede a cria√ß√£o de regras mais espec√≠ficas como joins complexos, valida√ß√µes por dom√≠nio ou integridade referencial.


---
<details>
  <summary> üè∑Ô∏è Regras de Neg√≥cios - Apple Store </summary>

  | **ID**    | **Fonte de Origem** | **Vers√£o do Projeto/Aplica√ß√£o** | **Regra de Neg√≥cio**                                               | **Descri√ß√£o**                                                                                                                                                             | **Objetivo**                                                                                     | **√öltima Atualiza√ß√£o** |
  |----------|----------------------|------------------------|---------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|-------------------------|
  | **RN001** | Google Play - Silver| v1 - 1.0.1             | Uso de dados hist√≥ricos (`historical_data`)                         | Utiliza a fun√ß√£o `historical_data` para obter a parti√ß√£o anterior e realizar atualiza√ß√£o incremental.                                                                     | Evitar reprocessamento completo e permitir atualiza√ß√£o incremental.                             | 2025-04-06              |
  | **RN002** | Apple Store - Silver| v1 - 1.0.1             | Remo√ß√£o de acentos e padroniza√ß√£o de texto                          | Os textos dos campos `author_name`, `title` e `content` devem ser convertidos para letras mai√∫sculas e ter acentos removidos.                                              | Uniformizar dados textuais para an√°lises e buscas.                                               | 2025-04-06              |
  | **RN003** | Apple Store - Silver| v1 - 1.0.1             | Gera√ß√£o de m√©tricas de erro                                         | Em caso de falha no processamento, uma m√©trica detalhada contendo o erro e informa√ß√µes do cliente ser√° salva no Elasticsearch.                                            | Permitir rastreabilidade e visibilidade de falhas.                                               | 2025-04-06              |
  | **RN004** | Apple Store - Silver| v1 - 1.0.1             | Padroniza√ß√£o de schema antes da escrita                             | Antes da persist√™ncia, os dados devem ser reestruturados conforme o schema definido para a camada silver (`apple_store_schema_silver`).                                  | Garantir consist√™ncia da estrutura dos dados armazenados.                                        | 2025-04-06              |
  | **RN005** | Apple Store - Silver| v1 - 1.0.1             | Extra√ß√£o de metadados a partir do nome do arquivo                   | Os campos `app` e `segmento` devem ser extra√≠dos a partir do caminho do arquivo no HDFS com express√µes regulares.                                                          | Enriquecer os dados com metadados √∫teis sem depender de colunas expl√≠citas.                     | 2025-04-06              |
  | **RN006** | Apple Store - Silver| v1 - 1.0.1             | Valida√ß√£o da exist√™ncia de parti√ß√µes no HDFS                        | A execu√ß√£o s√≥ continuar√° se houver parti√ß√µes no formato `odate=*` no caminho hist√≥rico `/santander/silver/compass/reviews/appleStore/`.                                  | Evitar falhas por aus√™ncia de dados e otimizar a execu√ß√£o.                                       | 2025-04-06              |
  | **RN007** | Apple Store - Silver| v1 - 1.0.1             | Salvamento de m√©tricas da aplica√ß√£o                                 | M√©tricas de execu√ß√£o bem-sucedida devem ser enviadas ao √≠ndice `compass_dt_datametrics` no Elasticsearch, usando autentica√ß√£o b√°sica.                                     | Garantir observabilidade da execu√ß√£o e indicadores de sucesso.                                  | 2025-04-06              |
  | **RN008** | Apple Store - Silver| v1 - 1.0.1             | Verifica√ß√£o de duplicidade de registros                             | Verifica se h√° duplicidade de registros com base na coluna `id`. Caso existam, retorna erro de conflito e bloqueia a execu√ß√£o.                                             | Evitar dados duplicados e garantir unicidade dos registros.                                     | 2025-04-06              |
  | **RN009** | Apple Store - Silver| v1 - 1.0.1             | Valida√ß√£o de campos nulos em colunas obrigat√≥rias                   | Valida se colunas essenciais como `id`, `content`, `im_rating`, `im_version` est√£o preenchidas. Caso contr√°rio, gera erro e encerra o processo.                           | Garantir integridade dos dados antes da persist√™ncia.                                            | 2025-04-06              |
  | **RN010** | Apple Store - Silver| v1 - 1.0.1             | Consist√™ncia de tipo para campos num√©ricos                          | Garante que os valores na coluna `im_rating` sejam num√©ricos v√°lidos (por exemplo, inteiros ou floats). Registros inv√°lidos s√£o descartados ou tratados conforme regra. | Evitar erros de tipo e assegurar qualidade para an√°lise quantitativa.                           | 2025-04-06              |

</details>

<details>
  <summary> üè∑Ô∏è Regras de Neg√≥cios - Google Play </summary>

  | **ID** | Fonte de Origem| Vers√£o do Projeto/Aplica√ß√£o | Regra de Neg√≥cio                             | Descri√ß√£o                                                                                                                                              | **Objetivo**                                                                 | √öltima Atualiza√ß√£o                    |
  |--------|----------------|-------------------|------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------|-----------------------------------|
  | **RN001**  | Google Play - Silver| v1 - 1.0.1             |  Uso de dados hist√≥ricos (`historical_data`)    | Utiliza a fun√ß√£o `historical_data` para obter a parti√ß√£o anterior e realizar atualiza√ß√£o incremental.                                                      | Evitar reprocessamento completo e permitir atualiza√ß√£o incremental.         | 2025-04-06      |
  | **RN002**  | Google Play - Silver| v1 - 1.0.1             | Filtragem por dados v√°lidos (`validate_ingest`) | Aplica regras de valida√ß√£o de schema, campos obrigat√≥rios, tipos de dados e padr√µes esperados.                                                             | Separar dados v√°lidos e inv√°lidos para rastreabilidade.                     | 2025-04-06        |
  | **RN003**  | Google Play - Silver| v1 - 1.0.1             | Normaliza√ß√£o de texto (`unidecode`)             | Remove acentua√ß√£o e converte para caixa alta nos campos `title` e `snippet`.                                                                               | Uniformizar texto para an√°lise textual.                                     | 2025-04-06          |
  | **RN004**  | Google Play - Silver| v1 - 1.0.1             | Identifica√ß√£o de segmenta√ß√£o (PF/PJ)            | Classifica os dados de entrada como pessoa f√≠sica ou jur√≠dica com base no caminho do arquivo.                                                              | Enriquecer o dado com a informa√ß√£o de segmento.                             | 2025-04-06                     |
  | **RN005**  | Google Play - Silver| v1 - 1.0.1             | Extra√ß√£o do nome do app                         | A partir do caminho do arquivo (`input_file_name`), extrai dinamicamente o nome do aplicativo.                                                             | Associar corretamente o review ao seu aplicativo.                           | 2025-04-06                      |
  | **RN006**  | Google Play - Silver| v1 - 1.0.1             | Cria√ß√£o de colunas t√©cnicas                     | Adiciona colunas como `job_datetime` e `partition_column` para rastreabilidade da execu√ß√£o e particionamento por data.                                    | Permitir auditoria e facilitar consultas particionadas.                      | 2025-04-06      |
  | **RN007**  | Google Play - Silver| v1 - 1.0.1             | Particionamento por data (`partition_column`)   | Os dados s√£o particionados por data da execu√ß√£o extra√≠da do nome do arquivo (`odate`).                                                                     | Melhorar performance de leitura e escrita no lake.                          | 2025-04-06             |
  | **RN008**  | Google Play - Silver| v1 - 1.0.1             | Rejei√ß√£o de dados inconsistentes                | Dados com inconsist√™ncias, como tipos errados ou campos vazios obrigat√≥rios, s√£o separados e salvos no caminho de *falhas*.                                | Garantir integridade da camada Silver.                                      | 2025-04-06                   |
  | **RN009**  | Google Play - Silver| v1 - 1.0.1             | Envio de m√©tricas para observabilidade          | Em caso de erro, envia um documento JSON para Elasticsearch com os detalhes do job.                                                                        | Monitorar falhas em tempo real.                                             | 2025-04-06   |
</details>

<details>
  <summary> üè∑Ô∏è Regras de Neg√≥cios - Base Interna | MongoDB </summary>

  | ID       | Fonte de Origem | Vers√£o do Projeto/Aplica√ß√£o | Regra de Neg√≥cio Funcional                    | Descri√ß√£o                                                                                                                        | Objetivo                                                                                      | √öltima Atualiza√ß√£o |
  |----------|------------------|--------------------|-----------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------|---------------------|
  | **RN001**   | MongoDB - Silver| v1 - 1.0.1       | Filtro por colunas obrigat√≥rias               | Remove registros que n√£o possuem `id`, `rating`, `snippet` ou `date`.                                                           | Garantir integridade m√≠nima dos dados antes do enriquecimento.                              | 2025-04-06          |
  | **RN002**   | MongoDB - Silver| v1 - 1.0.1       |  Tratamento de acentos                         | Aplica fun√ß√£o para remover acentos do campo `comment`.                                                                          | Padronizar texto para facilitar an√°lise textual.                                              | 2025-04-06          |
  | **RN003**   | MongoDB - Silver| v1 - 1.0.1       |  Convers√£o para caixa alta                     | Converte os coment√°rios (`comment`) para letras mai√∫sculas.                                                                     | Evitar distin√ß√µes entre palavras com mesmas letras em diferentes casos.                     | 2025-04-06          |
  | **RN004**   | MongoDB - Silver| v1 - 1.0.1       |  Adi√ß√£o da coluna `app`                        | Extrai o nome do app a partir do nome do arquivo/parquet lido.                                                                  | Enriquecer os dados com a aplica√ß√£o de origem.                                                | 2025-04-06          |
  | **RN005**   | MongoDB - Silver| v1 - 1.0.1       |  Adi√ß√£o da coluna `segmento`                   | Extrai o segmento (`pf` ou `pj`) do nome do arquivo/parquet lido.                                                               | Permitir segmenta√ß√£o dos dados por tipo de cliente.                                           | 2025-04-06          |
  | **RN006**   | MongoDB - Silver| v1 - 1.0.1       |  Cria√ß√£o da coluna `historical_data`           | Compara os dados atuais com dados anteriores e adiciona campo indicando altera√ß√µes.                                             | Rastrear modifica√ß√µes nos coment√°rios ou avalia√ß√µes ao longo do tempo.                      | 2025-04-06          |
  | **RN007**   | MongoDB - Silver| v1 - 1.0.1       |  Remo√ß√£o de colunas desnecess√°rias             | Remove campos como `avatar`, `iso_date`, entre outros ap√≥s transforma√ß√£o.                                                       | Reduzir tamanho do dataset e manter apenas colunas relevantes.                               | 2025-04-06          |
  | **RN008**   | MongoDB - Silver| v1 - 1.0.1       |  Padroniza√ß√£o do schema final (`Silver`)       | Aplica `withColumn` e `select` para garantir colunas fixas: `id`, `title`, `rating`, `comment`, `likes`, `date`, `app`, etc.   | Garantir compatibilidade com camadas posteriores e contratos de dados.                       | 2025-04-06          |
  | **RN009**   | MongoDB - Silver| v1 - 1.0.1       |  Cria√ß√£o da coluna `dt_partition`              | Adiciona uma parti√ß√£o de data (`dt_partition`) baseada na data de execu√ß√£o.                                                     | Otimizar queries futuras e organiza√ß√£o no HDFS.                                               | 2025-04-06          |
  | **RN010**   | MongoDB - Silver| v1 - 1.0.1       |  Convers√£o de tipos                            | Campos como `likes` e `rating` s√£o convertidos explicitamente para `IntegerType` e `FloatType`.                                | Evitar erros de tipo e garantir consist√™ncia na leitura e escrita.                          | 2025-04-06          |
  | **RN011**   | MongoDB - Silver| v1 - 1.0.1       |  Unifica√ß√£o dos dados `pf` e `pj`              | Dados s√£o lidos separadamente por segmento e unidos em um √∫nico DataFrame.                                                      | Obter um dataset consolidado para uso anal√≠tico.                                              | 2025-04-06          |

</details>


---

## 5.2 Dicion√°rio de Dados

Este dicion√°rio de dados tem como objetivo documentar e padronizar a estrutura dos dados utilizados ao longo das esteiras de ingest√£o, transforma√ß√£o e disponibiliza√ß√£o. Ele serve como uma refer√™ncia clara e objetiva para desenvolvedores, analistas e squads que atuam com os dados descritos.

A estrutura apresentada foi definida para garantir consist√™ncia, rastreabilidade e governan√ßa dos dados, al√©m de facilitar o entendimento t√©cnico-funcional sobre a origem e o destino de cada informa√ß√£o.

Cada tabela est√° organizada com os seguintes campos:

| Campo              | Descri√ß√£o |
|--------------------|-----------|
| **DIRETORIO**       | Caminho onde os dados s√£o armazenados no Data Lake. |
| **PARTICIONAMENTO** | Padr√£o de particionamento utilizado, visando performance de leitura e organiza√ß√£o dos dados. |
| **CAMPO**           | Nome da coluna. |
| **TYPE**            | Tipo de dado (string, int, double, etc.). |
| **PATTERN**         | Express√£o ou formato esperado (ex: regex, padr√£o ISO, etc.). |
| **OBRIGATORIO**     | Indica se o campo √© obrigat√≥rio ou n√£o. |
| **EXEMPLO**         | Um valor de exemplo para facilitar a interpreta√ß√£o. |
| **DESCRI√á√ÉO**       | Explica√ß√£o clara e funcional da regra de neg√≥cio atrelada ao campo. |


> [!NOTE]
> A maior parte das regras funcionais est√° associada √† estrutura final do dado e aos filtros aplicados durante a transforma√ß√£o. Por se tratar de dados **semiestruturados ou n√£o estruturados**, n√£o √© poss√≠vel aplicar todas as valida√ß√µes convencionais com rigidez. Assim, o foco deste dicion√°rio est√° em garantir a vis√£o **mais pr√≥xima poss√≠vel do modelo de sa√≠da**, com √™nfase na **estrutura de schema**, padr√µes m√≠nimos esperados e crit√©rios funcionais j√° implementados.

Este documento ser√° atualizado continuamente conforme novas regras forem implementadas ou alteradas nos pipelines. Ele deve ser utilizado como **refer√™ncia oficial** para an√°lises e desenvolvimento do projeto Compass.

---

<details>
<summary><strong>üé≤ Mostrar dicion√°rio de dados:</strong> Apple Store {application ingestion}  </summary>

<br>

| DIRETORIO                                                                 | PARTICIONAMENTO | ORIGEM      | CAMPO                    | TYPE      | OBRIGATORIO | EXEMPLO                                       | DESCRI√á√ÉO                                              | LOCALIZA√á√ÉO DAG/JOB                           |
|---------------------------------------------------------------------------|------------------|-------------|---------------------------|---------|-------------|-----------------------------------------------|---------------------------------------------------------|------------------------------------------------|
| /santander/bronze/compass/reviews/appleStore/banco-santander-br_pf/      | odate=yyyyMMdd   | Apple Store | author_name              | string    |S            | Flavia Lemes                                  | Campo do nome da avalia√ß√£o.                             | group_jobs_apple ‚Üí APPLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/appleStore/banco-santander-br_pf/      | odate=yyyyMMdd   | Apple Store | author_uri               | string    |S            | https://itunes.apple.com/br/reviews/id12083758426 | Campo da URI do autor da avalia√ß√£o.                    | group_jobs_apple ‚Üí APPLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/appleStore/banco-santander-br_pf/      | odate=yyyyMMdd   | Apple Store | content                  | string    |S            | app n√£o cair notifica√ß√£o                       | Campo com o conte√∫do da avalia√ß√£o.                      | group_jobs_apple ‚Üí APPLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/appleStore/banco-santander-br_pf/      | odate=yyyyMMdd   | Apple Store | content_attributes_label | string    |S            | Aplicativo                                     | Categoria atribu√≠da ao conte√∫do da avalia√ß√£o.          | group_jobs_apple ‚Üí APPLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/appleStore/banco-santander-br_pf/      | odate=yyyyMMdd   | Apple Store | content_attributes_term  | string    |S            | Application                                    | Termo relacionado ao conte√∫do da avalia√ß√£o.            | group_jobs_apple ‚Üí APPLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/appleStore/banco-santander-br_pf/      | odate=yyyyMMdd   | Apple Store | id                       | string    |S            | 12118476144                                   | Identificador √∫nico da avalia√ß√£o.                      | group_jobs_apple ‚Üí APPLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/appleStore/banco-santander-br_pf/      | odate=yyyyMMdd   | Apple Store | im_rating                | integer   |S            | 1                                              | Nota da avalia√ß√£o (1 a 5).                              | group_jobs_apple ‚Üí APPLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/appleStore/banco-santander-br_pf/      | odate=yyyyMMdd   | Apple Store | im_version               | string    |S            | 24.10.2                                       | Vers√£o do aplicativo avaliado.                         | group_jobs_apple ‚Üí APPLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/appleStore/banco-santander-br_pf/      | odate=yyyyMMdd   | Apple Store | im_votecount             | integer   |S            | 0                                              | Quantidade de votos recebidos.                         | group_jobs_apple ‚Üí APPLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/appleStore/banco-santander-br_pf/      | odate=yyyyMMdd   | Apple Store | im_votesum               | integer   |S            | 0                                              | Soma total dos votos recebidos.                        | group_jobs_apple ‚Üí APPLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/appleStore/banco-santander-br_pf/      | odate=yyyyMMdd   | Apple Store | link_attributes_href     | string    |S            | https://itunes.apple.com/br/reviews/id12083758426 | URL do link da avalia√ß√£o.                              | group_jobs_apple ‚Üí APPLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/appleStore/banco-santander-br_pf/      | odate=yyyyMMdd   | Apple Store | link_attributes_related  | string    |S            | related                                       | Tipo de relacionamento do link.                        | group_jobs_apple ‚Üí APPLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/appleStore/banco-santander-br_pf/      | odate=yyyyMMdd   | Apple Store | title                    | string    |S            | App Santander                                 | T√≠tulo da avalia√ß√£o.                                   | group_jobs_apple ‚Üí APPLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/appleStore/banco-santander-br_pf/      | odate=yyyyMMdd   | Apple Store | updated                  | timestamp |S            | 2024-12-30T02:59:00+00:00                    | Data e hora da √∫ltima atualiza√ß√£o da avalia√ß√£o.        | group_jobs_apple ‚Üí APPLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/appleStore/banco-santander-br_pf/      | odate=yyyyMMdd   | Apple Store | odate                    | string    |S            | 20250307                                     | Data de extra√ß√£o no formato yyyyMMdd.                  | group_jobs_apple ‚Üí APPLE_INGESTION_BANCO-SANTANDER-BR |


</details>


<details>
<summary><strong>üé≤ Mostrar dicion√°rio de dados:</strong> Google Play {application ingestion}  </summary>

<br>

| DIRETORIO                                                              | PARTICIONAMENTO  | ORIGEM      | CAMPO       | TYPE    | OBRIGATORIO  | EXEMPLO                                       | DESCRI√á√ÉO                                              | LOCALIZA√á√ÉO DAG/JOB                           |
|------------------------------------------------------------------------|------------------|-------------|-------------|---------|--------------|-----------------------------------------------|--------------------------------------------------------|---------------------------------------------------------|
| /santander/bronze/compass/reviews/googlePlay/banco-santander-br_pf/    | odate=yyyyMMdd   | Google Play | avatar      | string  | N            | https://play-lh.googleusercontent.com/...     | URL da imagem de perfil do autor da avalia√ß√£o.         | group_jobs_google ‚Üí GOOGLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/googlePlay/banco-santander-br_pf/    | odate=yyyyMMdd   | Google Play | date        | string  | S            | March 10, 2019                                | Data textual da avalia√ß√£o (formato Play Store).        | group_jobs_google ‚Üí GOOGLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/googlePlay/banco-santander-br_pf/    | odate=yyyyMMdd   | Google Play | id          | string  | S            | ca9a8eca-ee30-43c2-aaaa-bb10a7b0c774          | Identificador √∫nico da avalia√ß√£o.                      | group_jobs_google ‚Üí GOOGLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/googlePlay/banco-santander-br_pf/    | odate=yyyyMMdd   | Google Play | iso_date    | string  | S            | 2019-03-10T10:00:02Z                          | Data da avalia√ß√£o em formato ISO 8601.                 | group_jobs_google ‚Üí GOOGLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/googlePlay/banco-santander-br_pf/    | odate=yyyyMMdd   | Google Play | likes       | long    | N            | 85                                            | Quantidade de curtidas na avalia√ß√£o.                   | group_jobs_google ‚Üí GOOGLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/googlePlay/banco-santander-br_pf/    | odate=yyyyMMdd   | Google Play | rating      | double  | S            | 1.0                                           | Nota atribu√≠da √† avalia√ß√£o (de 1.0 a 5.0).             | group_jobs_google ‚Üí GOOGLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/googlePlay/banco-santander-br_pf/    | odate=yyyyMMdd   | Google Play | response    | map     | N            | {date -> March 12, 2019, text -> Obrigado!}   | Resposta do app √† avalia√ß√£o, contendo data e texto.    | group_jobs_google ‚Üí GOOGLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/googlePlay/banco-santander-br_pf/    | odate=yyyyMMdd   | Google Play | snippet     | string  | S            | Aplicativo super inst√°vel                     | Texto da avalia√ß√£o feita pelo usu√°rio.                 | group_jobs_google ‚Üí GOOGLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/googlePlay/banco-santander-br_pf/    | odate=yyyyMMdd   | Google Play | title       | string  | S            | Um usu√°rio do Google                          | Nome do autor da avalia√ß√£o (ou pseud√¥nimo do sistema). | group_jobs_google ‚Üí GOOGLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/googlePlay/banco-santander-br_pf/    | odate=yyyyMMdd   | Google Play | odate       | integer | S            | 20250307                                      | Data da coleta da avalia√ß√£o no formato yyyyMMdd.       | group_jobs_google ‚Üí GOOGLE_INGESTION_BANCO-SANTANDER-BR |


</details>


<details>
<summary><strong>üé≤ Mostrar dicion√°rio de dados:</strong> MongoDB, internal database {application ingestion}  </summary>

<br>

| DIRETORIO                                                                | PARTICIONAMENTO  | ORIGEM   | CAMPO          | TYPE    | OBRIGATORIO | EXEMPLO            | DESCRI√á√ÉO                                         | LOCALIZA√á√ÉO DAG/JOB                            |
|--------------------------------------------------------------------------|------------------|----------|----------------|---------|---------------------------------------------------|--------------|---------------------|----------------------------------------------------|
| /santander/bronze/compass/reviews/mongodb/banco-santander-br_pf/         | odate=yyyyMMdd   | MongoDB  | id             | string  | S            | 67c693b10f4ffb0e6...| Identificador √∫nico da avalia√ß√£o.                | group_jobs_mongo ‚Üí MONGO_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/mongodb/banco-santander-br_pf/         | odate=yyyyMMdd   | MongoDB  | comment        | string  | S            | FALTAM INFORMA√á√ïES NO APP | Texto da avalia√ß√£o.                              | group_jobs_mongo ‚Üí MONGO_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/mongodb/banco-santander-br_pf/         | odate=yyyyMMdd   | MongoDB  | votes_count    | int     | N            | 6                   | Quantidade de votos na avalia√ß√£o.                | group_jobs_mongo ‚Üí MONGO_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/mongodb/banco-santander-br_pf/         | odate=yyyyMMdd   | MongoDB  | os             | string  | N            | IOS                 | Sistema operacional do usu√°rio.                  | group_jobs_mongo ‚Üí MONGO_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/mongodb/banco-santander-br_pf/         | odate=yyyyMMdd   | MongoDB  | os_version     | string  | N            | 18.04               | Vers√£o do sistema operacional.                   | group_jobs_mongo ‚Üí MONGO_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/mongodb/banco-santander-br_pf/         | odate=yyyyMMdd   | MongoDB  | country        | string  | N            | BR                  | Pa√≠s do usu√°rio.                                 | group_jobs_mongo ‚Üí MONGO_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/mongodb/banco-santander-br_pf/         | odate=yyyyMMdd   | MongoDB  | age            | int     | N            | 68                  | Idade do usu√°rio.                                | group_jobs_mongo ‚Üí MONGO_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/mongodb/banco-santander-br_pf/         | odate=yyyyMMdd   | MongoDB  | customer_id    | string  | S            | 6461                | ID do cliente no sistema.                        | group_jobs_mongo ‚Üí MONGO_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/mongodb/banco-santander-br_pf/         | odate=yyyyMMdd   | MongoDB  | cpf            | string  | S            | 129.048.657-30      | CPF do cliente.                                  | group_jobs_mongo ‚Üí MONGO_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/mongodb/banco-santander-br_pf/         | odate=yyyyMMdd   | MongoDB  | app_version    | string  | N            | 1.0.0               | Vers√£o do aplicativo.                            | group_jobs_mongo ‚Üí MONGO_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/mongodb/banco-santander-br_pf/         | odate=yyyyMMdd   | MongoDB  | rating         | int     | S            | 4                   | Nota atribu√≠da pelo usu√°rio.                     | group_jobs_mongo ‚Üí MONGO_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/mongodb/banco-santander-br_pf/         | odate=yyyyMMdd   | MongoDB  | timestamp      | string  | S            | 2025-03-04T05:45:...| Data e hora da avalia√ß√£o.                        | group_jobs_mongo ‚Üí MONGO_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/mongodb/banco-santander-br_pf/         | odate=yyyyMMdd   | MongoDB  | app            | string  | S            | banco-santander-br  | Nome do aplicativo.                              | group_jobs_mongo ‚Üí MONGO_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/mongodb/banco-santander-br_pf/         | odate=yyyyMMdd   | MongoDB  | odate          | int     | S            | 20250308            | Data da parti√ß√£o no formato yyyyMMdd.            | group_jobs_mongo ‚Üí MONGO_INGESTION_BANCO-SANTANDER-BR |


</details>

---

<details>
<summary><strong>üé≤ Mostrar dicion√°rio de dados:</strong> Apple Store {application Silver}  </summary>

<br>

| DIRET√ìRIO                                         | PARTICIONAMENTO | ORIGEM      | CAMPO                      | TYPE               | PATTERN                                                | OBRIGAT√ìRIO | EXEMPLO                                                                                                                           | DESCRI√á√ÉO                                                           | LOCALIZA√á√ÉO                             |
|--------------------------------------------------|------------------|-------------|----------------------------|--------------------|--------------------------------------------------------|-------------|------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------|------------------------------------------|
| /santander/silver/compass/reviews/appleStore/    | odate=yyyyMMdd   | Apple Store | id                         | string             | ^\d+$                                                  | S           | 10660374634                                                                                                                      | Identificador √∫nico do review                                              | group_jobs_mongo ‚Üí SILVER_APP_SILVER_APPLE_STORE |
| /santander/silver/compass/reviews/appleStore/    | odate=yyyyMMdd   | Apple Store | name_client                | string             | ^.+$                                                   | S           | GABRIELALVESJ                                                                                                                    | Nome do cliente (em caixa alta)                                           | group_jobs_mongo ‚Üí SILVER_APP_SILVER_APPLE_STORE |
| /santander/silver/compass/reviews/appleStore/    | odate=yyyyMMdd   | Apple Store | app                        | string             | ^[a-z0-9\-_]+$                                         | S           | santander-select-global_pf                                                                                                       | Nome do aplicativo                                                        | group_jobs_mongo ‚Üí SILVER_APP_SILVER_APPLE_STORE |
| /santander/silver/compass/reviews/appleStore/    | odate=yyyyMMdd   | Apple Store | im_version                 | string             | ^\d+(\.\d+)*$                                          | S           | 23.12.2                                                                                                                           | Vers√£o do aplicativo                                                      | group_jobs_mongo ‚Üí SILVER_APP_SILVER_APPLE_STORE |
| /santander/silver/compass/reviews/appleStore/    | odate=yyyyMMdd   | Apple Store | im_rating                  | string             | ^[0-5](\.\d+)?$                                        | S           | 5                                                                                                                                | Avalia√ß√£o num√©rica do usu√°rio (1 a 5)                                     | group_jobs_mongo ‚Üí SILVER_APP_SILVER_APPLE_STORE |
| /santander/silver/compass/reviews/appleStore/    | odate=yyyyMMdd   | Apple Store | title                      | string             | ^.+$                                                   | S           | RECONHECIMENTO FACIAL NAO FUNCIONA                                                                                               | T√≠tulo do review                                                          | group_jobs_mongo ‚Üí SILVER_APP_SILVER_APPLE_STORE |
| /santander/silver/compass/reviews/appleStore/    | odate=yyyyMMdd   | Apple Store | content                    | string             | - obs: valida√ß√£o do se o campo √© nulo!                 | S           | TENHO BIOMETRIA FACIAL CADASTRADA NO APP...                                                                                      | Conte√∫do completo do review                                               | group_jobs_mongo ‚Üí SILVER_APP_SILVER_APPLE_STORE |
| /santander/silver/compass/reviews/appleStore/    | odate=yyyyMMdd   | Apple Store | updated                    | string             | -                                                      | S           | 2023-12-12T20:35:52-07:00                                                                                                         | Data e hora da √∫ltima atualiza√ß√£o (formato ISO 8601)                     | group_jobs_mongo ‚Üí SILVER_APP_SILVER_APPLE_STORE |
| /santander/silver/compass/reviews/appleStore/    | odate=yyyyMMdd   | Apple Store | segmento                   | string             | -                                                      | S           | pf                                                                                                                               | Segmento do cliente (pf = pessoa f√≠sica, pj = pessoa jur√≠dica)          | group_jobs_mongo ‚Üí SILVER_APP_SILVER_APPLE_STORE |
| /santander/silver/compass/reviews/appleStore/    | odate=yyyyMMdd   | Apple Store | historical_data.title      | array.struct.string| -                                                      | N           | []                                                                                                                               | Hist√≥rico de t√≠tulos de reviews anteriores                                | group_jobs_mongo ‚Üí SILVER_APP_SILVER_APPLE_STORE |
| /santander/silver/compass/reviews/appleStore/    | odate=yyyyMMdd   | Apple Store | historical_data.content    | array.struct.string| -                                                      | N           | []                                                                                                                               | Hist√≥rico de conte√∫dos de reviews anteriores                             | group_jobs_mongo ‚Üí SILVER_APP_SILVER_APPLE_STORE |
| /santander/silver/compass/reviews/appleStore/    | odate=yyyyMMdd   | Apple Store | historical_data.app        | array.struct.string| -                                                      | N           | []                                                                                                                               | Hist√≥rico de nomes de aplicativos                                          | group_jobs_mongo ‚Üí SILVER_APP_SILVER_APPLE_STORE |
| /santander/silver/compass/reviews/appleStore/    | odate=yyyyMMdd   | Apple Store | historical_data.segmento   | array.struct.string| -                                                      | N           | []                                                                                                                               | Hist√≥rico de segmentos                                                    | group_jobs_mongo ‚Üí SILVER_APP_SILVER_APPLE_STORE |
| /santander/silver/compass/reviews/appleStore/    | odate=yyyyMMdd   | Apple Store | historical_data.im_version | array.struct.string| -                                                      | N           | []                                                                                                                               | Hist√≥rico de vers√µes do aplicativo                                        | group_jobs_mongo ‚Üí SILVER_APP_SILVER_APPLE_STORE |
| /santander/silver/compass/reviews/appleStore/    | odate=yyyyMMdd   | Apple Store | historical_data.im_rating  | array.struct.string| -                                                      | N           | []                                                                                                                               | Hist√≥rico de avalia√ß√µes num√©ricas                                          | group_jobs_mongo ‚Üí SILVER_APP_SILVER_APPLE_STORE |
| /santander/silver/compass/reviews/appleStore/    | odate=yyyyMMdd   | Apple Store | odate                      | integer            | -                                                      | S           | 20250409                                                                                                                         | Data de particionamento da carga (formato yyyymmdd)                      | group_jobs_mongo ‚Üí SILVER_APP_SILVER_APPLE_STORE |


</details>

<details>
<summary><strong>üé≤ Mostrar dicion√°rio de dados:</strong> Google Play {application Silver}  </summary>

<br>

  | DIRET√ìRIO                                                 | PARTICIONAMENTO  | ORIGEM      | CAMPO                        | TYPE                   | PATTERN                             | OBRIGAT√ìRIO | EXEMPLO                                                                                                                                                                                                                                   | DESCRI√á√ÉO                                                                                                           | LOCALIZA√á√ÉO                                |
  |-----------------------------------------------------------|------------------|-------------|------------------------------|------------------------|--------------------------------------|--------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------|---------------------------------------------|
  | /santander/silver/compass/reviews/googlePlay/             | odate=yyyyMMdd   | Google Play | id                           | string                 | ^[a-f0-9]{8}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{4}-[a-f0-9]{12}$                       | S            | 0027bfd3-465b-4dec-a7d2-d8467f4751dc                                                                                                                                                                                                     | Identificador √∫nico da avalia√ß√£o                                                                                   | group_jobs_mongo ‚Üí SILVER_APP_SILVER_GOOGLE_PLAY |
  | /santander/silver/compass/reviews/googlePlay/             | odate=yyyyMMdd   | Google Play | app                          | string                 | ^[a-z0-9\-_]+$                         | S            | santander-way_pf                                                                                                                                                                                                                          | Identificador √∫nico do aplicativo                                                                                  | group_jobs_mongo ‚Üí SILVER_APP_SILVER_GOOGLE_PLAY |
  | /santander/silver/compass/reviews/googlePlay/             | odate=yyyyMMdd   | Google Play | segmento                     | string                 | ^(pf|pj)$                                 | S            | pf                                                                                                                                                                                                                                        | Segmento do cliente                                                                                                 | group_jobs_mongo ‚Üí SILVER_APP_SILVER_GOOGLE_PLAY |
  | /santander/silver/compass/reviews/googlePlay/             | odate=yyyyMMdd   | Google Play | rating                       | string                 | ^[1-5](\.\d+)?$                               | S            | 5                                                                                                                                                                                                                                         | Avalia√ß√£o atribu√≠da ao app                                                                                          | group_jobs_mongo ‚Üí SILVER_APP_SILVER_GOOGLE_PLAY |
  | /santander/silver/compass/reviews/googlePlay/             | odate=yyyyMMdd   | Google Play | iso_date                     | string                 | ^\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}Z$ | S            | 2025-02-27T19:18:26Z                                                                                                                                                                                                                      | Data e hora no formato ISO 8601                                                                                      | group_jobs_mongo ‚Üí SILVER_APP_SILVER_GOOGLE_PLAY |
  | /santander/silver/compass/reviews/googlePlay/             | odate=yyyyMMdd   | Google Play | title                        | string                 | ^.+$                                   | S            | GABRIEL CAVALCANTE                                                                                                                                                                                                                         | Nome do usu√°rio que avaliou                                                                                          | group_jobs_mongo ‚Üí SILVER_APP_SILVER_GOOGLE_PLAY |
  | /santander/silver/compass/reviews/googlePlay/             | odate=yyyyMMdd   | Google PLay | snippet                      | string                 | ^.+$                                  | S            | USEI O APP POR MAIS DE DOIS ANOS...                                                                                                                                                                                                       | Texto da avalia√ß√£o fornecida pelo usu√°rio                                                                            | group_jobs_mongo ‚Üí SILVER_APP_SILVER_GOOGLE_PLAY |
  | /santander/silver/compass/reviews/googlePlay/             | odate=yyyyMMdd   | Google Play | historical_data.title        | array.struct.string    | -                               | N            | []                                                                                                                                                                                                                                        | Lista de t√≠tulos hist√≥ricos da avalia√ß√£o                                                                             | group_jobs_mongo ‚Üí SILVER_APP_SILVER_GOOGLE_PLAY |
  | /santander/silver/compass/reviews/googlePlay/             | odate=yyyyMMdd   | Google Play | historical_data.snippet      | array.struct.string    | -                               | N            | []                                                                                                                                                                                                                                        | Lista de trechos hist√≥ricos da avalia√ß√£o                                                                             | group_jobs_mongo ‚Üí SILVER_APP_SILVER_GOOGLE_PLAY |
  | /santander/silver/compass/reviews/googlePlay/             | odate=yyyyMMdd   | Google Play | historical_data.app          | array.struct.string    | -                               | N            | []                                                                                                                                                                                                                                        | Lista de identificadores hist√≥ricos de apps                                                                           | group_jobs_mongo ‚Üí SILVER_APP_SILVER_GOOGLE_PLAY |
  | /santander/silver/compass/reviews/googlePlay/             | odate=yyyyMMdd   | Google Play | historical_data.segmento     | array.struct.string    | -                               | N            | []                                                                                                                                                                                                                                        | Lista de segmentos hist√≥ricos                                                                                        | group_jobs_mongo ‚Üí SILVER_APP_SILVER_GOOGLE_PLAY |
  | /santander/silver/compass/reviews/googlePlay/             | odate=yyyyMMdd   | Google Play | historical_data.rating       | array.struct.string    | -                               | N            | []                                                                                                                                                                                                                                        | Lista de ratings hist√≥ricos                                                                                          | group_jobs_mongo ‚Üí SILVER_APP_SILVER_GOOGLE_PLAY |
  | /santander/silver/compass/reviews/googlePlay/             | odate=yyyyMMdd   | Google Play | historical_data.iso_date     | array.struct.string    | -                               | N            | []                                                                                                                                                                                                                                        | Lista de datas hist√≥ricas no formato ISO 8601                                                                         | group_jobs_mongo ‚Üí SILVER_APP_SILVER_GOOGLE_PLAY |
  | /santander/silver/compass/reviews/googlePlay/             | odate=yyyyMMdd   | Google Play | odate                        | integer                | -                              | S            | 20250409                                                                                                                                                                                                                                  | Data de parti√ß√£o no formato yyyyMMdd                                                                                 | group_jobs_mongo ‚Üí SILVER_APP_SILVER_GOOGLE_PLAY |

</details>



</details>

<details>
<summary><strong>üé≤ Mostrar dicion√°rio de dados:</strong> Mongo DB (internal Database) {application Silver}  </summary>

<br>

| DIRET√ìRIO                                              | PARTICIONAMENTO   | ORIGEM                    | CAMPO                        | TYPE                 | PATTERN                  | OBRIGAT√ìRIO | EXEMPLO                                                  | DESCRI√á√ÉO                                                                                         | LOCALIZA√á√ÉO                                        |
|--------------------------------------------------------|--------------------|----------------------------|------------------------------|----------------------|---------------------------|-------------|----------------------------------------------------------|---------------------------------------------------------------------------------------------------|---------------------------------------------------|
| /santander/silver/compass/reviews/mongodb/            | odate=yyyyMMdd     | Mongo DB (internal database) | id                           | string               | ^[a-f0-9]+$             | S           | 67c69308ca13ea1488ad2812                                 | Identificador √∫nico do registro no MongoDB                                                      | group_jobs_mongo ‚Üí SILVER_APP_SILVER_INTERNAL_BASE |
| /santander/silver/compass/reviews/mongodb/            | odate=yyyyMMdd     | Mongo DB (internal database) | customer_id                  | string               | - obs: valida√ß√£o do se o campo √© nulo!                        | S           | 5436                                                     | Identificador do cliente                                                                         | group_jobs_mongo ‚Üí SILVER_APP_SILVER_INTERNAL_BASE |
| /santander/silver/compass/reviews/mongodb/            | odate=yyyyMMdd     | Mongo DB (internal database) | cpf                          | string               | ^\d{11}$|^\d{3}\.\d{3}\.\d{3}-\d{2}$ | S           | 471.962.380-87                                           | CPF do cliente                                                                                   | group_jobs_mongo ‚Üí SILVER_APP_SILVER_INTERNAL_BASE |
| /santander/silver/compass/reviews/mongodb/            | odate=yyyyMMdd     | Mongo DB (internal database) | app                          | string               | ^[a-z0-9\-_]+$               | S           | santander-way_pf                                         | Nome do aplicativo                                                                               | group_jobs_mongo ‚Üí SILVER_APP_SILVER_INTERNAL_BASE |
| /santander/silver/compass/reviews/mongodb/            | odate=yyyyMMdd     | Mongo DB (internal database) | segmento                     | string               | pf|pj                     | pf,            | pf                                                       | Segmento do cliente                                                                              | group_jobs_mongo ‚Üí SILVER_APP_SILVER_INTERNAL_BASE |
| /santander/silver/compass/reviews/mongodb/            | odate=yyyyMMdd     | Mongo DB (internal database) | rating                       | string               | ^[0-5](\.\d+)?$                     | S           | 1                                                        | Avalia√ß√£o do aplicativo pelo cliente (1 a 5)                                                    | group_jobs_mongo ‚Üí SILVER_APP_SILVER_INTERNAL_BASE |
| /santander/silver/compass/reviews/mongodb/            | odate=yyyyMMdd     | Mongo DB (internal database) | timestamp                    | string               | ^\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}(\.\d+)?$ | S     | 2025-03-04T05:42:06                                    | Data e hora do coment√°rio                                                                       | group_jobs_mongo ‚Üí SILVER_APP_SILVER_INTERNAL_BASE |
| /santander/silver/compass/reviews/mongodb/            | odate=yyyyMMdd     | Mongo DB (internal database) | comment                      | string               | - obs: valida√ß√£o do se o campo √© nulo!                       | S           | EXCELENTE, MAS A INTERFACE...                             | Coment√°rio textual do cliente sobre o app                                                       | group_jobs_mongo ‚Üí SILVER_APP_SILVER_INTERNAL_BASE |
| /santander/silver/compass/reviews/mongodb/            | odate=yyyyMMdd     | Mongo DB (internal database) | app_version                  | string               | ^\d+(\.\d+)*$             | S           | 1.0.0                                                    | Vers√£o do aplicativo                                                                             | group_jobs_mongo ‚Üí SILVER_APP_SILVER_INTERNAL_BASE |
| /santander/silver/compass/reviews/mongodb/            | odate=yyyyMMdd     | Mongo DB (internal database) | os_version                   | string               | ^\d+(\.\d+)*$               | S           | 10.0                                                     | Vers√£o do sistema operacional                                                                   | group_jobs_mongo ‚Üí SILVER_APP_SILVER_INTERNAL_BASE |
| /santander/silver/compass/reviews/mongodb/            | odate=yyyyMMdd     | Mongo DB (internal database) | os                           | string               | ^(Android|IOS)$             | S           | IOS                                                      | Sistema operacional do dispositivo                                                             | group_jobs_mongo ‚Üí SILVER_APP_SILVER_INTERNAL_BASE |
| /santander/silver/compass/reviews/mongodb/            | odate=yyyyMMdd     | Mongo DB (internal database) | historical_data.customer_id  | array.struct.string  | \[.*\]                   | N           | []                                                       | Hist√≥rico de customer_id relacionados                                                           | group_jobs_mongo ‚Üí SILVER_APP_SILVER_INTERNAL_BASE |
| /santander/silver/compass/reviews/mongodb/            | odate=yyyyMMdd     | Mongo DB (internal database) | historical_data.cpf          | array.struct.string  | \[.*\]                   | N           | []                                                       | Hist√≥rico de CPFs relacionados                                                                 | group_jobs_mongo ‚Üí SILVER_APP_SILVER_INTERNAL_BASE |
| /santander/silver/compass/reviews/mongodb/            | odate=yyyyMMdd     | Mongo DB (internal database) | historical_data.app          | array.struct.string  | \[.*\]                   | N           | []                                                       | Hist√≥rico de apps utilizados                                                                   | group_jobs_mongo ‚Üí SILVER_APP_SILVER_INTERNAL_BASE |
| /santander/silver/compass/reviews/mongodb/            | odate=yyyyMMdd     | Mongo DB (internal database) | historical_data.comment      | array.struct.string  | \[.*\]                   | N           | []                                                       | Hist√≥rico de coment√°rios feitos                                                                | group_jobs_mongo ‚Üí SILVER_APP_SILVER_INTERNAL_BASE |
| /santander/silver/compass/reviews/mongodb/            | odate=yyyyMMdd     | Mongo DB (internal database) | historical_data.segmento     | array.struct.string  | \[.*\]                   | N           | []                                                       | Hist√≥rico de segmentos associados                                                              | group_jobs_mongo ‚Üí SILVER_APP_SILVER_INTERNAL_BASE |
| /santander/silver/compass/reviews/mongodb/            | odate=yyyyMMdd     | Mongo DB (internal database) | historical_data.rating       | array.struct.string  | \[.*\]                   | N           | []                                                       | Hist√≥rico de avalia√ß√µes feitas                                                                 | group_jobs_mongo ‚Üí SILVER_APP_SILVER_INTERNAL_BASE |
| /santander/silver/compass/reviews/mongodb/            | odate=yyyyMMdd     | Mongo DB (internal database) | historical_data.timestamp    | array.struct.string  | \[.*\]                   | N           | []                                                       | Hist√≥rico de timestamps de reviews                                                             | group_jobs_mongo ‚Üí SILVER_APP_SILVER_INTERNAL_BASE |
| /santander/silver/compass/reviews/mongodb/            | odate=yyyyMMdd     | Mongo DB (internal database) | historical_data.app_version  | array.struct.string  | \[.*\]                   | N           | []                                                       | Hist√≥rico de vers√µes do aplicativo                                                             | group_jobs_mongo ‚Üí SILVER_APP_SILVER_INTERNAL_BASE |
| /santander/silver/compass/reviews/mongodb/            | odate=yyyyMMdd     | Mongo DB (internal database) | historical_data.os_version   | array.struct.string  | \[.*\]                   | N           | []                                                       | Hist√≥rico de vers√µes do sistema operacional                                                    | group_jobs_mongo ‚Üí SILVER_APP_SILVER_INTERNAL_BASE |
| /santander/silver/compass/reviews/mongodb/            | odate=yyyyMMdd     | Mongo DB (internal database) | odate                        | integer              | \d{8}                    | S           | 20250409                                                 | Data de refer√™ncia da parti√ß√£o (formato yyyyMMdd)                                               | group_jobs_mongo ‚Üí SILVER_APP_SILVER_INTERNAL_BASE |

</details>

---

<details>
<summary><strong>üé≤ Mostrar dicion√°rio de dados:</strong> Dados Agregados {application Gold}  </summary>

<br>

| DIRET√ìRIO                                                        | PARTICIONAMENTO | ORIGEM                                                                 | CAMPO                  | TYPE    |OBRIGAT√ìRIO | EXEMPLO                 | DESCRI√á√ÉO                                                                                  | LOCALIZA√á√ÉO                                       |
|------------------------------------------------------------------|------------------|------------------------------------------------------------------------|------------------------|--------|-------------|--------------------------|---------------------------------------------------------------------------------------------|--------------------------------------------------|
| /santander/gold/compass/reviews/apps_santander_aggregate         | odate=yyyyMMdd   | /santander/silver/compass/reviews/googlePlay, mongodb, appleStore     | app_nome               | string  | S           | BANCO-SANTANDER-BR       | Nome do aplicativo analisado                                                                | group_jobs_mongo ‚Üí GOLD_APP_GOLD_AGGREGATE_REVIEWS_SANTANDER |
| /santander/gold/compass/reviews/apps_santander_aggregate         | odate=yyyyMMdd   | /santander/silver/compass/reviews/googlePlay, mongodb, appleStore     | app_source             | string  | S           | GOOGLE_PLAY              | Fonte da avalia√ß√£o: loja de apps onde a review foi feita                                   | group_jobs_mongo ‚Üí GOLD_APP_GOLD_AGGREGATE_REVIEWS_SANTANDER |
| /santander/gold/compass/reviews/apps_santander_aggregate         | odate=yyyyMMdd   | /santander/silver/compass/reviews/googlePlay, mongodb, appleStore     | periodo_referencia     | string  | S           | 2025-02                  | Per√≠odo de refer√™ncia da avalia√ß√£o (formato YYYY-MM)                                       | group_jobs_mongo ‚Üí GOLD_APP_GOLD_AGGREGATE_REVIEWS_SANTANDER |
| /santander/gold/compass/reviews/apps_santander_aggregate         | odate=yyyyMMdd   | /santander/silver/compass/reviews/googlePlay, mongodb, appleStore     | segmento               | string  | S           | PF                       | Segmento de clientes (PF = Pessoa F√≠sica, PJ = Pessoa Jur√≠dica)                            | group_jobs_mongo ‚Üí GOLD_APP_GOLD_AGGREGATE_REVIEWS_SANTANDER |
| /santander/gold/compass/reviews/apps_santander_aggregate         | odate=yyyyMMdd   | /santander/silver/compass/reviews/googlePlay, mongodb, appleStore     | nota_media             | double  | S           | 2.2                      | Nota m√©dia das avalia√ß√µes dos usu√°rios                                                     | group_jobs_mongo ‚Üí GOLD_APP_GOLD_AGGREGATE_REVIEWS_SANTANDER |
| /santander/gold/compass/reviews/apps_santander_aggregate         | odate=yyyyMMdd   | /santander/silver/compass/reviews/googlePlay, mongodb, appleStore     | avaliacoes_total       | long    | S           | 449                      | Quantidade total de avalia√ß√µes recebidas                                                   | group_jobs_mongo ‚Üí GOLD_APP_GOLD_AGGREGATE_REVIEWS_SANTANDER |
| /santander/gold/compass/reviews/apps_santander_aggregate         | odate=yyyyMMdd   | /santander/silver/compass/reviews/googlePlay, mongodb, appleStore     | comentarios_positivos  | long    | S           | 38                        | Quantidade de coment√°rios positivos          | group_jobs_mongo ‚Üí GOLD_APP_GOLD_AGGREGATE_REVIEWS_SANTANDER |
| /santander/gold/compass/reviews/apps_santander_aggregate         | odate=yyyyMMdd   | /santander/silver/compass/reviews/googlePlay, mongodb, appleStore     | comentarios_negativos  | long    | S           | 27                       | Quantidade de coment√°rios negativos                                                        | group_jobs_mongo ‚Üí GOLD_APP_GOLD_AGGREGATE_REVIEWS_SANTANDER |

</details>

---

<details>
<summary><strong>üé≤ Exibir Dicion√°rio de Dados: Dados Rejeitados (Data Quality - Application)</strong></summary>

<br>

O processo de verifica√ß√£o da qualidade dos dados de reviews no projeto **Compass** √© realizado a partir de m√∫ltiplas fontes, estruturadas por data de processamento e carga (`odate=yyyyMMdd`). Abaixo est√£o os principais diret√≥rios, particionamentos e fontes envolvidos no pipeline:

---

**Diret√≥rios da Camada de Qualidade (Quality Layer)**

- `/santander/quality/compass/reviews/schema/odate={odate}`
- `/santander/quality/compass/reviews/pattern/google_play/odate={odate}`
- `/santander/quality/compass/reviews/pattern/apple_store/odate={odate}`
- `/santander/quality/compass/reviews/pattern/internal_databases/odate={odate}`

> [!NOTE>
> As cargas executadas pelo pipeline de Data Quality podem apresentar varia√ß√µes no schema e nos dados, de acordo com a origem. Essas diverg√™ncias s√£o esperadas nas camadas **Bronze** e **Silver**.

---

**Estrutura das Camadas de Dados**

| **Camada** | **Particionamento** | **Caminho Base**                                                                 |
|------------|---------------------|----------------------------------------------------------------------------------|
| Bronze     | `odate=yyyyMMdd`    | `/santander/bronze/compass/reviews/appleStore/<nome-app_segmento>`             |
| Bronze     | `odate=yyyyMMdd`    | `/santander/bronze/compass/reviews/googlePlay/<nome-app_segmento>`             |
| Bronze     | `odate=yyyyMMdd`    | `/santander/bronze/compass/reviews/mongodb/<nome-app_segmento>`                |
| Silver     | `odate=yyyyMMdd`    | `/santander/silver/compass/reviews/appleStore/`                                 |
| Silver     | `odate=yyyyMMdd`    | `/santander/silver/compass/reviews/googlePlay/`                                 |
| Silver     | `odate=yyyyMMdd`    | `/santander/silver/compass/reviews/mongodb/`                                    |

---

**Exemplo de Schema com Registros Rejeitados**

Exemplo de estrutura de schema gerada para registros rejeitados, com detalhamento dos campos inconsistentes:

```
|-- id: string (nullable = true)
|-- name_client: string (nullable = true)
|-- app: string (nullable = true)
|-- im_version: string (nullable = true)
|-- im_rating: string (nullable = true)
|-- title: string (nullable = true)
|-- content: string (nullable = true)
|-- updated: string (nullable = true)
|-- segmento: string (nullable = true)
|-- historical_data: array (nullable = true)
|    |-- element: struct (containsNull = true)
|        |-- title: string (nullable = true)
|        |-- content: string (nullable = true)
|        |-- app: string (nullable = true)
|        |-- segmento: string (nullable = true)
|        |-- im_version: string (nullable = true)
|        |-- im_rating: string (nullable = true)
|-- failed_columns: array (nullable = true)
|    |-- element: string (containsNull = true)
|-- validation: string (nullable = true)
|-- odate: integer (nullable = true)
```

---

**Compara√ß√£o de Schemas (Rejei√ß√µes por Incompatibilidade)**

| **Schema Atual** | **Schema Esperado** | **Fonte**     | **Status de Valida√ß√£o** |
|------------------|----------------------|---------------|--------------------------|
| `StructType([... votes_count: IntegerType(), ...])` | `StructType([... votes_count: StringType(), ...])` | mongodb      | `no_match`              |
| `StructType([... im_votesum: StringType(), ...])`   | `StructType([... im_votesum: IntegerType(), ...])` | apple_store | `no_match`              |

</details>

---

## 5.3 Produtos Compass

---

üß≠ Dashboard Funcional - Ger√™ncia


Este dashboard apresenta indicadores funcionais relacionados √† experi√™ncia do cliente com os canais digitais de uma Institui√ß√£o Financeira (apps m√≥veis - no case utilizamos a Institui√ß√£o Financeira Santander). Ele consolida m√©tricas extra√≠das de diversas fontes (Google Play, Apple Store, MongoDB - considerado como uma base interna), com foco na volumetria e avalia√ß√£o qualitativa de usu√°rios.


> [!NOTE]  
> Para informa√ß√µes detalhada de cada item do Dashboard, favor, consultar o t√≥pico **3.1.4 Camada de Visualiza√ß√£o e Telemetria (observabilidade)**

- Objetivo: Monitorar a qualidade percebida pelos usu√°rios nos aplicativos Santander.
- P√∫blico-alvo: Times de Produto, Experi√™ncia de Usu√°rio e Ger√™ncia. 
- Frequ√™ncia de atualiza√ß√£o: Di√°rio.
- Fontes de dados: Google Play, Apple Store e MongoDB.

üìå Filtros Globais do Dashboard: 

- Canais: Permite selecionar os canais (WAY, SELECT, BR).
- Fonte de Dados: Escolha entre fontes como Apple Store, Google Play e MongoDB.
- Segmento: PF ou PJ.
- Ano-M√™s: Para recortes temporais mensais.

üìå Paineis: 

1. Dashbord
2. Vis√£o Agregada:
3. Vis√£o Detalhada: 


![<metabase-metricas-funcionais>](https://github.com/gacarvalho/compass-deployment/blob/compass/infra-3.0.0/img/metabase-metricas-funcionais.gif?raw=true)

---

üß≠ Dashboard T√©cnico - Aplica√ß√µes e Dashboard T√©cnico - Sustenta√ß√£o  

Este dashboard foi desenvolvido para fornecer uma vis√£o t√©cnica consolidada da execu√ß√£o dos pipelines no projeto Compass, permitindo o monitoramento cont√≠nuo da sa√∫de operacional, da qualidade dos dados e da sustenta√ß√£o dos processos em produ√ß√£o.


üìå O que voc√™ encontrar√° neste painel:

  - Status geral do pipeline: identifica√ß√£o clara de execu√ß√µes bem-sucedidas ou com falhas.
  - Volume de jobs executados, com detalhamento entre sucessos e falhas.
  - Indicadores de qualidade de dados, incluindo:
  - Presen√ßa de valores nulos;
  - Inconsist√™ncias nos dados;
  - Registros duplicados.
  - Painel de Sustenta√ß√£o, com:
  - Marca√ß√£o de timestamp dos erros mais recentes;
  - Tabela com a criticidade dos jobs (escala de 0 a 2, sendo 0 o mais cr√≠tico);
  - Relat√≥rio de erros espec√≠ficos que causaram falhas na execu√ß√£o.

üìå P√∫blico-alvo

Este painel √© direcionado a times t√©cnicos de Engenharia de Dados, Sustenta√ß√£o e Opera√ß√µes, com o objetivo de garantir resposta √°gil a incidentes, visibilidade total do processo e tomada de decis√£o baseada em evid√™ncias.


> [!NOTE]  
> Para informa√ß√µes detalhada de cada item do Dashboard, favor, consultar o t√≥pico **3.1.4 Camada de Visualiza√ß√£o e Telemetria (observabilidade)**

<p align="center">
  <img src="https://github.com/gacarvalho/compass-deployment/blob/compass/infra-3.0.0/img/grafana_apps.png?raw=true" width="49%">
  <img src="https://github.com/gacarvalho/compass-deployment/blob/compass/infra-3.0.0/img/grafana_sustentacao.png?raw=true" width="49%">
</p>

---

# 6. Instru√ß√µes para Configura√ß√£o e Execu√ß√£o do Projeto Compass
---

## 6.1 Pr√©-requisitos
---
### Requisitos da M√°quina Local
- **CPU:** M√≠nimo de 4 vCPUs
- **Mem√≥ria RAM:** M√≠nimo 32 GB
- **Sistema Operacional:** Linux (recomendado)

### Requisitos de Conectividade
- **Acesso √† Internet:** Necess√°rio para download de imagens, depend√™ncias e integra√ß√£o com APIs externas

### Portas Necess√°rias (Protocolos TCP)
Certifique-se de que as seguintes portas estejam **liberadas**:

| Porta | Descri√ß√£o / Servi√ßo Relacionado      |
|-------|--------------------------------------|
| 32763 | Namenode                             |
| 8188  | History Server (YARN)                |
| 8088  | ResourceManager (YARN)               |
| 8084  | Spark Master                         |
| 8085  | Metabase                             |
| 4000  | Grafana                              |

> **Nota:** Ajuste as portas personalizadas conforme sua stack.

### Ferramentas Necess√°rias
- **Git** ‚Äì para clonar o reposit√≥rio do projeto
- **Docker e Docker Compose** ‚Äì para orquestra√ß√£o dos servi√ßos via containers e adicione o usu√°rio atual ao grupo docker, o que permite que ele execute comandos Docker sem precisar usar sudo. `sudo usermod -aG docker $USER` e para ativar o comando sem reiniciar a maquina utilize `newgrp docker`
- **Acesso Root** ‚Äì necess√°rio para instala√ß√µes, permiss√µes e execu√ß√£o de containers com privil√©gios
- **Make** ‚Äì para executar comandos definidos no Makefile que facilitam tarefas como build, deploy e testes


> [!NOTE]
> Certifique-se de atender **todos os requisitos m√≠nimos**, especialmente os relacionados √† **m√°quina local**. Eles s√£o fundamentais para garantir o funcionamento adequado e o desempenho esperado do projeto.

---


## 6.2 Passos de configura√ß√£o e execu√ß√£o do Projeto Compass
---

üß≠ **Execu√ß√£o 1 - Replica√ß√£o do projeto via reposit√≥rio** 

Clonagem do Reposit√≥rio

Clone o reposit√≥rio utilizando o comando abaixo ou acesse diretamente atrav√©s do link: [compass-deployment](https://github.com/gacarvalho/compass-deployment)

```bash
git clone https://github.com/gacarvalho/compass-deployment.git
```

Inicializa√ß√£o do Docker Swarm

Dentro do diret√≥rio raiz do projeto `compass-deployment`, inicialize o Docker Swarm com o seguinte comando:

```bash
docker swarm init
```

![<docker-swarm-init>](https://github.com/gacarvalho/compass-deployment/blob/compass/infra-3.0.0/img/1.2-docker-swarm-init.png)

Cria√ß√£o da Rede Docker

A cria√ß√£o da rede ser√° realizada via `Makefile`. Certifique-se de estar na raiz do reposit√≥rio conforme o path abaixo:

> **Exemplo -  raiz do projeto**: `{path-projeto}/compass-deployment$`

Execute o comando a seguir:

```bash
make create-network
```

![<docker-swarm-create-network>](https://github.com/gacarvalho/compass-deployment/blob/compass/infra-3.0.0/img/1.3-create-network.png)

Para preparar o ambiente, execute o seguinte comando para criar a estrutura de diret√≥rios necess√°ria dentro de {projeto}/mnt:

```bash
# Cria o grupo 'airflow' (caso n√£o exista) -> Necess√°rio para executar o comando make prepare-mnt
sudo groupadd airflow

# Cria o usu√°rio 'airflow', adiciona-o ao grupo 'airflow' e cria seu diret√≥rio home -> Necess√°rio para executar o comando make prepare-mnt
sudo useradd -m -g airflow airflow

make prepare-mnt
```

O resultado esperado √© algo semelhante ao log abaixo:

![<prepare-mnt>](https://github.com/gacarvalho/compass-deployment/blob/compass/infra-3.0.0/img/prepare-mnt.png)


Configura√ß√£o do Arquivo `.env`

Crie um arquivo de vari√°veis de ambiente no diret√≥rio indicado:

```bash
touch services/batch_layer/.env
```

Cole o conte√∫do abaixo dentro do arquivo `.env`:

> [!IMPORTANT]
> Substitua o valor de `SERPAPI_KEY=<mudanca_1>` pela sua chave de API obtida no site da [SERPAPI](https://serpapi.com/users/sign_in)

```env
MONGO_USER_ADMIN=gacarvalho
MONGO_PASS_ADMIN=santand@r
MONGO_USER=app_user
MONGO_PASS=secure_password123
MONGO_HOST=mongodb
MONGO_PORT=27017
MONGO_DB=compass
SERPAPI_KEY=<mudanca_1>
AIRFLOW_IMAGE_NAME=apache/airflow:2.5.1
AIRFLOW_PROJ_DIR=../../mnt/airflow/
AIRFLOW_UID=50000
POSTGRES_PASSWORD=airflow
POSTGRES_DB=airflow
AIRFLOW_ENV_DIR=.
ES_USER=elastic
ES_PASS=data-@a1
```

![<SERAPI>](https://github.com/gacarvalho/compass-deployment/blob/compass/infra-3.0.0/img/1.4.SER_API.png)

E fa√ßa uma c√≥pia do arquivo `.env` para uma pasta que voc√™ dever√° criar tamb√©m em `/env` na raiz do computador!

```bash
sudo mkdir /env
cp services/batch_layer/.env /env/
```

**Deployment do Elastic**
---

Crie as pastas necess√°rias e ajuste as permiss√µes de acesso:

```bash
mkdir -p ~/compass-deployment/mnt/certs
mkdir -p ~/compass-deployment/mnt/es_data
mkdir -p ~/compass-deployment/mnt/certs/es-node/
sudo chmod -R 777 mnt/es_data
sudo chmod -R 777 mnt/certs
sudo chmod -R 777 mnt/certs/es-node/
```

Gera√ß√£o de Certificados SSL

Cria√ß√£o da Autoridade Certificadora (CA)

```bash
openssl genpkey -algorithm RSA -out ca.key
openssl req -new -x509 -key ca.key -out ca.crt -days 365 -subj "/CN=Elasticsearch CA"
```

Gera√ß√£o do Certificado para o n√≥ do ElasticSearch

```bash
openssl genpkey -algorithm RSA -out es-node.key
openssl req -new -key es-node.key -out es-node.csr -subj "/CN=es-node"
openssl x509 -req -in es-node.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out es-node.crt -days 365
```

C√≥pia dos Certificados para o Diret√≥rio Esperado

```bash
user@maquina:~/compass-deployment/mnt$ 
.
‚îú‚îÄ‚îÄ certs
‚îÇ   ‚îú‚îÄ‚îÄ ca.crt
‚îÇ   ‚îú‚îÄ‚îÄ ca.key
‚îÇ   ‚îú‚îÄ‚îÄ es-node
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ca.key
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ es-node.crt
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ es-node.csr
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ es-node.key
‚îÇ   ‚îú‚îÄ‚îÄ es-node.crt
‚îÇ   ‚îú‚îÄ‚îÄ es-node.csr
‚îÇ   ‚îî‚îÄ‚îÄ es-node.key
‚îú‚îÄ‚îÄ es_data
```

E al√©m disso, vai ser necess√°rio atribuir as permiss√µes necess√°rias para cada arquivo e pasta:

```bash
sudo chown 1000:1000 mnt/certs/*
sudo chown 1000:1000 mnt/certs/es-node/*

sudo chmod 644 mnt/certs/*
sudo chmod 644 mnt/certs/es-node/*

```

Verifica√ß√£o do Caminho dos Certificados

Certifique-se de que os caminhos no arquivo YAML `compass-deployment/services/batch_layer/deployment-elasticsearch-service.yaml` est√£o configurados corretamente de acordo com o **volumes**, conforme o exemplo abaixo:

```yaml
services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.16.1
    environment:
      - node.name=es-node
      - cluster.name=es-cluster
      - discovery.seed_hosts=elasticsearch
      - cluster.initial_master_nodes=es-node
      - bootstrap.memory_lock=true
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
      - xpack.security.enabled=true
      - xpack.security.http.ssl.enabled=false
      - xpack.security.transport.ssl.enabled=true
      - xpack.security.transport.ssl.key=/usr/share/elasticsearch/config/certs/es-node/es-node.key
      - xpack.security.transport.ssl.certificate=/usr/share/elasticsearch/config/certs/es-node/es-node.crt
      - xpack.security.transport.ssl.certificate_authorities=/usr/share/elasticsearch/config/certs/ca.crt
      - ELASTIC_PASSWORD=data-@a1
    volumes:
      - ../../mnt/es_data:/usr/share/elasticsearch/data
      - ../../mnt/certs:/usr/share/elasticsearch/config/certs
```

**Deployment do Kibana**
---

Ao subirmos o container do Elasticsearch, vai ser necess√°rio **criar um usu√°rio de acesso antes de subirmos o kibana**, para isso, ser√° necess√°rio entrar no container do elasticsearch e criar um usu√°rio:

Identificar o container:

```bash
user@maquina:~/compass-deployment$ docker ps | grep elastic
809cdeb0aa11   docker.elastic.co/elasticsearch/elasticsearch:8.16.1   "/bin/tini -- /usr/l‚Ä¶"   24 minutes ago   Up 24 minutes   9200/tcp, 9300/tcp   deployment-elasticsearch_elasticsearch.1.uinpl1zt1e5f0i19eqdd6u5y9
```
Entrar no container:

>[!NOTE]
> Importante substituir o nome do container **deployment-elasticsearch_elasticsearch.1.uinpl1zt1e5f0i19eqdd6u5y9** pelo nome do seu container!

```bash
azureuser@vm-data-master-prd-compass-infra-replicate:~/compass-deployment$ docker exec -it deployment-elasticsearch_elasticsearch.1.uinpl1zt1e5f0i19eqdd6u5y9 bash
```

Caso tente subir os cont√™ineres antes de criar o usu√°rio no Elasticsearch, observar-se-√° que o cont√™iner do Kibana permanecer√° com scale de 0/1, pois ocorrer√° um erro de usu√°rio n√£o encontrado.



```bash
| Root causes: deployment-elasticsearch_kibana.1.8znz03ebk56q@vm-data-master-prd-compass-infra-replicate    
|                     security_exception: unable to authenticate user [kibana_user_service] for REST request [/_nodes?
```

Agora no shell do container do elasticsearch, executar o comando de cria√ß√£o de usu√°rio:

```bash
curl -X POST "http://elasticsearch:9200/_security/user/kibana_user" \
  -H "Content-Type: application/json" \
  -u elastic:data-@a1 \
  -d '{"password":"data-@a1","roles":["kibana_system"],"full_name":"Kibana User","email":"kibana_user@compass.com"}'
```

Depois da cria√ß√£o do usu√°rio, rodando o comando `make deployment-elasticsearch-service` na raiz do projeto `/compass-deployment$` para deployarmos novamente o container do kibana pelo yaml base, logo ap√≥s a execu√ß√£o, o resultado dever√° ser o mesmo do print abaixo, onde os containers subiram com sucesso! 

Ou voce poder√° dar restart apenas no container do kibana com o comando `docker service update --force deployment-elasticsearch_kibana` que o resultado ser√° o mesmo!


![elastic-kibana-running](https://github.com/gacarvalho/compass-deployment/blob/compass/infra-3.0.0/img/elastic-kibana-running.png)

Agora ser√° necess√°rio acessar a interface do Kibana pelo **usu√°rio** `elastic` e com  **senha** `data-@a1` pelo seu endere√ßo ip e porta: `<ip>:5601`

![elastic-kibana-running](https://github.com/gacarvalho/compass-deployment/blob/compass/infra-3.0.0/img/kibana-running.png)

**Cria√ß√£o do space e os indices**
---

Dentro do **container do Kibana**, voce pode criar o space tanto pela interface quanto pelo terminal pelo comando abaixo:

```bash
curl -u 'elastic:data-@a1' -X POST "http://localhost:5601/api/spaces/space" \
  -H "kbn-xsrf: true" \
  -H "Content-Type: application/json" \
  -d '{
        "id": "compass",
        "name": "compass",
        "description": "Space do projeto Compass",
        "color": "#FF5733"
    }'

```

Agora no **container do elasticsearch** voc√™ dever√° criar os indices do Elastic no terminal pelo comando abaixo:

1. Execu√ß√£o:

```bash
curl -u 'elastic:data-@a1' -X PUT "http://localhost:9200/compass_dt_datametrics" -H 'Content-Type: application/json' -d '{
  "mappings": {
    "properties": {
      "timestamp": {
        "type": "date"
      }
    }
  }
}'
```


2. Execu√ß√£o:

```bash
curl -u 'elastic:data-@a1' -X PUT "http://localhost:9200/compass_dt_datametrics_fail" -H 'Content-Type: application/json' -d '{
  "mappings": {
    "properties": {
      "timestamp": {
        "type": "date"
      }
    }
  }
}'
```

O resultado dever√° ser igual da imagem abaixo:

![elastic-create-indices](https://github.com/gacarvalho/compass-deployment/blob/compass/infra-3.0.0/img/elastic-create-indices.png)
![elastic-create-indices](https://github.com/gacarvalho/compass-deployment/blob/compass/infra-3.0.0/img/indices-elastic-kibana.png)

**Deployment do  Airflow**
---

Antes de iniciar o deploy do Airflow, √© essencial preparar o ambiente, garantindo que a estrutura de diret√≥rios, permiss√µes e usu√°rios estejam corretamente configurados.

Deploy do Servi√ßo Airflow via Makefile

Para realizar o deploy inicial do servi√ßo Airflow, execute:

```bash
make deployment-airflow-service
```

Caso necess√°rio, siga os ajustes descritos abaixo.

---

**Ajustes no Host**

Ajustar UID do Usu√°rio `airflow`

Garante que o UID do usu√°rio `airflow` no host corresponda ao UID do container (50000), evitando conflitos de permiss√µes em volumes:

```bash
sudo usermod -u 50000 airflow
```

Criar Usu√°rio e Grupo `airflow` (caso n√£o existam)

```bash
sudo groupadd airflow
sudo useradd -r -m -g airflow airflow
```

**Ajustar Permiss√µes dos Diret√≥rios**

Definir o usu√°rio e grupo corretos nas pastas de volumes montados:

```bash
sudo chown -R airflow:airflow /mnt/airflow/
sudo chown -R airflow:airflow /opt/airflow/
```

**Ajustar Permiss√µes no Diret√≥rio de Logs**

```bash
sudo chmod -R 755 /opt/airflow/logs
sudo mkdir -p /opt/airflow/logs/scheduler
```

Para acesso local (opcional, apenas durante desenvolvimento):

```bash
sudo chown -R $(whoami):$(whoami) /opt/airflow/logs
chmod -R 775 /opt/airflow/logs
sudo chown -R airflow:airflow /opt/airflow/logs
```

**Preparar Diret√≥rio de Plugins**

```bash
sudo mkdir -p /mnt/airflow/plugins
sudo chmod -R 775 /mnt/airflow/plugins/
```

---

**Verifica√ß√£o dos Volumes**

Liste os diret√≥rios para garantir a estrutura correta:

```bash
ls -la /opt/airflow/
ls -la /opt/airflow/logs/
```

Certifique-se de que as permiss√µes estejam corretas.

---

**üõ†Ô∏è Inicializa√ß√£o e Ajuste do Banco de Dados**

Ap√≥s os ajustes:

```bash
make deployment-airflow-service
```

Verifique se os servi√ßos est√£o no ar:

```bash
docker service ls
```

Exemplo de retorno do comando:

```
ID             NAME                                     MODE         REPLICAS   IMAGE                      PORTS
crejifngbav2   deployment-airflow_airflow-cli           replicated   1/1        apache/airflow:2.7.2        
crepz316peh3   deployment-airflow_airflow-init          replicated   0/1        apache/airflow:2.7.2        
lcqyejkpfods   deployment-airflow_airflow-scheduler     replicated   1/1        apache/airflow:2.7.2        
eauq2oh0x53x   deployment-airflow_airflow-triggerer     replicated   1/1        apache/airflow:2.7.2        
mb2bh1kcun4f   deployment-airflow_airflow-webserver     replicated   1/1        apache/airflow:2.7.2      *:8080->8080/tcp
3veo92az5ntq   deployment-airflow_airflow-worker        replicated   1/1        apache/airflow:2.7.2        
nbzi9a39elnr   deployment-airflow_flower                replicated   1/1        apache/airflow:2.7.2      *:5555->5555/tcp
v7130tavltgo   deployment-airflow_postgres              replicated   1/1        postgres:13                
syt6imxu24kb   deployment-airflow_redis                 replicated   1/1        redis:latest               
```

**Corre√ß√£o de Erro de Inicializa√ß√£o do Banco de Dados**

> ‚ö†Ô∏è Caso o `airflow-webserver` exiba o erro: `ERROR: You need to initialize the database. Please run 'airflow db init'.`

Execute:

```bash
docker exec -it $(docker ps -q -f name=airflow-webserver) bash
airflow db init
airflow db migrate
exit
```

Depois, reimplantamos:

```bash
make deployment-airflow-service
```

---

**Cria√ß√£o do Usu√°rio Admin**

Acesse a interface Web do Airflow:

```
http://<IP-OU-HOST>:8080/
```

Crie o usu√°rio administrador:

```bash
docker exec -it $(docker ps -q -f name=airflow-webserver) airflow users create \
   --username admin \
   --firstname Admin \
   --lastname User \
   --role Admin \
   --email admin@example.com \
   --password admin
```

**Login:**

- **Usu√°rio:** `admin`
- **Senha:** `admin`

Exemplo de visualiza√ß√£o das DAGs:

![Pipeline do Airflow](https://github.com/gacarvalho/compass-deployment/blob/compass/infra-3.0.0/img/airflow-pipeline.png)




**Deployment do Mongo DB**
---

Para subirmos o servi√ßo do Mongo DB, ser√° necess√°rio executar o Makefile para deployarmos:

```bash
make deployment-mongodb-service
```

O resultado esperado com o comando `docker service ls` √© que o scale do pod seja 1/1

```
ID             NAME                                     MODE         REPLICAS   IMAGE                                                  PORTS
hcqtsmor4vzg   deployment-mondodb_database-mongodb      replicated   1/1        mongo:7                                                *:27017->27017/tcp
```

Agora precisamos criar os usu√°rios de servi√ßo e as collections, primeiro ser√° necess√°rio entrar no terminal do container:

```bash
docker exec -it $(docker ps -q -f name=database-mongodb) mongosh admin
```

Agora, ser√° necess√°rio criar as collections com o comando abaixo:

```bash
use compass
db.createCollection('dt_d_view_silver_historical_compass')
db.createCollection('dt_d_view_gold_agg_compass')
```
![create-collections](https://github.com/gacarvalho/compass-deployment/blob/compass/infra-3.0.0/img/create-collections.png)


Depois da cria√ß√£o das collections, ser√° necess√°rio tamb√©m criar um usu√°rio de "servi√ßo", nesse caso estou usando como `gacarvalho`, mas voce pode alterar aqui e posteriormente no arquivo .env do projeto.

```bash
use compass
db.createUser({
  user: "gacarvalho",
  pwd: "santand@r",
  roles: [
    { role: "root", db: "admin" }
  ]
})

db.createUser({
  user: "app_user",
  pwd: "secure_password123",
  roles: [
    { role: "root", db: "admin" }
  ]
})
```

Logo ap√≥s a cria√ß√£o do usu√°rio, voc√™ poder√° sair do container e testar o acesso do usu√°rio novo criado pelo comando abaixo:

```bash
docker exec -it $(docker ps -q -f name=database-mongodb) mongosh "mongodb://gacarvalho:santand@r@localhost:27017/compass?authSource=compass"
```

![create-users-mongo](https://github.com/gacarvalho/compass-deployment/blob/compass/infra-3.0.0/img/create-users-mongo.png)


**Deployment do Hadoop**
---

Agora √© a ver de subir a estrutura do Hadoop, onde contamos com o Namenode, Datanode, History Server, Nodemanager e Resource Manager. Para subirmos os servi√ßos s√≥ vai ser neececess√°rio deployarmos com o comando de makefile, segue o comando abaixo:

```bash
make deployment-hadoop-service
```

E com a subida vamos observar a subida e os scale dos pods:

```bash
ID             NAME                                      MODE         REPLICAS   IMAGE                                                        PORTS
2dv9xw6w3zid   deployment-hadoop_infra-datanode          replicated   2/2        iamgacarvalho/hadoop-datanode-data-in-compass:2.0.0          *:9854-9864->9864/tcp
pxi6bojyb3j6   deployment-hadoop_infra-history-server    replicated   1/1        iamgacarvalho/hadoop-historyserver-data-in-compass:2.0.0     *:8188->8188/tcp
8oea82dervcx   deployment-hadoop_infra-namenode          replicated   1/1        iamgacarvalho/hadoop-namenode-data-in-compass:2.0.0          *:32763->9870/tcp
n4fj7d4bufef   deployment-hadoop_infra-nodemanager       replicated   2/2        iamgacarvalho/hadoop-nodemanager-data-in-compass:2.0.0       *:8032-8042->8042/tcp
wjw7w350t62q   deployment-hadoop_infra-resourcemanager   replicated   1/1        iamgacarvalho/hadoop-resourcemanager-data-in-compass:2.0.0   *:8088->8088/tcp
```

>[!NOTE]
> Ao subirmos o servi√ßo, assim como o Kibana precisa se conectar ao Elastic Search para subir o servi√ßo, o Nodemanager precisa se conectar ao Namenode, se essa conex√£o por algum motivo n√£o acontecer e por ventura o container venha dar erro, favor executar o arquivo de "atualiza√ß√£o" com o comando `docker stack deploy -c services/batch_layer/deployment-update-services.yaml  deployment-update` ou como ponto de certeza, voc√™ poder√° executar o comando `docker service update --force deployment-hadoop_infra-nodemanager` for√ßando o restart do container, pois ao acessar o resource manager o **Active Nodes** dever√° ficar com valor igual a 3!	

![hadoop](https://github.com/gacarvalho/compass-deployment/blob/compass/infra-3.0.0/img/hadoop.png)
![resource-manager](https://github.com/gacarvalho/compass-deployment/blob/compass/infra-3.0.0/img/rm.png)
![namenode](https://github.com/gacarvalho/compass-deployment/blob/compass/infra-3.0.0/img/namenode.png)


**Deployment do Grafana**
---

Agora, vamos subir o servi√ßo do Grafana pelo comando abaixo:

```bash
make deployment-grafana-service
```

O resultado esperado √©:

```
ID             NAME                                      MODE         REPLICAS   IMAGE                                                        PORTS
kexswnm9zbpo   deployment-grafana_grafana                replicated   2/2        grafana/grafana:latest                                       *:4000->3000/tcp
```

No endere√ßo `<ip>:4000` e com o usu√°rio: `admin` e a senha `admin123` voce consegue acessar a interface do Grafana. 

A ideia agora √© que voce fa√ßa o importe dos dashboard para o seu Grafana, na op√ß√£o **Menu** > **Dashboard** > **Op√ß√£o New** > **Import** > **Op√ß√£o Import via dashboard JSON model**, cole o JSON abaixo:

<details>
  <summary>Acesse aqui o JSON detalhado </summary> 

  **Dashboard: COMPASS - Opera√ß√£o Aplicacional**
      
  ```json
    {
      "annotations": {
        "list": [
          {
            "builtIn": 1,
            "datasource": {
              "type": "grafana",
              "uid": "-- Grafana --"
            },
            "enable": true,
            "hide": true,
            "iconColor": "rgba(0, 211, 255, 1)",
            "name": "Annotations & Alerts",
            "type": "dashboard"
          }
        ]
      },
      "editable": true,
      "fiscalYearStartMonth": 0,
      "graphTooltip": 0,
      "id": 2,
      "links": [],
      "liveNow": true,
      "panels": [
        {
          "fieldConfig": {
            "defaults": {},
            "overrides": []
          },
          "gridPos": {
            "h": 2,
            "w": 7,
            "x": 0,
            "y": 0
          },
          "id": 18,
          "options": {
            "code": {
              "language": "plaintext",
              "showLineNumbers": false,
              "showMiniMap": false
            },
            "content": "\n# TV [OPERA√á√ÉO MALHA COMPASS]",
            "mode": "markdown"
          },
          "pluginVersion": "11.5.2",
          "title": "",
          "transparent": true,
          "type": "text"
        },
        {
          "datasource": {
            "type": "elasticsearch",
            "uid": "feex5fk2nn08wf"
          },
          "fieldConfig": {
            "defaults": {},
            "overrides": []
          },
          "gridPos": {
            "h": 2,
            "w": 2,
            "x": 7,
            "y": 0
          },
          "id": 17,
          "options": {
            "bgColor": "transparent",
            "clockType": "24 hour",
            "countdownSettings": {
              "endCountdownTime": "2025-03-08T05:21:06-03:00",
              "endText": "00:00:00",
              "invalidValueText": "invalid value",
              "noValueText": "no value found",
              "queryCalculation": "last",
              "source": "input"
            },
            "countupSettings": {
              "beginCountupTime": "2025-03-08T05:21:06-03:00",
              "beginText": "00:00:00",
              "invalidValueText": "invalid value",
              "noValueText": "no value found",
              "queryCalculation": "last",
              "source": "input"
            },
            "dateSettings": {
              "dateFormat": "YYYY-MM-DD",
              "fontSize": "20px",
              "fontWeight": "normal",
              "locale": "",
              "showDate": true
            },
            "descriptionSettings": {
              "descriptionText": "",
              "fontSize": "36px",
              "fontWeight": "bold",
              "noValueText": "no description found",
              "source": "none"
            },
            "fontMono": false,
            "mode": "time",
            "refresh": "sec",
            "timeSettings": {
              "fontSize": "26px",
              "fontWeight": "bold"
            },
            "timezone": "",
            "timezoneSettings": {
              "fontSize": "12px",
              "fontWeight": "normal",
              "showTimezone": false,
              "zoneFormat": "offsetAbbv"
            }
          },
          "pluginVersion": "2.1.8",
          "targets": [
            {
              "alias": "",
              "bucketAggs": [
                {
                  "field": "timestamp",
                  "id": "2",
                  "settings": {
                    "interval": "auto"
                  },
                  "type": "date_histogram"
                }
              ],
              "metrics": [
                {
                  "id": "1",
                  "type": "count"
                }
              ],
              "query": "",
              "refId": "A",
              "timeField": "timestamp"
            }
          ],
          "title": "",
          "transparent": true,
          "type": "grafana-clock-panel"
        },
        {
          "collapsed": false,
          "gridPos": {
            "h": 1,
            "w": 24,
            "x": 0,
            "y": 2
          },
          "id": 7,
          "panels": [],
          "title": "Apps Historical",
          "type": "row"
        },
        {
          "datasource": {
            "type": "elasticsearch",
            "uid": "feex5fk2nn08wf"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              }
            },
            "overrides": []
          },
          "gridPos": {
            "h": 4,
            "w": 7,
            "x": 0,
            "y": 3
          },
          "id": 15,
          "options": {
            "colorMode": "background",
            "graphMode": "area",
            "justifyMode": "auto",
            "orientation": "auto",
            "percentChangeColorMode": "standard",
            "reduceOptions": {
              "calcs": [
                "sum"
              ],
              "fields": "",
              "values": false
            },
            "showPercentChange": false,
            "textMode": "value_and_name",
            "wideLayout": true
          },
          "pluginVersion": "11.5.2",
          "targets": [
            {
              "alias": "layer: bronze",
              "bucketAggs": [
                {
                  "field": "timestamp",
                  "id": "2",
                  "settings": {
                    "interval": "1d"
                  },
                  "type": "date_histogram"
                }
              ],
              "datasource": {
                "type": "elasticsearch",
                "uid": "feex5fk2nn08wf"
              },
              "metrics": [
                {
                  "id": "1",
                  "type": "count"
                }
              ],
              "query": "_index:\"compass_dt_datametrics\" AND owner.layer_lake:\"bronze\"",
              "refId": "A",
              "timeField": "timestamp"
            },
            {
              "alias": "layer: silver",
              "bucketAggs": [
                {
                  "field": "timestamp",
                  "id": "2",
                  "settings": {
                    "interval": "1d",
                    "trimEdges": "0"
                  },
                  "type": "date_histogram"
                }
              ],
              "datasource": {
                "type": "elasticsearch",
                "uid": "feex5fk2nn08wf"
              },
              "hide": false,
              "metrics": [
                {
                  "id": "1",
                  "type": "count"
                }
              ],
              "query": "_index:\"compass_dt_datametrics\" AND owner.layer_lake:\"silver\"",
              "refId": "B",
              "timeField": "timestamp"
            },
            {
              "alias": "layer: gold",
              "bucketAggs": [
                {
                  "field": "timestamp",
                  "id": "2",
                  "settings": {
                    "interval": "1d"
                  },
                  "type": "date_histogram"
                }
              ],
              "datasource": {
                "type": "elasticsearch",
                "uid": "feex5fk2nn08wf"
              },
              "hide": false,
              "metrics": [
                {
                  "id": "1",
                  "type": "count"
                }
              ],
              "query": "_index:\"compass_dt_datametrics\" AND owner.layer_lake:\"gold\"",
              "refId": "C",
              "timeField": "timestamp"
            }
          ],
          "timeFrom": "1d",
          "title": "Apps FInish per layer",
          "transparent": true,
          "type": "stat"
        },
        {
          "datasource": {
            "type": "elasticsearch",
            "uid": "feex5fk2nn08wf"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "palette-classic"
              },
              "custom": {
                "axisBorderShow": false,
                "axisCenteredZero": false,
                "axisColorMode": "text",
                "axisLabel": "",
                "axisPlacement": "auto",
                "barAlignment": 0,
                "barWidthFactor": 0.6,
                "drawStyle": "bars",
                "fillOpacity": 13,
                "gradientMode": "none",
                "hideFrom": {
                  "legend": false,
                  "tooltip": false,
                  "viz": false
                },
                "insertNulls": false,
                "lineInterpolation": "stepBefore",
                "lineStyle": {
                  "fill": "solid"
                },
                "lineWidth": 1,
                "pointSize": 8,
                "scaleDistribution": {
                  "type": "linear"
                },
                "showPoints": "auto",
                "spanNulls": false,
                "stacking": {
                  "group": "A",
                  "mode": "none"
                },
                "thresholdsStyle": {
                  "mode": "off"
                }
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  }
                ]
              }
            },
            "overrides": []
          },
          "gridPos": {
            "h": 10,
            "w": 17,
            "x": 7,
            "y": 3
          },
          "id": 2,
          "options": {
            "legend": {
              "calcs": [
                "sum"
              ],
              "displayMode": "table",
              "placement": "bottom",
              "showLegend": true
            },
            "timezone": [
              "browser"
            ],
            "tooltip": {
              "hideZeros": false,
              "mode": "single",
              "sort": "desc"
            }
          },
          "pluginVersion": "11.5.2",
          "targets": [
            {
              "alias": "layer: bronze",
              "bucketAggs": [
                {
                  "field": "timestamp",
                  "id": "2",
                  "settings": {
                    "interval": "10m",
                    "min_doc_count": "0"
                  },
                  "type": "date_histogram"
                }
              ],
              "datasource": {
                "type": "elasticsearch",
                "uid": "feext6ph5n1fkd"
              },
              "hide": false,
              "metrics": [
                {
                  "id": "1",
                  "type": "count"
                }
              ],
              "query": "_index:\"compass_dt_datametrics\" AND owner.layer_lake:\"bronze\"",
              "refId": "A",
              "timeField": "timestamp"
            },
            {
              "alias": "layer: silver",
              "bucketAggs": [
                {
                  "field": "timestamp",
                  "id": "2",
                  "settings": {
                    "interval": "10m",
                    "min_doc_count": "0"
                  },
                  "type": "date_histogram"
                }
              ],
              "datasource": {
                "type": "elasticsearch",
                "uid": "feext6ph5n1fkd"
              },
              "hide": false,
              "metrics": [
                {
                  "id": "1",
                  "type": "count"
                }
              ],
              "query": "_index:\"compass_dt_datametrics\" AND owner.layer_lake:\"silver\"",
              "refId": "B",
              "timeField": "timestamp"
            },
            {
              "alias": "layer: gold",
              "bucketAggs": [
                {
                  "field": "timestamp",
                  "id": "2",
                  "settings": {
                    "interval": "10m"
                  },
                  "type": "date_histogram"
                }
              ],
              "datasource": {
                "type": "elasticsearch",
                "uid": "feext6ph5n1fkd"
              },
              "hide": false,
              "metrics": [
                {
                  "id": "1",
                  "type": "count"
                }
              ],
              "query": "_index:\"compass_dt_datametrics\" AND owner.layer_lake:\"gold\"",
              "refId": "C",
              "timeField": "timestamp"
            }
          ],
          "title": "Applications completed per layer [historical]",
          "type": "timeseries"
        },
        {
          "datasource": {
            "type": "elasticsearch",
            "uid": "feex5fk2nn08wf"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "fixedColor": "semi-dark-green",
                "mode": "fixed"
              },
              "custom": {
                "neutral": -1
              },
              "decimals": 1,
              "fieldMinMax": false,
              "mappings": [],
              "max": 100,
              "min": 0,
              "noValue": "N0",
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              },
              "unit": "%"
            },
            "overrides": [
              {
                "__systemRef": "hideSeriesFrom",
                "matcher": {
                  "id": "byNames",
                  "options": {
                    "mode": "exclude",
                    "names": [
                      "Invalid data percentage"
                    ],
                    "prefix": "All except:",
                    "readOnly": true
                  }
                },
                "properties": []
              }
            ]
          },
          "gridPos": {
            "h": 6,
            "w": 7,
            "x": 0,
            "y": 7
          },
          "hideTimeOverride": false,
          "id": 10,
          "options": {
            "minVizHeight": 75,
            "minVizWidth": 75,
            "orientation": "auto",
            "reduceOptions": {
              "calcs": [
                "lastNotNull"
              ],
              "fields": "",
              "values": false
            },
            "showThresholdLabels": false,
            "showThresholdMarkers": true,
            "sizing": "auto",
            "text": {
              "percentSize": 1
            }
          },
          "pluginVersion": "11.5.2",
          "targets": [
            {
              "alias": "layer: bronze",
              "bucketAggs": [
                {
                  "field": "timestamp",
                  "id": "2",
                  "settings": {
                    "interval": "1d"
                  },
                  "type": "date_histogram"
                }
              ],
              "datasource": {
                "type": "elasticsearch",
                "uid": "feext6ph5n1fkd"
              },
              "hide": false,
              "metrics": [
                {
                  "field": "valid_data.percentage",
                  "id": "1",
                  "type": "avg"
                }
              ],
              "query": "_index:\"compass_dt_datametrics\" AND owner.layer_lake:\"bronze\"",
              "refId": "A",
              "timeField": "timestamp"
            },
            {
              "alias": "layer: silver",
              "bucketAggs": [
                {
                  "field": "timestamp",
                  "id": "2",
                  "settings": {
                    "interval": "auto"
                  },
                  "type": "date_histogram"
                }
              ],
              "datasource": {
                "type": "elasticsearch",
                "uid": "feext6ph5n1fkd"
              },
              "hide": false,
              "metrics": [
                {
                  "field": "valid_data.percentage",
                  "id": "1",
                  "type": "avg"
                }
              ],
              "query": "_index:\"compass_dt_datametrics\" AND owner.layer_lake:\"silver\"",
              "refId": "B",
              "timeField": "timestamp"
            },
            {
              "alias": "layer: gold",
              "bucketAggs": [
                {
                  "field": "timestamp",
                  "id": "2",
                  "settings": {
                    "interval": "1d"
                  },
                  "type": "date_histogram"
                }
              ],
              "datasource": {
                "type": "elasticsearch",
                "uid": "feext6ph5n1fkd"
              },
              "hide": false,
              "metrics": [
                {
                  "field": "valid_data.percentage",
                  "id": "1",
                  "type": "avg"
                }
              ],
              "query": "_index:\"compass_dt_datametrics\" AND owner.layer_lake:\"gold\"",
              "refId": "C",
              "timeField": "timestamp"
            }
          ],
          "timeFrom": "1d",
          "title": "Valid data percentage",
          "transparent": true,
          "type": "gauge"
        },
        {
          "datasource": {
            "type": "elasticsearch",
            "uid": "feext6ph5n1fkd"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "fixedColor": "dark-red",
                "mode": "fixed",
                "seriesBy": "min"
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              }
            },
            "overrides": []
          },
          "gridPos": {
            "h": 4,
            "w": 7,
            "x": 0,
            "y": 13
          },
          "id": 22,
          "options": {
            "colorMode": "background",
            "graphMode": "area",
            "justifyMode": "auto",
            "orientation": "auto",
            "percentChangeColorMode": "standard",
            "reduceOptions": {
              "calcs": [
                "sum"
              ],
              "fields": "",
              "values": false
            },
            "showPercentChange": false,
            "textMode": "auto",
            "wideLayout": true
          },
          "pluginVersion": "11.5.2",
          "targets": [
            {
              "alias": "layer: bronze",
              "bucketAggs": [
                {
                  "field": "timestamp",
                  "id": "2",
                  "settings": {
                    "interval": "10m"
                  },
                  "type": "date_histogram"
                }
              ],
              "datasource": {
                "type": "elasticsearch",
                "uid": "feext6ph5n1fkd"
              },
              "hide": false,
              "metrics": [
                {
                  "id": "1",
                  "type": "count"
                }
              ],
              "query": "_index:\"compass_dt_datametrics_fail\" AND (layer:\"bronze\")",
              "refId": "C",
              "timeField": "timestamp"
            },
            {
              "alias": "layer: silver",
              "bucketAggs": [
                {
                  "field": "timestamp",
                  "id": "2",
                  "settings": {
                    "interval": "10m"
                  },
                  "type": "date_histogram"
                }
              ],
              "datasource": {
                "type": "elasticsearch",
                "uid": "feext6ph5n1fkd"
              },
              "hide": false,
              "metrics": [
                {
                  "id": "1",
                  "type": "count"
                }
              ],
              "query": "_index:\"compass_dt_datametrics_fail\" AND (layer:\"silver\")",
              "refId": "A",
              "timeField": "timestamp"
            },
            {
              "alias": "layer: gold",
              "bucketAggs": [
                {
                  "field": "timestamp",
                  "id": "2",
                  "settings": {
                    "interval": "10m"
                  },
                  "type": "date_histogram"
                }
              ],
              "datasource": {
                "type": "elasticsearch",
                "uid": "feext6ph5n1fkd"
              },
              "hide": false,
              "metrics": [
                {
                  "id": "1",
                  "type": "count"
                }
              ],
              "query": "_index:\"compass_dt_datametrics_fail\" AND (layer:\"gold\")",
              "refId": "B",
              "timeField": "timestamp"
            }
          ],
          "title": "Applications fail per layer [historical]",
          "transparent": true,
          "type": "stat"
        },
        {
          "datasource": {
            "type": "elasticsearch",
            "uid": "feext6ph5n1fkd"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "fixedColor": "dark-red",
                "mode": "fixed",
                "seriesBy": "min"
              },
              "custom": {
                "axisBorderShow": false,
                "axisCenteredZero": false,
                "axisColorMode": "series",
                "axisLabel": "",
                "axisPlacement": "auto",
                "barAlignment": 0,
                "barWidthFactor": 0.9,
                "drawStyle": "bars",
                "fillOpacity": 22,
                "gradientMode": "none",
                "hideFrom": {
                  "legend": false,
                  "tooltip": false,
                  "viz": false
                },
                "insertNulls": false,
                "lineInterpolation": "stepBefore",
                "lineStyle": {
                  "fill": "solid"
                },
                "lineWidth": 2,
                "pointSize": 6,
                "scaleDistribution": {
                  "type": "linear"
                },
                "showPoints": "auto",
                "spanNulls": false,
                "stacking": {
                  "group": "A",
                  "mode": "normal"
                },
                "thresholdsStyle": {
                  "mode": "off"
                }
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              }
            },
            "overrides": []
          },
          "gridPos": {
            "h": 10,
            "w": 17,
            "x": 7,
            "y": 13
          },
          "id": 5,
          "options": {
            "legend": {
              "calcs": [
                "sum"
              ],
              "displayMode": "table",
              "placement": "bottom",
              "showLegend": true
            },
            "timezone": [
              "browser"
            ],
            "tooltip": {
              "hideZeros": false,
              "mode": "multi",
              "sort": "desc"
            }
          },
          "pluginVersion": "11.5.2",
          "targets": [
            {
              "alias": "layer: bronze",
              "bucketAggs": [
                {
                  "field": "timestamp",
                  "id": "2",
                  "settings": {
                    "interval": "10m"
                  },
                  "type": "date_histogram"
                }
              ],
              "datasource": {
                "type": "elasticsearch",
                "uid": "feext6ph5n1fkd"
              },
              "hide": false,
              "metrics": [
                {
                  "id": "1",
                  "type": "count"
                }
              ],
              "query": "_index:\"compass_dt_datametrics_fail\" AND (layer:\"bronze\")",
              "refId": "C",
              "timeField": "timestamp"
            },
            {
              "alias": "layer: silver",
              "bucketAggs": [
                {
                  "field": "timestamp",
                  "id": "2",
                  "settings": {
                    "interval": "10m"
                  },
                  "type": "date_histogram"
                }
              ],
              "datasource": {
                "type": "elasticsearch",
                "uid": "feext6ph5n1fkd"
              },
              "hide": false,
              "metrics": [
                {
                  "id": "1",
                  "type": "count"
                }
              ],
              "query": "_index:\"compass_dt_datametrics_fail\" AND (layer:\"silver\")",
              "refId": "A",
              "timeField": "timestamp"
            },
            {
              "alias": "layer: gold",
              "bucketAggs": [
                {
                  "field": "timestamp",
                  "id": "2",
                  "settings": {
                    "interval": "10m"
                  },
                  "type": "date_histogram"
                }
              ],
              "datasource": {
                "type": "elasticsearch",
                "uid": "feext6ph5n1fkd"
              },
              "hide": false,
              "metrics": [
                {
                  "id": "1",
                  "type": "count"
                }
              ],
              "query": "_index:\"compass_dt_datametrics_fail\" AND (layer:\"gold\")",
              "refId": "B",
              "timeField": "timestamp"
            }
          ],
          "title": "Applications fail per layer [historical]",
          "type": "timeseries"
        },
        {
          "datasource": {
            "type": "elasticsearch",
            "uid": "feex5fk2nn08wf"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "fixedColor": "dark-red",
                "mode": "fixed"
              },
              "decimals": 1,
              "mappings": [],
              "max": 100,
              "min": 1,
              "thresholds": {
                "mode": "percentage",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  },
                  {
                    "color": "red",
                    "value": 2
                  }
                ]
              },
              "unit": "%"
            },
            "overrides": []
          },
          "gridPos": {
            "h": 6,
            "w": 7,
            "x": 0,
            "y": 17
          },
          "id": 21,
          "options": {
            "minVizHeight": 75,
            "minVizWidth": 75,
            "orientation": "auto",
            "reduceOptions": {
              "calcs": [
                "lastNotNull"
              ],
              "fields": "",
              "values": false
            },
            "showThresholdLabels": false,
            "showThresholdMarkers": true,
            "sizing": "auto"
          },
          "pluginVersion": "11.5.2",
          "targets": [
            {
              "alias": "layer: bronze",
              "bucketAggs": [
                {
                  "field": "timestamp",
                  "id": "2",
                  "settings": {
                    "interval": "1d"
                  },
                  "type": "date_histogram"
                }
              ],
              "metrics": [
                {
                  "field": "invalid_data.percentage",
                  "id": "1",
                  "type": "avg"
                }
              ],
              "query": "_index:\"compass_dt_datametrics\" AND owner.layer_lake:\"bronze\"",
              "refId": "A",
              "timeField": "timestamp"
            },
            {
              "alias": "layer: silver",
              "bucketAggs": [
                {
                  "field": "timestamp",
                  "id": "2",
                  "settings": {
                    "interval": "1d"
                  },
                  "type": "date_histogram"
                }
              ],
              "datasource": {
                "type": "elasticsearch",
                "uid": "feex5fk2nn08wf"
              },
              "hide": false,
              "metrics": [
                {
                  "field": "invalid_data.percentage",
                  "id": "1",
                  "type": "avg"
                }
              ],
              "query": "_index:\"compass_dt_datametrics\" AND owner.layer_lake:\"silver\"",
              "refId": "B",
              "timeField": "timestamp"
            },
            {
              "alias": "layer: gold",
              "bucketAggs": [
                {
                  "field": "timestamp",
                  "id": "2",
                  "settings": {
                    "interval": "1d"
                  },
                  "type": "date_histogram"
                }
              ],
              "datasource": {
                "type": "elasticsearch",
                "uid": "feex5fk2nn08wf"
              },
              "hide": false,
              "metrics": [
                {
                  "field": "invalid_data.percentage",
                  "id": "1",
                  "type": "avg"
                }
              ],
              "query": "_index:\"compass_dt_datametrics\" AND owner.layer_lake:\"gold\"",
              "refId": "C",
              "timeField": "timestamp"
            }
          ],
          "title": "Invalid data percentage",
          "transparent": true,
          "type": "gauge"
        },
        {
          "datasource": {
            "type": "elasticsearch",
            "uid": "feex5fk2nn08wf"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "fixedColor": "dark-blue",
                "mode": "fixed"
              },
              "fieldMinMax": false,
              "mappings": [],
              "noValue": "N0",
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  },
                  {
                    "color": "red",
                    "value": 0
                  }
                ]
              }
            },
            "overrides": []
          },
          "gridPos": {
            "h": 9,
            "w": 7,
            "x": 0,
            "y": 23
          },
          "id": 23,
          "options": {
            "displayMode": "lcd",
            "legend": {
              "calcs": [],
              "displayMode": "list",
              "placement": "bottom",
              "showLegend": false
            },
            "maxVizHeight": 300,
            "minVizHeight": 0,
            "minVizWidth": 8,
            "namePlacement": "top",
            "orientation": "horizontal",
            "reduceOptions": {
              "calcs": [
                "sum"
              ],
              "fields": "",
              "values": false
            },
            "showUnfilled": true,
            "sizing": "manual",
            "valueMode": "color"
          },
          "pluginVersion": "11.5.2",
          "targets": [
            {
              "alias": "count events: bronze",
              "bucketAggs": [
                {
                  "field": "timestamp",
                  "id": "2",
                  "settings": {
                    "interval": "1d"
                  },
                  "type": "date_histogram"
                }
              ],
              "metrics": [
                {
                  "field": "total_records",
                  "id": "1",
                  "type": "sum"
                }
              ],
              "query": "_index:\"compass_dt_datametrics\" AND owner.layer_lake:\"bronze\"",
              "refId": "A",
              "timeField": "timestamp"
            },
            {
              "alias": "count events: silver",
              "bucketAggs": [
                {
                  "field": "timestamp",
                  "id": "2",
                  "settings": {
                    "interval": "1d"
                  },
                  "type": "date_histogram"
                }
              ],
              "datasource": {
                "type": "elasticsearch",
                "uid": "feex5fk2nn08wf"
              },
              "hide": false,
              "metrics": [
                {
                  "field": "total_records",
                  "id": "1",
                  "type": "sum"
                }
              ],
              "query": "_index:\"compass_dt_datametrics\" AND owner.layer_lake:\"silver\"",
              "refId": "B",
              "timeField": "timestamp"
            },
            {
              "alias": "count events: gold",
              "bucketAggs": [
                {
                  "field": "timestamp",
                  "id": "2",
                  "settings": {
                    "interval": "1d"
                  },
                  "type": "date_histogram"
                }
              ],
              "datasource": {
                "type": "elasticsearch",
                "uid": "feex5fk2nn08wf"
              },
              "hide": false,
              "metrics": [
                {
                  "field": "total_records",
                  "id": "1",
                  "type": "sum"
                }
              ],
              "query": "_index:\"compass_dt_datametrics\" AND owner.layer_lake:\"gold\"",
              "refId": "C",
              "timeField": "timestamp"
            }
          ],
          "title": "Event Count of the Bronze Layer [historical]",
          "transparent": true,
          "type": "bargauge"
        },
        {
          "datasource": {
            "type": "elasticsearch",
            "uid": "feex5fk2nn08wf"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "fieldMinMax": true,
              "mappings": [],
              "min": 0,
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "blue",
                    "value": null
                  },
                  {
                    "color": "red",
                    "value": 5
                  }
                ]
              },
              "unit": "none"
            },
            "overrides": [
              {
                "__systemRef": "hideSeriesFrom",
                "matcher": {
                  "id": "byNames",
                  "options": {
                    "mode": "exclude",
                    "names": [
                      "layer: bronze"
                    ],
                    "prefix": "All except:",
                    "readOnly": true
                  }
                },
                "properties": []
              }
            ]
          },
          "gridPos": {
            "h": 9,
            "w": 6,
            "x": 7,
            "y": 23
          },
          "id": 12,
          "options": {
            "colorMode": "value",
            "graphMode": "area",
            "justifyMode": "auto",
            "orientation": "horizontal",
            "percentChangeColorMode": "same_as_value",
            "reduceOptions": {
              "calcs": [
                "sum"
              ],
              "fields": "",
              "values": false
            },
            "showPercentChange": false,
            "textMode": "value_and_name",
            "wideLayout": true
          },
          "pluginVersion": "11.5.2",
          "targets": [
            {
              "alias": "layer: bronze duplicates",
              "bucketAggs": [
                {
                  "field": "timestamp",
                  "id": "2",
                  "settings": {
                    "interval": "auto"
                  },
                  "type": "date_histogram"
                }
              ],
              "datasource": {
                "type": "elasticsearch",
                "uid": "feext6ph5n1fkd"
              },
              "hide": false,
              "metrics": [
                {
                  "id": "1",
                  "type": "count"
                }
              ],
              "query": "owner.layer_lake.keyword:\"bronze\" AND validation_results.duplicate_check.code:\"409\"",
              "refId": "A",
              "timeField": "timestamp"
            },
            {
              "alias": "layer: bronze nulls",
              "bucketAggs": [
                {
                  "field": "timestamp",
                  "id": "2",
                  "settings": {
                    "interval": "auto"
                  },
                  "type": "date_histogram"
                }
              ],
              "datasource": {
                "type": "elasticsearch",
                "uid": "feext6ph5n1fkd"
              },
              "hide": false,
              "metrics": [
                {
                  "id": "1",
                  "type": "count"
                }
              ],
              "query": "owner.layer_lake.keyword:\"bronze\" AND validation_results.null_check.code:\"400\"",
              "refId": "B",
              "timeField": "timestamp"
            },
            {
              "alias": "layer: bronze consistency",
              "bucketAggs": [
                {
                  "field": "timestamp",
                  "id": "2",
                  "settings": {
                    "interval": "auto"
                  },
                  "type": "date_histogram"
                }
              ],
              "datasource": {
                "type": "elasticsearch",
                "uid": "feext6ph5n1fkd"
              },
              "hide": false,
              "metrics": [
                {
                  "id": "1",
                  "type": "count"
                }
              ],
              "query": "owner.layer_lake.keyword:\"bronze\" AND validation_results.type_consistency_check.code:\"400\"",
              "refId": "C",
              "timeField": "timestamp"
            }
          ],
          "title": "Event Quality of the Bronze Layer [historical]",
          "type": "stat"
        },
        {
          "datasource": {
            "type": "elasticsearch",
            "uid": "feex5fk2nn08wf"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "fieldMinMax": true,
              "mappings": [],
              "min": 0,
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "blue",
                    "value": null
                  },
                  {
                    "color": "red",
                    "value": 5
                  }
                ]
              },
              "unit": "none"
            },
            "overrides": [
              {
                "__systemRef": "hideSeriesFrom",
                "matcher": {
                  "id": "byNames",
                  "options": {
                    "mode": "exclude",
                    "names": [
                      "layer: bronze"
                    ],
                    "prefix": "All except:",
                    "readOnly": true
                  }
                },
                "properties": []
              }
            ]
          },
          "gridPos": {
            "h": 9,
            "w": 6,
            "x": 13,
            "y": 23
          },
          "id": 13,
          "options": {
            "colorMode": "value",
            "graphMode": "area",
            "justifyMode": "auto",
            "orientation": "horizontal",
            "percentChangeColorMode": "standard",
            "reduceOptions": {
              "calcs": [
                "sum"
              ],
              "fields": "",
              "values": false
            },
            "showPercentChange": false,
            "textMode": "auto",
            "wideLayout": true
          },
          "pluginVersion": "11.5.2",
          "targets": [
            {
              "alias": "layer: silver duplicates",
              "bucketAggs": [
                {
                  "field": "timestamp",
                  "id": "2",
                  "settings": {
                    "interval": "auto"
                  },
                  "type": "date_histogram"
                }
              ],
              "datasource": {
                "type": "elasticsearch",
                "uid": "feext6ph5n1fkd"
              },
              "hide": false,
              "metrics": [
                {
                  "id": "1",
                  "type": "count"
                }
              ],
              "query": "owner.layer_lake.keyword:\"silver\" AND validation_results.duplicate_check.code:\"409\"",
              "refId": "A",
              "timeField": "timestamp"
            },
            {
              "alias": "layer: silver nulls",
              "bucketAggs": [
                {
                  "field": "timestamp",
                  "id": "2",
                  "settings": {
                    "interval": "auto"
                  },
                  "type": "date_histogram"
                }
              ],
              "datasource": {
                "type": "elasticsearch",
                "uid": "feext6ph5n1fkd"
              },
              "hide": false,
              "metrics": [
                {
                  "id": "1",
                  "type": "count"
                }
              ],
              "query": "owner.layer_lake.keyword:\"silver\" AND validation_results.null_check.code:\"400\"",
              "refId": "B",
              "timeField": "timestamp"
            },
            {
              "alias": "layer: silver consistency",
              "bucketAggs": [
                {
                  "field": "timestamp",
                  "id": "2",
                  "settings": {
                    "interval": "auto"
                  },
                  "type": "date_histogram"
                }
              ],
              "datasource": {
                "type": "elasticsearch",
                "uid": "feext6ph5n1fkd"
              },
              "hide": false,
              "metrics": [
                {
                  "id": "1",
                  "type": "count"
                }
              ],
              "query": "owner.layer_lake.keyword:\"silver\" AND validation_results.type_consistency_check.code:\"400\"",
              "refId": "C",
              "timeField": "timestamp"
            }
          ],
          "title": "Event Quality of the Silver Layer [historical]",
          "type": "stat"
        },
        {
          "datasource": {
            "type": "elasticsearch",
            "uid": "feex5fk2nn08wf"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "mode": "thresholds"
              },
              "fieldMinMax": true,
              "mappings": [],
              "min": 0,
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "blue",
                    "value": null
                  },
                  {
                    "color": "red",
                    "value": 5
                  }
                ]
              },
              "unit": "none"
            },
            "overrides": [
              {
                "__systemRef": "hideSeriesFrom",
                "matcher": {
                  "id": "byNames",
                  "options": {
                    "mode": "exclude",
                    "names": [
                      "layer: bronze"
                    ],
                    "prefix": "All except:",
                    "readOnly": true
                  }
                },
                "properties": []
              }
            ]
          },
          "gridPos": {
            "h": 9,
            "w": 5,
            "x": 19,
            "y": 23
          },
          "id": 14,
          "options": {
            "colorMode": "value",
            "graphMode": "area",
            "justifyMode": "auto",
            "orientation": "horizontal",
            "percentChangeColorMode": "standard",
            "reduceOptions": {
              "calcs": [
                "sum"
              ],
              "fields": "",
              "values": false
            },
            "showPercentChange": false,
            "textMode": "auto",
            "wideLayout": true
          },
          "pluginVersion": "11.5.2",
          "targets": [
            {
              "alias": "layer: gold duplicates",
              "bucketAggs": [
                {
                  "field": "timestamp",
                  "id": "2",
                  "settings": {
                    "interval": "auto"
                  },
                  "type": "date_histogram"
                }
              ],
              "datasource": {
                "type": "elasticsearch",
                "uid": "feext6ph5n1fkd"
              },
              "hide": false,
              "metrics": [
                {
                  "id": "1",
                  "type": "count"
                }
              ],
              "query": "owner.layer_lake.keyword:\"gold\" AND validation_results.duplicate_check.code:\"409\"",
              "refId": "A",
              "timeField": "timestamp"
            },
            {
              "alias": "layer: gold nulls",
              "bucketAggs": [
                {
                  "field": "timestamp",
                  "id": "2",
                  "settings": {
                    "interval": "auto"
                  },
                  "type": "date_histogram"
                }
              ],
              "datasource": {
                "type": "elasticsearch",
                "uid": "feext6ph5n1fkd"
              },
              "hide": false,
              "metrics": [
                {
                  "id": "1",
                  "type": "count"
                }
              ],
              "query": "owner.layer_lake.keyword:\"gold\" AND validation_results.null_check.code:\"400\"",
              "refId": "B",
              "timeField": "timestamp"
            },
            {
              "alias": "layer: gold consistency",
              "bucketAggs": [
                {
                  "field": "timestamp",
                  "id": "2",
                  "settings": {
                    "interval": "auto"
                  },
                  "type": "date_histogram"
                }
              ],
              "datasource": {
                "type": "elasticsearch",
                "uid": "feext6ph5n1fkd"
              },
              "hide": false,
              "metrics": [
                {
                  "id": "1",
                  "type": "count"
                }
              ],
              "query": "owner.layer_lake.keyword:\"gold\" AND validation_results.type_consistency_check.code:\"400\"",
              "refId": "C",
              "timeField": "timestamp"
            }
          ],
          "title": "Event Quality of the Gold Layer [historical]",
          "type": "stat"
        }
      ],
      "preload": false,
      "refresh": "5s",
      "schemaVersion": 40,
      "tags": [],
      "templating": {
        "list": []
      },
      "time": {
        "from": "now-24h",
        "to": "now"
      },
      "timepicker": {},
      "timezone": "browser",
      "title": "COMPASS - Opera√ß√£o Aplicacional",
      "uid": "eeex6c5w2x9fkb",
      "version": 215,
      "weekStart": ""
    }
  ```

  Repita o mesmo passo a passo para o **Dashboard: COMPASS - Sustenta√ß√£o**:

  ```json
    {
      "annotations": {
        "list": [
          {
            "builtIn": 1,
            "datasource": {
              "type": "grafana",
              "uid": "-- Grafana --"
            },
            "enable": true,
            "hide": true,
            "iconColor": "rgba(0, 211, 255, 1)",
            "name": "Annotations & Alerts",
            "type": "dashboard"
          }
        ]
      },
      "editable": true,
      "fiscalYearStartMonth": 0,
      "graphTooltip": 0,
      "id": 4,
      "links": [],
      "panels": [
        {
          "fieldConfig": {
            "defaults": {},
            "overrides": []
          },
          "gridPos": {
            "h": 2,
            "w": 8,
            "x": 0,
            "y": 0
          },
          "id": 3,
          "options": {
            "code": {
              "language": "plaintext",
              "showLineNumbers": false,
              "showMiniMap": false
            },
            "content": "\n# TV COMPASS [SUSTENTA√á√ÉO]",
            "mode": "markdown"
          },
          "pluginVersion": "11.5.2",
          "title": "",
          "transparent": true,
          "type": "text"
        },
        {
          "datasource": {
            "type": "elasticsearch",
            "uid": "feex5fk2nn08wf"
          },
          "fieldConfig": {
            "defaults": {},
            "overrides": []
          },
          "gridPos": {
            "h": 2,
            "w": 3,
            "x": 8,
            "y": 0
          },
          "id": 6,
          "options": {
            "bgColor": "transparent",
            "clockType": "24 hour",
            "countdownSettings": {
              "endCountdownTime": "2025-03-08T05:21:06-03:00",
              "endText": "00:00:00",
              "invalidValueText": "invalid value",
              "noValueText": "no value found",
              "queryCalculation": "last",
              "source": "input"
            },
            "countupSettings": {
              "beginCountupTime": "2025-03-08T05:21:06-03:00",
              "beginText": "00:00:00",
              "invalidValueText": "invalid value",
              "noValueText": "no value found",
              "queryCalculation": "last",
              "source": "input"
            },
            "dateSettings": {
              "dateFormat": "YYYY-MM-DD",
              "fontSize": "20px",
              "fontWeight": "normal",
              "locale": "",
              "showDate": true
            },
            "descriptionSettings": {
              "descriptionText": "",
              "fontSize": "36px",
              "fontWeight": "bold",
              "noValueText": "no description found",
              "source": "none"
            },
            "fontMono": false,
            "mode": "time",
            "refresh": "sec",
            "timeSettings": {
              "fontSize": "26px",
              "fontWeight": "bold"
            },
            "timezone": "",
            "timezoneSettings": {
              "fontSize": "12px",
              "fontWeight": "normal",
              "showTimezone": false,
              "zoneFormat": "offsetAbbv"
            }
          },
          "pluginVersion": "2.1.8",
          "targets": [
            {
              "alias": "",
              "bucketAggs": [
                {
                  "field": "timestamp",
                  "id": "2",
                  "settings": {
                    "interval": "auto"
                  },
                  "type": "date_histogram"
                }
              ],
              "metrics": [
                {
                  "id": "1",
                  "type": "count"
                }
              ],
              "query": "",
              "refId": "A",
              "timeField": "timestamp"
            }
          ],
          "title": "",
          "transparent": true,
          "type": "grafana-clock-panel"
        },
        {
          "collapsed": false,
          "gridPos": {
            "h": 1,
            "w": 24,
            "x": 0,
            "y": 2
          },
          "id": 4,
          "panels": [],
          "title": "Sustentra√ß√£o - [Malha]",
          "type": "row"
        },
        {
          "datasource": {
            "type": "elasticsearch",
            "uid": "feext6ph5n1fkd"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "fixedColor": "dark-red",
                "mode": "continuous-reds",
                "seriesBy": "min"
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "light-green",
                    "value": null
                  }
                ]
              }
            },
            "overrides": []
          },
          "gridPos": {
            "h": 9,
            "w": 8,
            "x": 0,
            "y": 3
          },
          "id": 5,
          "options": {
            "displayMode": "lcd",
            "legend": {
              "calcs": [],
              "displayMode": "list",
              "placement": "bottom",
              "showLegend": false
            },
            "maxVizHeight": 300,
            "minVizHeight": 16,
            "minVizWidth": 8,
            "namePlacement": "top",
            "orientation": "horizontal",
            "reduceOptions": {
              "calcs": [
                "sum"
              ],
              "fields": "",
              "values": false
            },
            "showUnfilled": true,
            "sizing": "auto",
            "valueMode": "color"
          },
          "pluginVersion": "11.5.2",
          "targets": [
            {
              "alias": "priority: 0",
              "bucketAggs": [
                {
                  "field": "timestamp",
                  "id": "2",
                  "settings": {
                    "interval": "1h"
                  },
                  "type": "date_histogram"
                }
              ],
              "datasource": {
                "type": "elasticsearch",
                "uid": "feext6ph5n1fkd"
              },
              "hide": false,
              "metrics": [
                {
                  "id": "1",
                  "type": "count"
                }
              ],
              "query": "_index:\"compass_dt_datametrics_fail\" \nAND (priority.keyword:(0))",
              "refId": "C",
              "timeField": "timestamp"
            },
            {
              "alias": "priority: 1",
              "bucketAggs": [
                {
                  "field": "timestamp",
                  "id": "2",
                  "settings": {
                    "interval": "1h"
                  },
                  "type": "date_histogram"
                }
              ],
              "datasource": {
                "type": "elasticsearch",
                "uid": "feext6ph5n1fkd"
              },
              "hide": false,
              "metrics": [
                {
                  "id": "1",
                  "type": "count"
                }
              ],
              "query": "_index:\"compass_dt_datametrics_fail\" \nAND (priority.keyword:(1))",
              "refId": "A",
              "timeField": "timestamp"
            },
            {
              "alias": "priority: 2",
              "bucketAggs": [
                {
                  "field": "timestamp",
                  "id": "2",
                  "settings": {
                    "interval": "1h"
                  },
                  "type": "date_histogram"
                }
              ],
              "datasource": {
                "type": "elasticsearch",
                "uid": "feext6ph5n1fkd"
              },
              "hide": false,
              "metrics": [
                {
                  "id": "1",
                  "type": "count"
                }
              ],
              "query": "_index:\"compass_dt_datametrics_fail\" \nAND (priority.keyword:(2))",
              "refId": "B",
              "timeField": "timestamp"
            }
          ],
          "title": "Applications fail per priority [total]",
          "type": "bargauge"
        },
        {
          "datasource": {
            "type": "elasticsearch",
            "uid": "feext6ph5n1fkd"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "fixedColor": "dark-red",
                "mode": "fixed",
                "seriesBy": "min"
              },
              "custom": {
                "axisBorderShow": false,
                "axisCenteredZero": false,
                "axisColorMode": "series",
                "axisLabel": "",
                "axisPlacement": "auto",
                "barAlignment": 0,
                "barWidthFactor": 0.8,
                "drawStyle": "bars",
                "fillOpacity": 100,
                "gradientMode": "none",
                "hideFrom": {
                  "legend": false,
                  "tooltip": false,
                  "viz": false
                },
                "insertNulls": false,
                "lineInterpolation": "stepBefore",
                "lineStyle": {
                  "fill": "solid"
                },
                "lineWidth": 2,
                "pointSize": 6,
                "scaleDistribution": {
                  "type": "linear"
                },
                "showPoints": "auto",
                "spanNulls": false,
                "stacking": {
                  "group": "A",
                  "mode": "normal"
                },
                "thresholdsStyle": {
                  "mode": "off"
                }
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              }
            },
            "overrides": []
          },
          "gridPos": {
            "h": 9,
            "w": 16,
            "x": 8,
            "y": 3
          },
          "id": 2,
          "options": {
            "legend": {
              "calcs": [
                "sum"
              ],
              "displayMode": "table",
              "placement": "right",
              "showLegend": true
            },
            "timezone": [
              "browser"
            ],
            "tooltip": {
              "hideZeros": false,
              "mode": "multi",
              "sort": "desc"
            }
          },
          "pluginVersion": "11.5.2",
          "targets": [
            {
              "alias": "layer: bronze",
              "bucketAggs": [
                {
                  "field": "timestamp",
                  "id": "2",
                  "settings": {
                    "interval": "1h"
                  },
                  "type": "date_histogram"
                }
              ],
              "datasource": {
                "type": "elasticsearch",
                "uid": "feext6ph5n1fkd"
              },
              "hide": false,
              "metrics": [
                {
                  "id": "1",
                  "type": "count"
                }
              ],
              "query": "_index:\"compass_dt_datametrics_fail\" \nAND (layer:\"bronze\") \nAND (priority.keyword:(0 OR 1 OR 2))",
              "refId": "C",
              "timeField": "timestamp"
            },
            {
              "alias": "layer: silver",
              "bucketAggs": [
                {
                  "field": "timestamp",
                  "id": "2",
                  "settings": {
                    "interval": "1h"
                  },
                  "type": "date_histogram"
                }
              ],
              "datasource": {
                "type": "elasticsearch",
                "uid": "feext6ph5n1fkd"
              },
              "hide": false,
              "metrics": [
                {
                  "id": "1",
                  "type": "count"
                }
              ],
              "query": "_index:\"compass_dt_datametrics_fail\" \nAND (layer:\"silver\") \nAND (priority.keyword:(0 OR 1 OR 2))",
              "refId": "A",
              "timeField": "timestamp"
            },
            {
              "alias": "layer: gold",
              "bucketAggs": [
                {
                  "field": "timestamp",
                  "id": "2",
                  "settings": {
                    "interval": "1h"
                  },
                  "type": "date_histogram"
                }
              ],
              "datasource": {
                "type": "elasticsearch",
                "uid": "feext6ph5n1fkd"
              },
              "hide": false,
              "metrics": [
                {
                  "id": "1",
                  "type": "count"
                }
              ],
              "query": "_index:\"compass_dt_datametrics_fail\" \nAND (layer:\"gold\") \nAND (priority.keyword:(0 OR 1 OR 2))",
              "refId": "B",
              "timeField": "timestamp"
            }
          ],
          "title": "Applications fail per priority [historical]",
          "type": "timeseries"
        },
        {
          "datasource": {
            "type": "elasticsearch",
            "uid": "feext6ph5n1fkd"
          },
          "fieldConfig": {
            "defaults": {
              "color": {
                "fixedColor": "dark-red",
                "mode": "fixed",
                "seriesBy": "min"
              },
              "custom": {
                "align": "left",
                "cellOptions": {
                  "applyToRow": false,
                  "mode": "gradient",
                  "type": "color-background",
                  "wrapText": false
                },
                "filterable": true,
                "inspect": true
              },
              "mappings": [],
              "thresholds": {
                "mode": "absolute",
                "steps": [
                  {
                    "color": "green",
                    "value": null
                  },
                  {
                    "color": "red",
                    "value": 80
                  }
                ]
              }
            },
            "overrides": []
          },
          "gridPos": {
            "h": 17,
            "w": 24,
            "x": 0,
            "y": 12
          },
          "id": 7,
          "options": {
            "cellHeight": "sm",
            "footer": {
              "countRows": false,
              "enablePagination": true,
              "fields": "",
              "reducer": [],
              "show": true
            },
            "showHeader": true,
            "sortBy": [
              {
                "desc": true,
                "displayName": "timestamp"
              }
            ]
          },
          "pluginVersion": "11.5.2",
          "targets": [
            {
              "alias": "",
              "bucketAggs": [],
              "datasource": {
                "type": "elasticsearch",
                "uid": "feext6ph5n1fkd"
              },
              "hide": false,
              "metrics": [
                {
                  "id": "1",
                  "settings": {
                    "limit": "500"
                  },
                  "type": "logs"
                }
              ],
              "query": "_index:\"compass_dt_datametrics_fail\" \nAND (priority.keyword:(0 OR 1 OR 2))",
              "refId": "C",
              "timeField": "timestamp"
            }
          ],
          "title": "",
          "transformations": [
            {
              "id": "organize",
              "options": {
                "excludeByName": {
                  "_id": true,
                  "_index": true,
                  "_source": true,
                  "_type": true,
                  "client": true,
                  "highlight": true,
                  "id": true,
                  "sort": true
                },
                "includeByName": {},
                "indexByName": {
                  "_id": 8,
                  "_index": 9,
                  "_source": 10,
                  "_type": 11,
                  "client": 5,
                  "error": 7,
                  "highlight": 12,
                  "id": 13,
                  "job": 2,
                  "layer": 1,
                  "priority": 3,
                  "project": 4,
                  "sort": 14,
                  "timestamp": 0,
                  "tower": 6
                },
                "renameByName": {}
              }
            }
          ],
          "type": "table"
        }
      ],
      "preload": false,
      "refresh": "",
      "schemaVersion": 40,
      "tags": [],
      "templating": {
        "list": []
      },
      "time": {
        "from": "now-7d",
        "to": "now"
      },
      "timepicker": {},
      "timezone": "browser",
      "title": "COMPASS - Sustenta√ß√£o",
      "uid": "fef83ot67ctmoe",
      "version": 30,
      "weekStart": ""
    }

```

Agora para o dashboard de "COMPASS - Comece aqui"


```json
    {
      "annotations": {
        "list": [
          {
            "builtIn": 1,
            "datasource": {
              "type": "grafana",
              "uid": "-- Grafana --"
            },
            "enable": true,
            "hide": true,
            "iconColor": "rgba(0, 211, 255, 1)",
            "name": "Annotations & Alerts",
            "type": "dashboard"
          }
        ]
      },
      "editable": true,
      "fiscalYearStartMonth": 0,
      "graphTooltip": 0,
      "id": 3,
      "links": [],
      "panels": [
        {
          "collapsed": false,
          "gridPos": {
            "h": 1,
            "w": 24,
            "x": 0,
            "y": 0
          },
          "id": 3,
          "panels": [],
          "title": "README",
          "type": "row"
        },
        {
          "datasource": {
            "type": "elasticsearch",
            "uid": "feex5fk2nn08wf"
          },
          "fieldConfig": {
            "defaults": {},
            "overrides": []
          },
          "gridPos": {
            "h": 9,
            "w": 3,
            "x": 0,
            "y": 1
          },
          "id": 2,
          "options": {
            "bgColor": "transparent",
            "clockType": "24 hour",
            "countdownSettings": {
              "endCountdownTime": "2025-03-08T05:21:06-03:00",
              "endText": "00:00:00",
              "invalidValueText": "invalid value",
              "noValueText": "no value found",
              "queryCalculation": "last",
              "source": "input"
            },
            "countupSettings": {
              "beginCountupTime": "2025-03-08T05:21:06-03:00",
              "beginText": "00:00:00",
              "invalidValueText": "invalid value",
              "noValueText": "no value found",
              "queryCalculation": "last",
              "source": "input"
            },
            "dateSettings": {
              "dateFormat": "YYYY-MM-DD",
              "fontSize": "20px",
              "fontWeight": "normal",
              "locale": "",
              "showDate": true
            },
            "descriptionSettings": {
              "descriptionText": "",
              "fontSize": "36px",
              "fontWeight": "bold",
              "noValueText": "no description found",
              "source": "none"
            },
            "fontMono": false,
            "mode": "time",
            "refresh": "sec",
            "timeSettings": {
              "fontSize": "46px",
              "fontWeight": "bold"
            },
            "timezone": "",
            "timezoneSettings": {
              "fontSize": "12px",
              "fontWeight": "normal",
              "showTimezone": false,
              "zoneFormat": "offsetAbbv"
            }
          },
          "pluginVersion": "2.1.8",
          "targets": [
            {
              "alias": "",
              "bucketAggs": [
                {
                  "field": "timestamp",
                  "id": "2",
                  "settings": {
                    "interval": "auto"
                  },
                  "type": "date_histogram"
                }
              ],
              "metrics": [
                {
                  "id": "1",
                  "type": "count"
                }
              ],
              "query": "",
              "refId": "A",
              "timeField": "timestamp"
            }
          ],
          "title": "",
          "transparent": true,
          "type": "grafana-clock-panel"
        },
        {
          "fieldConfig": {
            "defaults": {},
            "overrides": []
          },
          "gridPos": {
            "h": 9,
            "w": 12,
            "x": 3,
            "y": 1
          },
          "id": 8,
          "options": {
            "code": {
              "language": "markdown",
              "showLineNumbers": false,
              "showMiniMap": false
            },
            "content": "<img src=\"https://github.com/gacarvalho/repo-spark-delta-iceberg/blob/main/header.png?raw=true\" alt=\"Arquitetura Data Master Compass\" width=\"1350\">\n",
            "mode": "markdown"
          },
          "pluginVersion": "11.5.2",
          "title": "",
          "transparent": true,
          "type": "text"
        },
        {
          "description": "",
          "fieldConfig": {
            "defaults": {},
            "overrides": []
          },
          "gridPos": {
            "h": 9,
            "w": 9,
            "x": 15,
            "y": 1
          },
          "id": 4,
          "options": {
            "code": {
              "language": "plaintext",
              "showLineNumbers": false,
              "showMiniMap": false
            },
            "content": "`Owner: sigla DT`\n`Project: Compass` \n`enviroment: prod`\n\n#### ‚ô®Ô∏è **Projeto Data Master Compass**\n\nO **Projeto Data Master Compass** √© uma iniciativa estrat√©gica de **Engenharia de Dados** com **Data Master** para o **Banco Santander**, criada para capturar e analisar as avalia√ß√µes dos nossos clientes sobre os produtos e servi√ßos do banco. Assim como o nome **Compass** sugere, a proposta do projeto √© atuar como uma verdadeira b√∫ssola para o time de neg√≥cios, orientando o desenvolvimento e a melhoria cont√≠nua dos nossos processos e produtos.\n\n#### ‚ô®Ô∏è **Objetivos e Benef√≠cios**\n\nAo coletar e interpretar os feedbacks dos clientes, identificamos **necessidades** e **oportunidades de aprimoramento** que fortalecem nosso compromisso com a **satisfa√ß√£o** e **fideliza√ß√£o**. Essa abordagem nos permite n√£o apenas refinar a **experi√™ncia do cliente**, mas tamb√©m consolidar o **Santander** como a **escolha de refer√™ncia e confian√ßa** para nossos clientes.\n",
            "mode": "markdown"
          },
          "pluginVersion": "11.5.2",
          "title": "",
          "transparent": true,
          "type": "text"
        },
        {
          "collapsed": false,
          "gridPos": {
            "h": 1,
            "w": 24,
            "x": 0,
            "y": 10
          },
          "id": 10,
          "panels": [],
          "title": "LINKS",
          "type": "row"
        },
        {
          "fieldConfig": {
            "defaults": {},
            "overrides": []
          },
          "gridPos": {
            "h": 10,
            "w": 15,
            "x": 0,
            "y": 11
          },
          "id": 5,
          "options": {
            "folderUID": "eeex5johzxo8we",
            "includeVars": true,
            "keepTime": false,
            "maxItems": 10,
            "query": "",
            "showFolderNames": true,
            "showHeadings": true,
            "showRecentlyViewed": false,
            "showSearch": true,
            "showStarred": true,
            "tags": []
          },
          "pluginVersion": "11.5.2",
          "title": "Dashboards - utiliza√ß√£o",
          "type": "dashlist"
        },
        {
          "description": "Owner: sigla DT, project Compass",
          "fieldConfig": {
            "defaults": {},
            "overrides": []
          },
          "gridPos": {
            "h": 10,
            "w": 9,
            "x": 15,
            "y": 11
          },
          "id": 9,
          "options": {
            "code": {
              "language": "plaintext",
              "showLineNumbers": false,
              "showMiniMap": false
            },
            "content": "#### ‚ô®Ô∏è **Links √öteis**\n\n- `update: 03/2025` **M√©tricas Funcionais (Metabase)**: [Acessar Metabase](http://51.141.176.64:8085/d)\n\n#### ‚ô®Ô∏è **Outros Links**\n\n- `update: 03/2025` **Github do Projeto**: [Projeto Compass Deployment](https://github.com/gacarvalho/compass-deployment)\n- `update: 03/2025` **Infraestrutura**: [Infraestrutura Data Master Compass](https://github.com/gacarvalho/infra-data-master-compass)\n",
            "mode": "markdown"
          },
          "pluginVersion": "11.5.2",
          "title": "LINKS COMPASS",
          "transparent": true,
          "type": "text"
        }
      ],
      "preload": false,
      "refresh": "",
      "schemaVersion": 40,
      "tags": [
        "datamaster",
        "compass"
      ],
      "templating": {
        "list": []
      },
      "time": {
        "from": "now-6h",
        "to": "now"
      },
      "timepicker": {},
      "timezone": "browser",
      "title": "COMPASS - Comece aqui",
      "uid": "aef6eps590mpsb",
      "version": 31,
      "weekStart": ""
    }
  ```
</details>

O resultado esperado √© que voce consiga visualizar os dashboard listados!

![grafana-import](https://github.com/gacarvalho/compass-deployment/blob/compass/infra-3.0.0/img/dashboard-grafana.png)

Agora vamos criar a conex√£o com o Elastic Search para aparecer dados no dashboard:

No grafana em **Home** > **Connections** > **Add new connection** > **Elasticsearch** > **Add new data source**

Voce dever√° preencher com as op√ß√µes:

**Nome da conex√£o:** elasticsearch

  - Connection (URL): `http://elasticsearch:9200`
  - Authentication - Authentication method - Basic authentication: user: `elastic` password: `data-@a1`
  - Elasticsearch details - Index name: `compass_dt_datametrics`
  - Elasticsearch details - Time field name: `timestamp`

Resultado:

```
Elasticsearch data source is healthy.
Next, you can start to visualize data by building a dashboard, or by querying data in the Explore view.
```
E voc√™ vai repetir o mesmo para outro indice:

**Nome da conex√£o:** elasticsearch-2

  - Connection (URL): `http://elasticsearch:9200`
  - Authentication - Authentication method - Basic authentication: user: `elastic` password: `data-@a1`
  - Elasticsearch details - Index name: `compass_dt_datametrics_fail`
  - Elasticsearch details - Time field name: `timestamp`

Resultado:

```
Elasticsearch data source is healthy.
Next, you can start to visualize data by building a dashboard, or by querying data in the Explore view.
```

E as conex√µes dever√£o aparecer dessa forma:

![grafana-conexao](https://github.com/gacarvalho/compass-deployment/blob/compass/infra-3.0.0/img/conexao-grafana.png)

>[!NOTE]
> Lembrando que n√£o rodamos as aplica√ß√µes, ent√£o n√£o vamos ter dados no Elastic Search de logs para exibir no Grafana.


**Deployment do Metabase**
---

Agora, vamos subir o servi√ßo do Metabase com o comando abaixo:

```bash
make deployment-metabase-service
```

>[!NOTE]
> Na estrutura do projeto em `{path_compass_deployment}/mnt/metabase` temos j√° um arquivo configura√ß√£o de backup (arquivos .db), ent√£o n√£o ser√° necess√°rio realizar muitas configura√ß√µes.

Ap√≥s a subida voce ver√° que o scale do pod ficou em 1/1

```bash
ID             NAME                                      MODE         REPLICAS   IMAGE                                                        PORTS
igc5savoteqh   deployment-metabase_business-metabase     replicated   1/1        metabase/metabase:latest                                     *:8085->3000/tcp
```

E assim voce poder√° acessar no navegador `http://<ip>:8085/auth/login` e com o usu√°rio `gacarvalho.contato@gmail.com` e a senha `data1-in@a` voc√™ ter√° acesso ao painel do Metabase e o dashboard Compass!

![metabase](https://github.com/gacarvalho/compass-deployment/blob/compass/infra-3.0.0/img/metabase.png)

Voc√™ vai perceber que n√£o temos informa√ß√µes no painel, pois precisamos rodar o nosso pipeline al√©m disso, gerar uma conex√£o com o MongoDB. Para isso voc√™ ir√° no **canto superior direito** > **Configura√ß√£o de Admin** > **Banco de Dados** > **mongodb-connection** >  E verifique se o status est√° como **CONECTADO**, se n√£o tiver, verifique a string de conex√£o.

A interface de conex√£o dever√° aparecer dessa forma:

![metabase-conexao](https://github.com/gacarvalho/compass-deployment/blob/compass/infra-3.0.0/img/metabase-conexao.png)

Ao sairmos da vis√£o de ADMIN e voltar ao painel do dashboard, a vis√£o correta "sem dados" √© como a imagem abaixo (pois ainda n√£o rodamos o pipeline):

![metabase-dados](https://github.com/gacarvalho/compass-deployment/blob/compass/infra-3.0.0/img/metabase-dados.png)

**Vis√£o Final**
---
Se voc√™ chegou at√© essa sess√£o, parab√©ns! Voc√™ conseguiu replicar toda a infraestrutura do projeto Compass! Agora, vamos rodar o pipeline pela 1a vez e consultar os dados.

>[!NOTE]
> Antes da execu√ß√£o do pipeline no Airflow √© importante executar o comando `sudo chmod 666 /var/run/docker.sock` para permitir que o container do orquestrador tenha acesso para executar imagens das aplica√ß√µes.
> E para que o Airflow funcione corretamente, voc√™ deve ajustar na DAG o caminho do diret√≥rio e garantir que a pasta /env/ exista na raiz do computador, copiando para ela o arquivo `/env/.env`.

Um ponto crucial para rodar o pipeline `dag_d_pipeline_compass_reviews` √© rodar uma DAG eventual que vai gerar dados de forma eventual "simulando" a alimenta√ß√£o de feedbacks no Mongo DB como se fosse o canal.

![dag_eventual](https://github.com/gacarvalho/compass-deployment/blob/compass/infra-3.0.0/img/dag_e.png)

Agora j√° √© poss√≠vel executar o pipeline dag_d_pipeline_compass_reviews e com os acessos devidos.

![airflow-run](https://github.com/gacarvalho/compass-deployment/blob/compass/infra-3.0.0/img/airflow-run.png)

Ap√≥s o start do pipeline podemos ver os containers das imagens spark rodando no ambiente com inicio da nomeclatura de `dmc-...`

![apps-spark-run](https://github.com/gacarvalho/compass-deployment/blob/compass/infra-3.0.0/img/apps-spark-run.png)

Agora √© poss√≠vel perceber que o pipeline di√°rio teve a sua primeira execu√ß√£o com sucesso.

![dag_diario](https://github.com/gacarvalho/compass-deployment/blob/compass/infra-3.0.0/img/dag_d.png)

As aplica√ß√µes listadas no Yarn.

![yarn](https://github.com/gacarvalho/compass-deployment/blob/compass/infra-3.0.0/img/replicate-2.png)

E os dados de neg√≥cios entregue no Metabase:

![metabase-populado](https://github.com/gacarvalho/compass-deployment/blob/compass/infra-3.0.0/img/metabase-ok.png)

**Spark**
---

Agora ser√° poss√≠vel realizar o deploy dos containers Spark para se conectar ao Hadoop, assim voc√™ poder√° acessar o HDFS e abrir sess√µes em pyspark e spark-shell.

Com o comando abaixo ser√° realizado o deploy do Spark Master (1 container) e o Spark Worker (2 containers).

```bash
make deployment-spark-service
```

O resultado esperado √© que seja semanalhante a esse output abaixo:

```bash
ID             NAME                                      MODE         REPLICAS   IMAGE                                                        PORTS
                                                     *:27017->27017/tcp
ldzfn8t9c725   deployment-spark_infra-spark-master       replicated   1/1        iamgacarvalho/spark-master-data-in-compass:3.0.0             *:7077->7077/tcp, *:8084->8082/tcp
djskgqaj7v0t   deployment-spark_infra-spark-worker       replicated   2/2        iamgacarvalho/spark-worker-data-in-compass:3.0.0             *:8090-8100->8081/tcp
```

Agora acessando qualquer um dos containers, vamos conseguir navegador no HDFS:

![spark-hdfs](https://github.com/gacarvalho/compass-deployment/blob/compass/infra-3.0.0/img/spark-hdfs.png)

E abrindo a sess√£o em pyspark √© poss√≠vel realizar a leitura dos arquivos alocados no HDFS:

![spark-read](https://github.com/gacarvalho/compass-deployment/blob/compass/infra-3.0.0/img/spark-read.png)

Abaixo √© uma leitura dos registros rejeitados e fora do padr√£o, nesse caso especifico √© um rejeitado por conta do **pattern** que n√£o foi atendido:

```bash
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /__ / .__/\_,_/_/ /_/\_\   version 3.5.0
      /_/

Using Python version 3.7.3 (default, Mar 23 2024 16:12:05)
Spark context Web UI available at http://b595c75b463e:4040
Spark context available as 'sc' (master = local[*], app id = local-1745842549531).
SparkSession available as 'spark'.
>>> path = "/santander/quality/compass/reviews/pattern/apple_store/odate=20250427/"
>>> df = spark.read.parquet(path)
>>> df.printSchema()
root
 |-- id: string (nullable = true)
 |-- name_client: string (nullable = true)
 |-- app: string (nullable = true)
 |-- im_version: string (nullable = true)
 |-- im_rating: string (nullable = true)
 |-- title: string (nullable = true)
 |-- content: string (nullable = true)
 |-- updated: string (nullable = true)
 |-- segmento: string (nullable = true)
 |-- historical_data: array (nullable = true)
 |    |-- element: struct (containsNull = true)
 |    |    |-- title: string (nullable = true)
 |    |    |-- content: string (nullable = true)
 |    |    |-- app: string (nullable = true)
 |    |    |-- segmento: string (nullable = true)
 |    |    |-- im_version: string (nullable = true)
 |    |    |-- im_rating: string (nullable = true)
 |-- failed_columns: array (nullable = true)
 |    |-- element: string (containsNull = true)
 |-- validation: string (nullable = true)

>>> df.show(truncate=False)
+-----------+-----------+----------------+----------+---------+-----+---------------------+-------------------------+--------+---------------+--------------+----------+
|id         |name_client|app             |im_version|im_rating|title|content              |updated                  |segmento|historical_data|failed_columns|validation|
+-----------+-----------+----------------+----------+---------+-----+---------------------+-------------------------+--------+---------------+--------------+----------+
|12528197545|ULISSES.   |santander-way_pf|25.3.2    |5        |     |SALVACAO DO DIA A DIA|2025-04-10T17:08:12-07:00|pf      |[]             |[title]       |no_match  |
|12551740578|QUEROLLEN  |santander-way_pf|25.3.2    |5        |     |MARAVILHOSO          |2025-04-16T16:35:29-07:00|pf      |[]             |[title]       |no_match  |
+-----------+-----------+----------------+----------+---------+-----+---------------------+-------------------------+--------+---------------+--------------+----------+

```

![spark-rejeitado](https://github.com/gacarvalho/compass-deployment/blob/compass/infra-3.0.0/img/rejeitado.png)


Se voc√™ chegou at√© essa √∫ltima intera√ß√£o com o Spark, voc√™ conseguiu replicar todo o projeto Compass! 

---

# 7. Melhorias do projeto e Considera√ß√µes Finais

 
 ## 7.1 Melhorias do projeto
---

O case desenvolvido tem como foco principal evidenciar o valor estrat√©gico da Engenharia de Dados na gera√ß√£o de insights significativos sobre a experi√™ncia do usu√°rio, al√©m de viabilizar ao time de neg√≥cios o acesso a dados reais tanto dos pr√≥prios clientes quanto dos concorrentes. A proposta busca n√£o apenas promover uma vis√£o aprofundada da jornada do cliente, mas tamb√©m oferecer subs√≠dios concretos para decis√µes orientadas por dados, fortalecendo a atua√ß√£o da empresa em um mercado cada vez mais competitivo.

A seguir, ser√° listada os itens de sugest√£o de melhorias, evolu√ß√£o e contribui√ß√µes - divididas em estrutura funcional e t√©cnica:


**Funcional:**

  - **Escalabilidade** ‚Äì A arquitetura proposta foi pensada para ser escal√°vel e adapt√°vel a diferentes institui√ß√µes do mesmo segmento. No case, utilizamos como base o aplicativo de cart√µes, conta corrente e conta internal do Santander, mas como parte da evolu√ß√£o funcional, fica como sugest√£o a inclus√£o de novos pipelines (DAGs no Airflow) para ingest√£o e tratamento de dados de aplicativos concorrentes, como os das institui√ß√µes Nubank, Bradesco, Ita√∫, entre outros. Isso possibilita compara√ß√µes mais amplas e estrat√©gicas entre os players do mercado.
  - **Enriquecimento com Dados Externos** ‚Äì  Incorporar fontes de dados externas adicionais, como Reclame Aqui ou redes sociais, pode oferecer uma vis√£o ainda mais ampla e contextualizada sobre a percep√ß√£o do cliente. Esse enriquecimento auxilia na constru√ß√£o de an√°lises mais precisas e na prioriza√ß√£o de problemas cr√≠ticos para o neg√≥cio.
  - **Segmento por √°rea** ‚Äì Evoluir o dashboard funcional (Metabase) com a inclus√£o de filtros por √°reas respons√°veis pelos produtos, como PIX, Cart√µes, Contas, Cons√≥rcios, entre outros. Essa segmenta√ß√£o permite an√°lises mais direcionadas, facilita a prioriza√ß√£o de a√ß√µes por equipe e contribui para uma visualiza√ß√£o estrat√©gica dos indicadores conforme a estrutura organizacional da institui√ß√£o.



**T√©cnicas:**

  - **Camada de Observabilidade** ‚Äì Inser√ß√£o de alertas autom√°ticos no Grafana vinculados √† falha de execu√ß√£o de jobs. Esses alertas ser√£o classificados conforme a criticidade (prioridades 0, 1 e 2), considerando o impacto direto no pipeline e na entrega final dos dados ao cliente.
  - **Camada de Observabilidade** ‚Äì Amplia√ß√£o da vis√£o atual do dashboard de sustenta√ß√£o, que hoje √© focado em m√©tricas de aplica√ß√µes Spark, para tamb√©m contemplar o status das DAGs no Airflow. Essa melhoria visa cobrir cen√°rios onde o job Spark n√£o chega a ser executado por falhas no ambiente, vari√°veis de entrada incorretas, ou outros problemas de orquestra√ß√£o que atualmente n√£o s√£o capturados. Isso garante uma vis√£o mais completa da sa√∫de da aplica√ß√£o e contribui para uma resposta mais r√°pida a falhas.
  - **Camada de Observabilidade** ‚Äì Implementar alertas autom√°ticos no Grafana vinculados √† camada de valida√ß√£o dos dados no pipeline. Essa valida√ß√£o ao encontrar uma irregularidade, gere um alerta para o time de sustenta√ß√£o, onde √© verificado regras de integridade, conformidade de schema e verifica√ß√£o de valores nulos. Com isso, √© poss√≠vel detectar inconsist√™ncias em tempo real, reduzir riscos operacionais e assegurar a confiabilidade dos dados utilizados nas an√°lises e decis√µes estrat√©gicas.

  - **An√°lise de Sentimento com NLP** ‚Äì A aplica√ß√£o de t√©cnicas de Processamento de Linguagem Natural (NLP), como an√°lise de sentimento e classifica√ß√£o autom√°tica de t√≥picos, permitir√° categorizar coment√°rios e avalia√ß√µes com mais profundidade, facilitando a identifica√ß√£o de padr√µes de satisfa√ß√£o ou insatisfa√ß√£o por funcionalidade, vers√£o do app ou per√≠odo, mas sendo necess√°rio um tratamento da base para servir ao modelos de t√©cnicas de Processamento de Linguagem Natural com NLP.



 ## 7.2 Considera√ß√µes Finais
---

O projeto Compass refor√ßa o papel da Engenharia de Dados como elemento central na constru√ß√£o de solu√ß√µes voltadas para o neg√≥cio, com foco direto na experi√™ncia do usu√°rio. Ao oferecer uma estrutura confi√°vel, escal√°vel e orientada √† gera√ß√£o de insights, a iniciativa n√£o apenas empodera times de produto com dados relevantes sobre seus pr√≥prios aplicativos, mas tamb√©m fornece uma base comparativa frente aos concorrentes do setor. Com isso, o Compass se torna uma ferramenta valiosa para institui√ß√µes que buscam n√£o s√≥ entender, mas tamb√©m antecipar as necessidades dos seus clientes ‚Äî fortalecendo sua presen√ßa no mercado e avan√ßando na jornada rumo √† principalidade financeira.
