üß≠ ‚ô®Ô∏è COMPASS
---

<p align="left">
  <img src="https://img.shields.io/badge/projeto-Compass-blue?style=flat-square" alt="Projeto">
  <img src="https://img.shields.io/badge/vers√£o-1.0.0-blue?style=flat-square" alt="Vers√£o">
  <img src="https://img.shields.io/badge/status-deployed-green?style=flat-square" alt="Status">
  <img src="https://img.shields.io/badge/autor-Gabriel_Carvalho-lightgrey?style=flat-square" alt="Autor">
</p>

O reposit√≥rio **compass-deployment** √© uma solu√ß√£o desenvolvida no contexto do programa Data Master, promovido pela F1rst Tecnologia, com o objetivo de disponibilizar uma plataforma robusta e escal√°vel para captura, processamento e an√°lise de feedbacks de clientes do Banco Santander.


![<data-master-compass>](https://github.com/gacarvalho/repo-spark-delta-iceberg/blob/main/header.png?raw=true)

Este documento apresenta a vis√£o geral do projeto, abrangendo desde os objetivos iniciais at√© a descri√ß√£o t√©cnica da arquitetura, fluxos funcionais, tecnologias empregadas, instru√ß√µes para execu√ß√£o e considera√ß√µes finais. A proposta √© oferecer um panorama completo sobre o funcionamento do Compass como produto de analytics voltado √† experi√™ncia do cliente.



- [1. Objetivo do Projeto](#1-objetivo-do-projeto)
  * [1.1 O Projeto Compass](#11-o-projeto-compass)
- [2. Arquitetura da Solu√ß√£o](#2-arquitetura-da-solu√ß√£o)
- [3. Vis√£o Geral da Arquitetura T√©cnica](#3-vis√£o-geral-da-arquitetura-t√©cnica)
  * [3.1 Descri√ß√£o do Fluxo de Dados](#31-descri√ß√£o-do-fluxo-de-dados)
    + [3.1.1 Origens de Dados (fontes)](#311-origens-de-dados-fontes)
    + [3.1.2 Camada de Processamento](#312-camada-de-processamento)
    + [3.1.3 Camada de Armazenamento](#313-camada-de-armazenamento)
    + [3.1.4 Camada de Visualiza√ß√£o e Telemetria (observabilidade)](#314-camada-de-visualiza√ß√£o-e-telemetria-observabilidade)
  * [3.2 Aspectos T√©cnicos do Projeto Compass](#32-aspectos-t√©cnicos-do-projeto-compass)
    + [3.2.1 Tecnologias Utilizadas](#321-tecnologias-utilizadas)
    + [3.2.2 Caracteristicas da Execu√ß√£o do Projeto](#322-caracteristicas-da-execu√ß√£o-do-projeto)
    + [3.2.2.1 Infraestrutura do Projeto Compass](#3221-infraestrutura-do-projeto-compass)
    + [3.2.2.2 Aplica√ß√µes do Projeto Compass](#3222-aplica√ß√µes-do-projeto-compass)
    + [3.2.2.3  Malha do Projeto Compass](#3223-malha-do-projeto-compass)
- [4. Fluxo Funcional e Jornada do Cliente](#4-fluxo-funcional-e-jornada-do-cliente)
- [5. Compass como produto analytics Santander](#5-compass-como-produto-analytics-santander)
  * [5.1 Regras de Neg√≥cio](#51-regras-de-neg√≥cio)
  * [5.2 Dicion√°rio de Dados](#52-dicion√°rio-de-dados)
  * [5.3 Produtos Compass](#53-produtos-compass)
- [6. Instru√ß√µes para Configura√ß√£o e Execu√ß√£o do Projeto Compass](#6-instru√ß√µes-para-configura√ß√£o-e-execu√ß√£o-do-projeto-compass)
- [7. Melhorias do projeto e Considera√ß√µes Finais](#7-melhorias-do-projeto-e-considera√ß√µes-finais)



## 1. Objetivo do Projeto
---

A idealiza√ß√£o deste case surgiu da necessidade de conectar as dores do time de neg√≥cios ao potencial da Engenharia de Dados para resolv√™-las. O objetivo foi explorar como a extra√ß√£o, transforma√ß√£o e disponibiliza√ß√£o de informa√ß√µes podem gerar insights valiosos sobre a experi√™ncia dos clientes do Santander ao utilizarem seus produtos e servi√ßos. Al√©m disso, a solu√ß√£o tem o potencial de analisar as dores dos clientes da concorr√™ncia, permitindo uma vis√£o estrat√©gica ainda mais ampla.

### 1.1 O Projeto Compass
---

O **Projeto Data Master Compass** √© uma iniciativa de Engenharia de Dados projetada para capturar e analisar feedbacks de clientes sobre produtos e servi√ßos do Banco Santander. O nome `Compass` reflete seu prop√≥sito: orientar o time de neg√≥cios na melhoria cont√≠nua de processos e produtos, com base em dados reais.

Ao coletar e interpretar avalia√ß√µes dos clientes, o projeto identifica necessidades e oportunidades de aprimoramento, fortalecendo o compromisso do Santander com a satisfa√ß√£o e fideliza√ß√£o. Essa abordagem n√£o s√≥ refina a experi√™ncia do cliente, mas tamb√©m consolida o banco como refer√™ncia no mercado, contribuindo para a **principalidade** ‚Äî ser o banco principal de seus clientes.

A solu√ß√£o centraliza as informa√ß√µes em um **Data Lake** no HDFS, categorizando por data de referencia e segmento (PF e PJ). Isso proporciona insights valiosos para **Product Owners**, **Product Managers** e **Gerentes de Projetos**, permitindo decis√µes baseadas em evid√™ncias e alinhadas √†s necessidades reais dos clientes.

üß≠ **Exemplo Pr√°tico**

Imagine uma equipe desenvolvendo uma nova funcionalidade para contas correntes, como extratos detalhados com mais de 90 dias de transa√ß√µes. Sem feedbacks reais, as melhorias podem ser implementadas com base em suposi√ß√µes internas. O Projeto Compass elimina essa incerteza, fornecendo acesso r√°pido √†s avalia√ß√µes dos clientes, substituindo pesquisas demoradas e garantindo que as melhorias atendam √†s expectativas reais.

Agora, imagine que o Banco Santander deseja lan√ßar um novo canal de investimentos para jovens do ensino m√©dio. Como √© um produto novo para o banco, √© essencial entender como esse modelo funciona no mercado. O Projeto Compass possibilita a an√°lise das principais reclama√ß√µes e elogios dos clientes da concorr√™ncia, oferecendo insights estrat√©gicos para um lan√ßamento mais assertivo.

Al√©m disso, times respons√°veis por produtos como PIX, Cons√≥rcio e Contas Correntes podem monitorar continuamente a evolu√ß√£o de suas funcionalidades, acompanhando a satisfa√ß√£o dos clientes por segmento e canal, com avalia√ß√µes de 1 a 5 estrelas.

Em resumo, o Projeto Compass √© uma iniciativa estrat√©gica que alinha o desenvolvimento de produtos √†s necessidades reais dos clientes, impulsionando a excel√™ncia operacional e aprimorando a experi√™ncia do usu√°rio.


## 2. Arquitetura da Solu√ß√£o
---

A arquitetura proposta √© baseada em um ambiente **on-premises**, utilizando tecnologias para armazenamento, processamento e visualiza√ß√£o de dados. A solu√ß√£o √© composta por v√°rias camadas, cada uma com um papel espec√≠fico no fluxo de dados.

![<arquitetura-data-master-compass>](https://raw.githubusercontent.com/gacarvalho/repo-spark-delta-iceberg/refs/heads/main/arquitetura.png)

Separando a arquitetura do Compass por compoentes, √© pos≈õivel entender que √© composta por quatro componentes principais, cada um respons√°vel por uma etapa espec√≠fica do fluxo de dados:

| **Componente**          | **Descri√ß√£o**                                                                 | **Vers√£o**  |
|-------------------------|-------------------------------------------------------------------------------|---------------------------------|
| Storage                 | Armazenamento de dados funcionais dividido em duas categorias: <br> - Avalia√ß√µes internas dos aplicativos Santander: Alimentadas via API e canal de feedback, armazenadas no MongoDB. <br> - M√©tricas aplicacionais: Armazenadas no Elasticsearch. <br> Armazenamento de dados historico: <br> - Armazenamento de dados hist√≥ricos com reten√ß√£o m√°xima de cinco anos. Utiliza Apache Hadoop para suportar grandes volumes de dados. | MongoDB: 7 <br>  Elasticsearch: 8.16.1 <br> Apache Hadoop: 3.1.1  |
| Processing              | Utiliza Apache Spark para processamento distribu√≠do de dados.                 | Apache Spark 3.5.0 |
| Visualization           | M√©tricas t√©cnicas: Grafana. <br> M√©tricas funcionais: Metabase. | Grafana, Metabase |
| Orchestrator            | Apache Airflow √© utilizado como orquestrador principal da malha de dados do projeto. | Apache Airflow 2.7.2 |


> [!NOTE]
> O reposit√≥rio da infraestrutura do Hadoop foi desenvolvida em:
> https://github.com/gacarvalho/infra-data-master-compass



## 3. Vis√£o Geral da Arquitetura T√©cnica
---

Como base da arquitetura, o projeto Compass utiliza alguns recursos para realizar o processo desde a extra√ß√£o dos dados at√© a disponibiliza√ß√£o. O ambiente onde o projeto est√° em execu√ß√£o √© on-premisses e foram divididas em algumas camadas, como:

- **Arquitetura Batch**: Servi√ßos e produtos finais referente a arquitetura de big data on-premisse.
  
| **Arquitetura** | **Camada**                   | **Descri√ß√£o**                                                                                   | **P√∫blico alvo**        |
|-----------------|------------------------------|-------------------------------------------------------------------------------------------------|-------------------------|
| Batch           | Camada de Observabilidade     | Servi√ßos respons√°veis por coletar e monitorar dados de telemetria, fornecendo visibilidade sobre o desempenho e a integridade dos recursos das aplica√ß√µes. | Time Dev, Sustenta√ß√£o   |
| Batch           | Camada de Business Service    | Servi√ßos focados em an√°lise e intelig√™ncia de neg√≥cios, fornecendo insights estrat√©gicos para decis√µes organizacionais por meio de BI e relat√≥rios anal√≠ticos. | Plataforma, Ger√™ncia    |
| Batch           | Camada de Aplica√ß√µes          | Aplica√ß√µes desenvolvidas em PySpark (Python), com artefatos implementados em containers, oferecendo uma abordagem escal√°vel e modular para processamento de dados. | Time Dev                |



### 3.1 Descri√ß√£o do Fluxo de Dados
---

Como parte da arquitetura, vamos ter 3 divis√µes bases, como: Extra√ß√£o de dados, Transforma√ß√£o de Dados e Carga de Dados.

> [!IMPORTANT]
> Descri√ß√£o das collections e armazenamento est√£o descritos para **v1 do Projeto Compass**!


#### 3.1.1 Origens de Dados (fontes)

As cole√ß√µes do MongoDB representam o armazenamento interno do Santander, utilizado para armazenar os feedbacks provenientes de diversos canais, refletindo a jornada do cliente dentro do aplicativo Santander. Essas cole√ß√µes s√£o alimentadas conforme o canal respons√°vel por cada intera√ß√£o.


- **BASE INTERNA SANTANDER**:
    - `Collections (MongoDB) Santander Way`: Aplica√ß√£o m√≥vel do Santander utilizada pelos clientes.
    - `Collections (MongoDB) Santander BR`: Aplica√ß√£o m√≥vel do Santander para opera√ß√µes banc√°rias.
    - `Collections (MongoDB) Santander Select Global`: Aplica√ß√£o m√≥vel de conta em d√≥lar do Santander.
    - `Collections (MongoDB) Outros Aplicativos Santander`: Diversos aplicativos que fornecem dados transacionais.

As APIs externas s√£o respons√°veis pela captura de dados provenientes de fontes fora do ecossistema Santander, utilizando duas APIs distintas. A SERPAPI, uma solu√ß√£o paga, foi escolhida como alternativa devido a uma limita√ß√£o no acesso direto aos dados do Google Play. Como n√£o somos propriet√°rios do aplicativo Santander na plataforma, n√£o podemos acessar essas informa√ß√µes diretamente. Para realizar a extra√ß√£o dos dados, seria necess√°rio ser propriet√°rio do aplicativo na Google Play Store e possuir uma conta de servi√ßo com permiss√µes de desenvolvedor. Diante dessa restri√ß√£o, a SERPAPI foi adotada como uma solu√ß√£o vi√°vel.

Por outro lado, a API do iTunes est√° dispon√≠vel sem custos, mas sua utiliza√ß√£o requer uma libera√ß√£o de firewall e a colabora√ß√£o com um time respons√°vel pela extra√ß√£o de dados externos do Santander. Vale destacar que, ao utilizar essa API, h√° uma limita√ß√£o no n√∫mero de avalia√ß√µes que podem ser acessadas, sendo poss√≠vel buscar apenas as √∫ltimas 500 avalia√ß√µes.

- **EXTENO SANTANDER**:
    - `SerpApi`: API utilizada para coletar avalia√ß√µes do **Google Play** (opcional).
    - `itunes.apple.com`: API utilizada para coletar avalia√ß√µes da **Apple Store**.

#### 3.1.2 Camada de Processamento 

A Camada de Processamento √© uma das principais respons√°veis pelo tratamento e transforma√ß√£o dos dados dentro do projeto Compass, composta por tr√™s camadas distintas de processamento utilizando o Apache Spark. Cada camada tem um papel espec√≠fico no fluxo de dados, desde a ingest√£o at√© o enriquecimento final.

- **PROCESSAMENTO**:
    - `Spark Bronze - Ingestion`: Respons√°vel pela ingest√£o e pr√©-processamento de dados.
    - `Spark Silver`: Camada intermedi√°ria de processamento, armazenando dados hist√≥ricos.
    - `Spark Gold`: Camada de agrega√ß√£o e enriquecimento dos dados processados.

> [!NOTE]
> A regra de neg√≥cios est√° detalhado no item `4. Fluxo Funcional e Jornada do Cliente`!

#### 3.1.3 Camada de Armazenamento

- **ARMAZENAMENTO**:
    - `MongoDB`: Banco de dados NoSQL para armazenamento estruturado para dados funcionais.

  <details>
    <summary>Informa√ß√µes Detalhada do Armazenamento: MONGODB</summary>
  
  
    | **Collection**                          | **Descri√ß√£o**                                          | **Quem Alimenta**                              |
    |-----------------------------------------|--------------------------------------------------------|------------------------------------------------|
    | banco-santander-br                      | Feedbacks e avalia√ß√µes do aplicativo Santander BR      | Canal                                          |
    | santander-select-global                 | Feedbacks e avalia√ß√µes do aplicativo Santander Select Global            | Canal            |
    | santander-way                           | Feedbacks e avalia√ß√µes do aplicativo Santander Way     | Canal                       |
    | dt_d_view_gold_agg_compass              | Camada de agrega√ß√£o de dados hist√≥ricos e enriquecidos  |  <ul><li>Processos de agrega√ß√£o e an√°lise do Compass</li> <li>  DAG: dag_d_pipeline_compass_reviews. </li> <li> JOB: GOLD_APP_GOLD_AGGREGATE_REVIEWS_SANTANDER    </li> |
    | dt_d_view_silver_historical_compass     | Camada intermedi√°ria de dados hist√≥ricos               | <ul><li> Processos de pr√©-processamento e agrega√ß√£o do Compass </li> <li>  DAG: dag_d_pipeline_compass_reviews. </li> <li>  JOB: GOLD_APP_GOLD_AGGREGATE_REVIEWS_SANTANDE </li> </ul> |
  
  </details>




  - `Hadoop`: Sistema distribu√≠do para armazenamento e processamento de dados.



  <details>
    <summary>Informa√ß√µes Detalhada do Armazenamento: HADOOP</summary>

    <p>A camada Bronze armazena dados brutos coletados de diferentes fontes. Esses dados ainda n√£o passaram por processamento ou transforma√ß√£o. Subdiret√≥rios por aplicativo: `banco-santander-br_pf`, `santander-select-global_pf`, `santander-way_pf`. Abaixo est√° a estrutura detalhada:</p>

    > Caminho Base Bronze: `/santander/bronze/compass/reviews/`
    
    
    | **Plataforma**     | **Caminho**                                       | **Subdiret√≥rios por Aplicativo**                                                                | **Organiza√ß√£o**                                 |
    |--------------------|---------------------------------------------------|------------------------------------------------------------------------------------------------|------------------------------------------------|
    | **Apple Store**     | `/santander/bronze/compass/reviews/appleStore/`   | <ul><li> `banco-santander-br_pf/`</li> <li>`santander-select-global_pf/`</li> <li>`santander-way_pf/`</li></ul>                     | Subdiret√≥rios por data (`odate=YYYYMMDD`)      |
    | **Google Play**     | `/santander/bronze/compass/reviews/googlePlay/`   | <ul><li>`banco-santander-br_pf/` </li><li>`santander-select-global_pf/`</li> <li>`santander-way_pf/` </li></ul>                     | Subdiret√≥rios por data (`odate=YYYYMMDD`)      |
    | **MongoDB**         | `/santander/bronze/compass/reviews/mongodb/`      | <ul><li>`banco-santander-br_pf/` </li><li>`santander-select-global_pf/`</li> <li>`santander-way_pf/` </li>                     | Subdiret√≥rios por data (`odate=YYYYMMDD`)      |

    ---
    
    A camada **Silver** cont√©m dados processados e transformados a partir da camada Bronze. Esses dados s√£o mais estruturados e prontos para an√°lise.
    
    > Caminho Base Silver: `/santander/silver/compass/reviews/`
    
    
    
    | **Plataforma**     | **Caminho**                                       | **Subdiret√≥rios por Aplicativo**           | **Organiza√ß√£o**                                 |
    |--------------------|---------------------------------------------------|--------------------------------------------|------------------------------------------------|
    | **Apple Store**     | `/santander/silver/compass/reviews/appleStore/`   | Dados processados da Apple Store.         | Subdiret√≥rios por data (`odate=YYYYMMDD`)      |
    | **Google Play**     | `/santander/silver/compass/reviews/googlePlay/`   | Dados processados do Google Play.         | Subdiret√≥rios por data (`odate=YYYYMMDD`)      |
    | **MongoDB**         | `/santander/silver/compass/reviews/mongodb/`      | Dados processados do MongoDB.             | Subdiret√≥rios por data (`odate=YYYYMMDD`)      |
    | **Falhas**          | `/santander/silver/compass/reviews_fail/`         | Dados que falharam no processamento.      | Subdiret√≥rios por data (`odate=YYYYMMDD`)      |
    
    ---
    
    A camada **Gold** cont√©m dados agregados e prontos para consumo final. Esses dados s√£o utilizados para gera√ß√£o de relat√≥rios, dashboards e an√°lises avan√ßadas.
    > Caminho Base Gold: `/santander/gold/compass/reviews/`
    
    | **Tipo de Dado**          | **Caminho**                                       | **Descri√ß√£o**                                                                                   | **Organiza√ß√£o**                                 |
    |---------------------------|---------------------------------------------------|------------------------------------------------------------------------------------------------|------------------------------------------------|
    | **Agrega√ß√£o de Reviews**  | `/santander/gold/compass/reviews/apps_santander_aggregate/` | Dados agregados dos aplicativos do Santander.                                                  | Subdiret√≥rios por data (`odate=YYYYMMDD`)      |
    | **Falhas no Processamento** | `/santander/gold/compass/reviews_fail/`           | Dados que falharam no processamento final.                                                     | Subdiret√≥rios por data (`odate=YYYYMMDD`)      |
    
    ---
    
    
    A camada **Quality** cont√©m dados relacionados √† qualidade dos dados, como padr√µes de valida√ß√£o e m√©tricas de qualidade.
    > Caminho Base Quality: `/santander/quality/compass/reviews/`
    
    | **Tipo de Dado**          | **Caminho**                                       | **Descri√ß√£o**                                                                                   | **Organiza√ß√£o**                                 |
    |---------------------------|---------------------------------------------------|------------------------------------------------------------------------------------------------|------------------------------------------------|
    | **Padr√µes de Valida√ß√£o**  | `/santander/quality/compass/reviews/pattern/`     | Padr√µes de valida√ß√£o aplicados aos dados.                                                      | Subdiret√≥rios por plataforma (ex: `pattern/`, `schema/`) |
    
  
  </details>

  - `Elasticsearch`: O **Elasticsearch** √© usado para indexa√ß√£o e busca de dados t√©cnicos. Abaixo est√£o os √≠ndices dispon√≠veis, com seus objetivos e respons√°veis pela ingest√£o dos dados.

  <details>
      <summary>Informa√ß√µes Detalhada do Armazenamento: ELASTICSEARCH</summary>
    
    
    | **√çndice**                         | **Objetivo**                                  | **Quem Alimenta** |
    |-------------------------------------|-----------------------------------------------|-------------------|
    | **compass_dt_datametrics**          | Dados t√©cnicos de m√©tricas de performance     | <ul><li> DAG: `dag_d_pipeline_compass_review` </li> <li>JOB: Todos JOBS SPARK (group_ingestion, group_jobs_silver, group_jobs_gold)</li></ul> |
    | **compass_dt_datametrics_fail**     | Dados de falhas nas m√©tricas de performance   | <ul><li> DAG: `dag_d_pipeline_compass_reviews` </li> <li> JOB: Todos JOBS SPARK (group_ingestion, group_jobs_silver, group_jobs_gold) </li></ul> |
    
  </details>



#### 3.1.4 Camada de Visualiza√ß√£o e Telemetria (observabilidade)

- `Metabase`: Ferramenta de Business Intelligence (BI) para an√°lise de dados.
  <details>
    <summary>Informa√ß√µes Detalhada do Dashboard: METABASE </summary>

    O Metabase √© uma ferramenta de Business Intelligence (BI) que permite a an√°lise de dados de forma intuitiva e visual. Ele facilita a cria√ß√£o de dashboards interativos e relat√≥rios sem a necessidade de conhecimento avan√ßado em queries.

    - **Objetivo do Metabase:**  O principal objetivo do Metabase √© fornecer uma interface amig√°vel para que usu√°rios de neg√≥cio possam acessar, visualizar e analisar dados sem depend√™ncia de equipes t√©cnicas. Ele permite a tomada de decis√µes baseada em dados de forma √°gil e eficiente.

    - **Por que utilizar o Metabase?** 
        - Interface intuitiva: N√£o requer conhecimento avan√ßado em queries.
        - Open-source e extens√≠vel: Pode ser personalizado conforme necessidade.
        - Integra√ß√£o com diversas fontes de dados: Suporte para bancos SQL e NoSQL.
        - Cria√ß√£o r√°pida de dashboards: Permite visualizar KPIs e m√©tricas facilmente.
        - Automatiza√ß√£o de relat√≥rios: Gera√ß√£o autom√°tica de relat√≥rios e alertas por e-mail.       

    - **Dashboards  (link de acesso):** Os dashboards criados no Metabase fornecem uma vis√£o detalhada dos principais indicadores e m√©tricas da organiza√ß√£o.

    | **Categoria**                     | **M√©tricas**             | **Ambiente** | **Link de acesso**
    |-----------------------------------|--------------------------|--------------|----------------------
    | Observabilidade Aplica√ß√£o         | Aplica√ß√£o (neg√≥cio)      | Pro-Produ√ß√£o | [Dashboard Compass - PRO - Data - Metabase](http://00.000.000.00:8085/setup)


  - **Metodologia e boas pr√°ticas:** Utilizando as boas pr√°ticas, o dashboard foi dividido em 3 vis√µes: (1) vis√£o gerencial, (2) vis√£o macro por ano-mes e (3) vis√£o granular.

    A vis√£o (1) √© dedicada para a vis√£o gerencial estruturado com vis√µes gr√°ficas estraturada em:

      - M√©dia da experi√™ncia do cliente atual
      - Segmenta√ß√£o do(s) canais Santander PF e PJ 
      - Nota m√©dia do(s) aplicativos Santander - hist√≥rico
      - Volumetria de avalia√ß√µes dos apps Santander - total
      - Volume por canais e segmento
      - Volumetria de avalia√ß√µes nos canais Santander por ano-mes
      - Volume por origem extra√ß√£o e segmento
      - Volumetria de avalia√ß√µes dos canais Santander por origem

    J√° a vis√£o (2) √© dedicada para a vis√£o macro gerencial estruturado em tabela com vis√µes das seguintes informa√ß√µes:

      - App nome
      - App Source
      - Periodo Referencia
      - Segmento
      - Nota M√©dia
      - Avalia√ß√µes Totais
      - Coment√°rios Positivos
      - Coment√°rios Negativos

    E a vis√£o (3) j√° √© com a menor granularidade, sendo os eventos de feedbacks dos clientes, estruturado em tabela nas seguintes vis√µes:
  
      - Titulo
      - Snippet (conte√∫do da avalia√ß√£o)
      - App Source
      - App
      - Segmento
      - Nota
      - Timestamp da avalia√ß√£o
      - Periodo Rereferencia 
  - **Tabela de m√©tricas utilizadas:**

    | **Componente**              | **Categoria**            | Vis√£o | **Tipo de Painel**        | **Nome da m√©trica**                         | **Unidade**  | **Descri√ß√£o** | **Query Metrica** | **Fonte**
    |-----------------------------|--------------------------|-------|-------------------|---------------------------------------------|--------------|---------------|-----------------------------------|----------------------------
    | Nota m√©dia das avalia√ß√µes   | Indicador                | Display: Progresso  | Dashboard     | M√©dia da experi√™ncia do cliente atual       | 1 a 5        | Nota m√©dia das avalia√ß√µes dos clientes de 1 a 5 de acordo filtro selecionado| `[ {"$sort":{"periodo_referencia":-1}}, {"$project":{"app_nome":"$app_nome","app_source":"$app_source","periodo_referencia":"$periodo_referencia","nota_media":{"$round":["$nota_media",0]},"avaliacoes_total":"$avaliacoes_total","comentarios_positivos":"$comentarios_positivos","comentarios_negativos":"$comentarios_negativos","segmento":"$segmento"}}, {"$limit":1048575}, {"$match":{"$and":[{"nota_media":{"$gte":1}},{"nota_media":{"$lte":5}}]}}, {"$sort":{"periodo_referencia":1,"app_nome":1,"app_source":1}}, {"$project":{"_id":"$_id","app_nome":"$app_nome","app_source":"$app_source","periodo_referencia":"$periodo_referencia","nota_media":"$nota_media","avaliacoes_total":"$avaliacoes_total","comentarios_positivos":"$comentarios_positivos","comentarios_negativos":"$comentarios_negativos","segmento":"$segmento"}}, {"$limit":1048575}, {"$match":{"$and":[{"nota_media":{"$gte":1}},{"nota_media":{"$lte":5}}]}}, {"$group":{"_id":{"periodo_referencia":"$periodo_referencia","segmento":"$segmento"},"avg_nota_media":{"$avg":"$nota_media"},"app_nome":{"$first":"$app_nome"},"app_source":{"$first":"$app_source"}}}, {"$sort":{"_id":1}}, {"$project":{"_id":false,"periodo_referencia":"$_id.periodo_referencia","segmento":"$_id.segmento","avg":"$avg_nota_media","app_nome":1,"app_source":1}}, { "$match": { "$expr": { "$eq": [ "$periodo_referencia", { "$max": "$periodo_referencia" } ] } } }, { "$sort": { "periodo_referencia": -1 } }, { "$project": { "_id": false, "avg": "$avg" } }, { "$limit": 1 } ]` | MongoDB
    | Volumetria de reclama√ß√µes por segmento   | Indicador   | Display: Pizza  |Dashboard     | Segmenta√ß√£o do(s) canais Santander - PF e PJ ~| PF, PJ + volumetria        | Volumetria de reclama√ß√µes por segmento x volumetria + porcentagem | `[ {"$sort":{"periodo_referencia":-1}}, {"$project":{"app_nome":"$app_nome","app_source":"$app_source","periodo_referencia":"$periodo_referencia","nota_media":{"$round":["$nota_media",0]},"avaliacoes_total":"$avaliacoes_total","comentarios_positivos":"$comentarios_positivos","comentarios_negativos":"$comentarios_negativos","segmento":"$segmento"}}, {"$limit":1048575}, {"$match":{"$and":[{"nota_media":{"$gte":1}},{"nota_media":{"$lte":5}}]}}, {"$sort":{"periodo_referencia":1,"app_nome":1,"app_source":1}}, {"$project":{"_id":"$_id","app_nome":"$app_nome","app_source":"$app_source","periodo_referencia":"$periodo_referencia","nota_media":"$nota_media","avaliacoes_total":"$avaliacoes_total","comentarios_positivos":"$comentarios_positivos","comentarios_negativos":"$comentarios_negativos","segmento":"$segmento"}}, {"$limit":1048575}, {"$match":{"$and":[{"nota_media":{"$gte":1}},{"nota_media":{"$lte":5}}]}}, {"$group":{"_id":{"periodo_referencia":"$periodo_referencia","segmento":"$segmento"},"avg_nota_media":{"$avg":"$nota_media"},"app_nome":{"$first":"$app_nome"},"app_source":{"$first":"$app_source"}}}, {"$sort":{"_id":1}}, {"$project":{"_id":false,"periodo_referencia":"$_id.periodo_referencia","segmento":"$_id.segmento","avg":"$avg_nota_media","app_nome":1,"app_source":1}}, { "$match": { "$and": [ { "$and": [ { "avg": { "$gte": 1 } }, { "avg": { "$lte": 5 } } ] }, { "$or": [ { "segmento": "PF" }, { "segmento": "PJ" } ] } ] } }, { "$sort": { "periodo_referencia": -1 } }, { "$project": { "_id": false, "periodo_referencia": "$periodo_referencia", "segmento": "$segmento", "avg": "$avg", "app_nome": "$app_nome", "app_source": "$app_source" } }, { "$limit": 1048575 } ]` | MongoDB
    | Nota m√©dia dos aplicativos Santander por ano m√™s   | Indicador   | Display: Barra  |Dashboard     | Nota m√©dia do(s) aplicativos Santander - historico ~| M√©dia da nota por ano m√™s       | Nota rela√ß√£o aplicativos Santader por ano m√™s de acordo filtro selecionado| `[ {"$sort":{"periodo_referencia":-1}}, {"$project":{"app_nome":"$app_nome","app_source":"$app_source","periodo_referencia":"$periodo_referencia","nota_media":{"$round":["$nota_media",0]},"avaliacoes_total":"$avaliacoes_total","comentarios_positivos":"$comentarios_positivos","comentarios_negativos":"$comentarios_negativos","segmento":"$segmento"}}, {"$limit":1048575}, {"$match":{"$and":[{"nota_media":{"$gte":1}},{"nota_media":{"$lte":5}}]}}, {"$sort":{"periodo_referencia":1,"app_nome":1,"app_source":1}}, {"$project":{"_id":"$_id","app_nome":"$app_nome","app_source":"$app_source","periodo_referencia":"$periodo_referencia","nota_media":"$nota_media","avaliacoes_total":"$avaliacoes_total","comentarios_positivos":"$comentarios_positivos","comentarios_negativos":"$comentarios_negativos","segmento":"$segmento"}}, {"$limit":1048575}, {"$match":{"$and":[{"nota_media":{"$gte":1}},{"nota_media":{"$lte":5}}]}}, {"$group":{"_id":{"periodo_referencia":"$periodo_referencia","segmento":"$segmento"},"avg_nota_media":{"$avg":"$nota_media"},"app_nome":{"$first":"$app_nome"},"app_source":{"$first":"$app_source"}}}, {"$sort":{"_id":1}}, {"$project":{"_id":false,"periodo_referencia":"$_id.periodo_referencia","segmento":"$_id.segmento","avg":"$avg_nota_media","app_nome":1,"app_source":1}}, { "$match": { "$and": [ { "avg": { "$gte": 1 } }, { "avg": { "$lte": 5 } } ] } }, { "$sort": { "periodo_referencia": -1 } }, { "$project": { "_id": false, "periodo_referencia": "$periodo_referencia", "segmento": "$segmento", "avg": "$avg", "app_nome": "$app_nome", "app_source": "$app_source" } }, { "$limit": 1048575 } ]` | MongoDB
    | Volumetria de avalia√ß√µes totais   | Indicador   | Display: Indicador  |Dashboard     | Volumetria de avalia√ß√µes dos apps Santander total ~ | Volumetria totais de avalia√ß√µes      | Volumetria totais de avalia√ß√µes de acordo filtro selecionado| `[ {"$sort":{"periodo_referencia":1}}, {"$project":{"_id":"$_id","app_nome":"$app_nome","app_source":"$app_source","periodo_referencia":"$periodo_referencia","nota_media":"$nota_media","nota_tendencia":"$nota_tendencia","avaliacoes_total":"$avaliacoes_total","comentarios_positivos":"$comentarios_positivos","comentarios_negativos":"$comentarios_negativos","segmento":"$segmento"}}, {"$limit":1048575}, {"$match":{"$and":[{"nota_media":{"$gte":1}},{"nota_media":{"$lte":5}}]}}, {"$sort":{"periodo_referencia":-1}}, {"$project":{"_id":"$_id","app_nome":"$app_nome","app_source":"$app_source","periodo_referencia":"$periodo_referencia","nota_media":"$nota_media","nota_tendencia":"$nota_tendencia","avaliacoes_total":"$avaliacoes_total","comentarios_positivos":"$comentarios_positivos","comentarios_negativos":"$comentarios_negativos","segmento":"$segmento"}}, {"$limit":1048575}, {"$group":{"_id":{"periodo_referencia":"$periodo_referencia","segmento":"$segmento","app_nome":"$app_nome","app_source":"$app_source"},"avg_nota_media":{"$avg":"$nota_media"},"avg_nota_tendencia":{"$avg":"$nota_tendencia"},"total_avaliacoes":{"$sum":"$avaliacoes_total"}}}, {"$sort":{"_id":1}}, {"$project":{"_id":false,"periodo_referencia":"$_id.periodo_referencia","segmento":"$_id.segmento","app_nome":"$_id.app_nome","app_source":"$_id.app_source","avg_nota_media":"$avg_nota_media","avg_nota_tendencia":"$avg_nota_tendencia","total_avaliacoes":"$total_avaliacoes"}}, { "$group": { "_id": null, "sum": { "$sum": "$total_avaliacoes" } } }, { "$sort": { "_id": 1 } }, { "$project": { "_id": false, "sum": true } } ]` | MongoDB
    | Volumetria de avalia√ß√µes totais agregados por canais e segmento   | Indicador   | Display: Pizza  |Dashboard     | Volume por canais e segmento ~ | Volumetria totais de avalia√ß√µes agregado por cenais e segmento    | Volumetria totais de avalia√ß√µes agregado de acordo filtro selecionado | `[ {"$sort":{"periodo_referencia":1}}, {"$project":{"_id":"$_id","app_nome":"$app_nome","app_source":"$app_source","periodo_referencia":"$periodo_referencia","nota_media":"$nota_media","nota_tendencia":"$nota_tendencia","avaliacoes_total":"$avaliacoes_total","comentarios_positivos":"$comentarios_positivos","comentarios_negativos":"$comentarios_negativos","segmento":"$segmento"}}, {"$limit":1048575}, {"$match":{"$and":[{"nota_media":{"$gte":1}},{"nota_media":{"$lte":5}}]}}, {"$sort":{"periodo_referencia":-1}}, {"$project":{"_id":"$_id","app_nome":"$app_nome","app_source":"$app_source","periodo_referencia":"$periodo_referencia","nota_media":"$nota_media","nota_tendencia":"$nota_tendencia","avaliacoes_total":"$avaliacoes_total","comentarios_positivos":"$comentarios_positivos","comentarios_negativos":"$comentarios_negativos","segmento":"$segmento"}}, {"$limit":1048575}, {"$group":{"_id":{"periodo_referencia":"$periodo_referencia","segmento":"$segmento","app_nome":"$app_nome","app_source":"$app_source"},"avg_nota_media":{"$avg":"$nota_media"},"avg_nota_tendencia":{"$avg":"$nota_tendencia"},"total_avaliacoes":{"$sum":"$avaliacoes_total"}}}, {"$sort":{"_id":1}}, {"$project":{"_id":false,"periodo_referencia":"$_id.periodo_referencia","segmento":"$_id.segmento","app_nome":"$_id.app_nome","app_source":"$_id.app_source","avg_nota_media":"$avg_nota_media","avg_nota_tendencia":"$avg_nota_tendencia","total_avaliacoes":"$total_avaliacoes"}}, { "$sort": { "periodo_referencia": -1 } }, { "$project": { "_id": false, "periodo_referencia": "$periodo_referencia", "segmento": "$segmento", "app_nome": "$app_nome", "app_source": "$app_source", "total_avaliacoes": "$total_avaliacoes" } }, { "$limit": 1048575 } ]` | MongoDB
    | Volumetria de avalia√ß√µes totais agregados por canais e segmento   | Indicador   | Display: Barra  |Dashboard     | Volumetria de avalia√ß√µes nos Canais Santander por ano-mes ~ | Volumetria totais de avalia√ß√µes agregado por cenais e segmento    | Volumetria totais de avalia√ß√µes agregado de acordo filtro selecionado selecionado | `[ {"$sort":{"periodo_referencia":1}}, {"$project":{"_id":"$_id","app_nome":"$app_nome","app_source":"$app_source","periodo_referencia":"$periodo_referencia","nota_media":"$nota_media","nota_tendencia":"$nota_tendencia","avaliacoes_total":"$avaliacoes_total","comentarios_positivos":"$comentarios_positivos","comentarios_negativos":"$comentarios_negativos","segmento":"$segmento"}}, {"$limit":1048575}, {"$match":{"$and":[{"nota_media":{"$gte":1}},{"nota_media":{"$lte":5}}]}}, {"$sort":{"periodo_referencia":-1}}, {"$project":{"_id":"$_id","app_nome":"$app_nome","app_source":"$app_source","periodo_referencia":"$periodo_referencia","nota_media":"$nota_media","nota_tendencia":"$nota_tendencia","avaliacoes_total":"$avaliacoes_total","comentarios_positivos":"$comentarios_positivos","comentarios_negativos":"$comentarios_negativos","segmento":"$segmento"}}, {"$limit":1048575}, {"$group":{"_id":{"periodo_referencia":"$periodo_referencia","segmento":"$segmento","app_nome":"$app_nome","app_source":"$app_source"},"avg_nota_media":{"$avg":"$nota_media"},"avg_nota_tendencia":{"$avg":"$nota_tendencia"},"total_avaliacoes":{"$sum":"$avaliacoes_total"}}}, {"$sort":{"_id":1}}, {"$project":{"_id":false,"periodo_referencia":"$_id.periodo_referencia","segmento":"$_id.segmento","app_nome":"$_id.app_nome","app_source":"$_id.app_source","avg_nota_media":"$avg_nota_media","avg_nota_tendencia":"$avg_nota_tendencia","total_avaliacoes":"$total_avaliacoes"}}, { "$sort": { "periodo_referencia": -1 } }, { "$project": { "_id": false, "periodo_referencia": "$periodo_referencia", "segmento": "$segmento", "app_nome": "$app_nome", "app_source": "$app_source", "total_avaliacoes": "$total_avaliacoes" } }, { "$limit": 1048575 } ]` | MongoDB
    | Volumetria agregada por origem de extra√ß√£o e segmento PF/PJ   | Indicador   | Display: Pizza  |Dashboard     | Volume por Origem Extracao e Segmento ~ | Volumetria agregada por origem e segmento dos clientes    | Volumetria agregada por origem e segmento de acordo filtro selecionado | `[ {"$sort":{"periodo_referencia":1}}, {"$project":{"_id":"$_id","app_nome":"$app_nome","app_source":"$app_source","periodo_referencia":"$periodo_referencia","nota_media":"$nota_media","nota_tendencia":"$nota_tendencia","avaliacoes_total":"$avaliacoes_total","comentarios_positivos":"$comentarios_positivos","comentarios_negativos":"$comentarios_negativos","segmento":"$segmento"}}, {"$limit":1048575}, {"$match":{"$and":[{"nota_media":{"$gte":1}},{"nota_media":{"$lte":5}}]}}, {"$sort":{"periodo_referencia":-1}}, {"$project":{"_id":"$_id","app_nome":"$app_nome","app_source":"$app_source","periodo_referencia":"$periodo_referencia","nota_media":"$nota_media","nota_tendencia":"$nota_tendencia","avaliacoes_total":"$avaliacoes_total","comentarios_positivos":"$comentarios_positivos","comentarios_negativos":"$comentarios_negativos","segmento":"$segmento"}}, {"$limit":1048575}, {"$group":{"_id":{"periodo_referencia":"$periodo_referencia","segmento":"$segmento","app_nome":"$app_nome","app_source":"$app_source"},"avg_nota_media":{"$avg":"$nota_media"},"avg_nota_tendencia":{"$avg":"$nota_tendencia"},"total_avaliacoes":{"$sum":"$avaliacoes_total"}}}, {"$sort":{"_id":1}}, {"$project":{"_id":false,"periodo_referencia":"$_id.periodo_referencia","segmento":"$_id.segmento","app_nome":"$_id.app_nome","app_source":"$_id.app_source","avg_nota_media":"$avg_nota_media","avg_nota_tendencia":"$avg_nota_tendencia","total_avaliacoes":"$total_avaliacoes"}}, { "$sort": { "periodo_referencia": -1 } }, { "$project": { "_id": false, "periodo_referencia": "$periodo_referencia", "segmento": "$segmento", "app_nome": "$app_nome", "app_source": "$app_source", "total_avaliacoes": "$total_avaliacoes" } }, { "$limit": 1048575 } ]` | MongoDB
    | Volumetria agregada por canais vs origem   | Indicador   | Display: Linha  |Dashboard     | Volumetria de avalia√ß√µes dos Canais Santander por Origem ~ | Volumetria agregada por canal e origem de extra√ß√£o   | Volumetria agregada por canal e origem de acordo com filtro selecionado | `[ {"$sort":{"periodo_referencia":1}}, {"$project":{"_id":"$_id","app_nome":"$app_nome","app_source":"$app_source","periodo_referencia":"$periodo_referencia","nota_media":"$nota_media","nota_tendencia":"$nota_tendencia","avaliacoes_total":"$avaliacoes_total","comentarios_positivos":"$comentarios_positivos","comentarios_negativos":"$comentarios_negativos","segmento":"$segmento"}}, {"$limit":1048575}, {"$match":{"$and":[{"nota_media":{"$gte":1}},{"nota_media":{"$lte":5}}]}}, {"$sort":{"periodo_referencia":-1}}, {"$project":{"_id":"$_id","app_nome":"$app_nome","app_source":"$app_source","periodo_referencia":"$periodo_referencia","nota_media":"$nota_media","nota_tendencia":"$nota_tendencia","avaliacoes_total":"$avaliacoes_total","comentarios_positivos":"$comentarios_positivos","comentarios_negativos":"$comentarios_negativos","segmento":"$segmento"}}, {"$limit":1048575}, {"$group":{"_id":{"periodo_referencia":"$periodo_referencia","segmento":"$segmento","app_nome":"$app_nome","app_source":"$app_source"},"avg_nota_media":{"$avg":"$nota_media"},"avg_nota_tendencia":{"$avg":"$nota_tendencia"},"total_avaliacoes":{"$sum":"$avaliacoes_total"}}}, {"$sort":{"_id":1}}, {"$project":{"_id":false,"periodo_referencia":"$_id.periodo_referencia","segmento":"$_id.segmento","app_nome":"$_id.app_nome","app_source":"$_id.app_source","avg_nota_media":"$avg_nota_media","avg_nota_tendencia":"$avg_nota_tendencia","total_avaliacoes":"$total_avaliacoes"}}, {"$project":{"_id":false,"periodo_referencia":"$periodo_referencia","segmento":"$segmento","app_nome":"$app_nome","app_source":"$app_source","avg_nota_media":"$avg_nota_media","avg_nota_tendencia":"$avg_nota_tendencia","total_avaliacoes":"$total_avaliacoes"}}, {"$limit":1048575}, { "$sort": { "periodo_referencia": -1, "app_source": 1 } }, { "$project": { "_id": false, "periodo_referencia": "$periodo_referencia", "segmento": "$segmento", "app_nome": "$app_nome", "app_source": "$app_source", "avg_nota_media": "$avg_nota_media", "avg_nota_tendencia": "$avg_nota_tendencia", "total_avaliacoes": "$total_avaliacoes" } }, { "$limit": 1048575 } ]` | MongoDB
    | Vis√£o agregada (macro) por Fonte, Canal e Segmento   | Tabela Agregada   | Display: Tabela  |Agregada     | Dt D View Gold Agg Compass ~ | Agregada por ano m√™s, segmento e nota m√©dia.   | Vis√£o agregada por Fonte de Origem, Canais, Segmento (PF, PJ) e quebrado por nota m√©dia, avalia√ß√µes totais, coment√°rios positivos e coment√°rios negativos. | `[ { "$project": { "_id": "$_id", "app_nome": "$app_nome", "app_source": "$app_source", "periodo_referencia": "$periodo_referencia", "segmento": "$segmento", "nota_media": "$nota_media", "avaliacoes_total": "$avaliacoes_total", "comentarios_positivos": "$comentarios_positivos", "comentarios_negativos": "$comentarios_negativos" } }, { "$limit": 1048575 } ]` | MongoDB
    | Vis√£o detalhada  | Tabela Anal√≠tica   | Display: Tabela  |Anal√≠tica     | Compass - Visao detalhada, Ordenado por iso_date descendente, segmento ascendente, app ascendente, e app_source ascendente | Vis√£o granular das avalia√ß√µes dos clientes.   | Vis√£o detalhada na menor granulidade com as avalia√ß√µes dos clientes, disponibilizando o TITULO (descritivo da avalia√ß√£o ou nome do cliente), SNIPPET (corpo da avalia√ß√£o), APP_SOURCE (fonte de origem), APP, SEGMENTO, RATING (nota da avalia√ß√£o do cliente), ISO_DATE (timestamp da avalia√ß√£o) e PERIODO_REFERENCIA (ano m√™s da avalia√ß√£o) | `[ {"$match":{"$and":[{"rating":{"$gte":1}},{"rating":{"$lte":5}}]}}, {"$sort":{"iso_date":-1,"app_source":1,"app":1}}, {"$project":{"_id":"$_id","title":"$title","snippet":"$snippet","app_source":"$app_source","app":"$app","segmento":"$segmento","rating":"$rating","iso_date":"$iso_date"}}, {"$limit":1048575}, { "$sort": { "iso_date": -1, "segmento": 1, "app": 1, "app_source": 1 } }, { "$project": { "_id": false, "title": "$title", "snippet": "$snippet", "app_source": "$app_source", "app": "$app", "segmento": "$segmento", "rating": "$rating", "iso_date": "$iso_date", "periodo_referencia": { "$substrCP": [ "$iso_date", { "$subtract": [ 1, 1 ] }, 7 ] } } }, { "$limit": 1048575 } ]` | MongoDB
    
    


  </details>
  
- `Grafana`: Plataforma para monitoramento e visualiza√ß√£o de m√©tricas operacionais.
  <details>
    <summary>Informa√ß√µes Detalhada do Dashboard: GRAFANA </summary>

    O Grafana √© uma plataforma de monitoramento e observabilidade utilizada para visualizar m√©tricas, logs e traces em tempo real. Ele permite a cria√ß√£o de dashboards din√¢micos, integrando diferentes fontes de dados para um acompanhamento eficiente da infraestrutura e aplica√ß√µes.

  - **Objetivo do Grafa:** O Grafana foi projetado para fornecer uma interface intuitiva e centralizada para monitoramento de sistemas e an√°lise de m√©tricas. Ele √© ideal para equipes de SRE, DevOps e engenharia de dados, permitindo a detec√ß√£o r√°pida de problemas e otimiza√ß√£o do desempenho de aplica√ß√µes e servidores.

  - **Por que utilizar o Grafana?**

    -  Monitoramento - Ideal para an√°lise cont√≠nua de m√©tricas e logs.
    - Integra√ß√£o com diversas fontes de dados ‚Äì Compat√≠vel com Prometheus, InfluxDB, Elasticsearch, MySQL, PostgreSQL, entre outros.
    - Dashboards altamente personaliz√°veis ‚Äì Suporte a pain√©is interativos, gr√°ficos avan√ßados e filtros din√¢micos.
    - Alertas inteligentes ‚Äì Configura√ß√£o de notifica√ß√µes autom√°ticas via Slack, PagerDuty, e-mail, entre outros.
  
  - Dashboards (link de acesso): Os dashboards criados no Metabase fornecem uma vis√£o detalhada dos principais indicadores e m√©tricas da organiza√ß√£o.
    
    | **Categoria**                     | **M√©tricas**             | **Ambiente** | **Link de acesso**
    |-----------------------------------|--------------------------|--------------|----------------------
    | Observabilidade Aplica√ß√£o         | Aplica√ß√£o (dev)      | Pro-Produ√ß√£o | [Dashboard Compass - PRO - Data - Grafana](http://00.000.000.00:4000/d/eeex6c5w2x9fkb/compass-operacao-aplicacional?orgId=1&from=now-30d&to=now&timezone=browser))
    | Observabilidade Sustenta√ß√£o        | Sustenta√ß√£o         | Pro-Produ√ß√£o | [Dashboard Compass - PRO - Data - Grafana](http://00.000.000.00:4000/d/fef83ot67ctmoe/compass-sustentacao?orgId=1&from=now-30d&to=now&timezone=browser))

    

  - **Metolodogia e boas pr√°ticas:** O dashboard est√° estruturado em um padr√£o que dever√° ser mantido, garantindo a replica√ß√£o, organiza√ß√£o e adi√ß√£o de novas m√©tricas e componentes, pertmindo que os pain√©is respondam as perguntas sobre a sa√∫de dos sistemas que integram o projeto Compass.

    A vis√£o do Grafana foi dividida em 2 (duas) categorias, Dashboard de Aplica√ß√µes e Dashboard de Sustenta√ß√£o - **Dashboard de Aplica√ß√µes**

    O Dashboard de Aplica√ß√µes foram separados em alguns componentes para entender a volumetria de apps que rodaram e falharam nas √∫ltimas 24 horas e indicadores historicos de acordo com o filtro de timestamp selecionado, sendo composto por:
    
    - App Finish per layer
    - Valid Data Percentage
    - Applications Fail per layer
    - Invalid Data Percentage
    - Event Count of the Bronze Layer [historical]
    - Applications Completed per layer [historical]
    - Applications Fail per layer [historical]
    - Event Quality of the Bronze Layer [historical]
    - Event Quality of the Silver Layer [historical]
    - Event Quality of the Gold Layer [historical]
  
    | **Componente**      | **Categoria**            | Vis√£o                         | **Tipo de Painel**        | **Nome da m√©trica**                           | **Unidade**         | **Descri√ß√£o**                                                                                                                                                             | **Query Metrica**                                                                                | **Fonte**
    |---------------------|--------------------------|-------------------------------|---------------------------|-----------------------------------------------|---------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|----------------------------
    | Aplica√ß√µes Spark    | Totais de Sucessos       | Display: Estado               | Dashboard                 | App Finish per layer                          | Numero Total        | Exibe total de aplica√ß√µes que rodaram com sucesso nas √∫ltimas 24 horas, exibindo por camada Bronze, Silver e Gold                                                         | ``                                                                                               | ElasticSearch
    | Dados Validos       | Porcentagem Sucesso      | Display: Medidor              | Dashboard                 | Valid Data Percentage                         | Percentagem         | Exibe como est√° a qualidade de dados em porcentagem da ingest√£o e tratamento das cargas das √∫ltimas 24 horas de dados validos, exibindo por camada Bronze, Silver e Gold  | ``                                                                                               | ElasticSearch
    | Aplica√ß√µes Spark    | Totais de Falhas         | Display: Estado               | Dashboard                 | App Fail Finish per layer                     | Numero Total        | Exibe total de aplica√ß√µes que rodaram com falha nas √∫ltimas 24 horas, exibindo por camada Bronze, Silver e Gold                                                           | ``                                                                                               | ElasticSearch
    | Dados Invalidos     | Porcentagem Falha        | Display: Medidor              | Dashboard                 | Invalid Data Percentage                       | Percentagem         | Exibe como est√° a qualidade de dados em porcentagem da ingest√£o e tratamento das cargas das √∫ltimas 24 horas de dados invalidos, exibindo por camada Bronze, Silver e Gold| ``                                                                                               | ElasticSearch
    | Volumetria de dados | Totais de eventos        | Display: Medidor de Barras    | Dashboard                 | Count events: <camada: bronze,silver,gold>    | Numero Total        | Exibe a quantidade de dados processados por camada, desde a camada Bronze at√© a Gold                                                                                      | ``                                                                                               | ElasticSearch
    | Aplica√ß√µes Spark    | Totais de Sucessos       | Display: S√©ries Temporais     | Dashboard                 | App Finish per layer [historical]             | Numero Total        | Exibe total de aplica√ß√µes que rodaram com sucesso por timestamp (filtro) selecionado, exibindo por camada Bronze, Silver e Gold                                           | ``                                                                                               | ElasticSearch
    | Data Quality        | Totais de dados Invalidos| Display: S√©ries Temporais     | Dashboard                 | Event Quality of the Bronze Layer [historical]| Numero Total        | Exibe total de dados inv√°lidos encontrados para: Duplicados, Nulos e Consist√™ncia de Dados inv√°lidos para a camada Bronze                                                 | ``                                                                                               | ElasticSearch
    | Data Quality        | Totais de dados Invalidos| Display: S√©ries Temporais     | Dashboard                 | Event Quality of the Bronze Layer [historical]| Numero Total        | Exibe total de dados inv√°lidos encontrados para: Duplicados, Nulos e Consist√™ncia de Dados inv√°lidos para a camada Silver                                                 | ``                                                                                               | ElasticSearch
    | Data Quality        | Totais de dados Invalidos| Display: S√©ries Temporais     | Dashboard                 | Event Quality of the Bronze Layer [historical]| Numero Total        | Exibe total de dados inv√°lidos encontrados para: Duplicados, Nulos e Consist√™ncia de Dados inv√°lidos para a camada Gold                                                   | ``                                                                                               | ElasticSearch

    **Dashboard Sustenta√ß√£o**

    J√° o Dashboard de Sustenta√ß√£o foi estruturado para ter poucos componentes e sendo composto com apenas indicadores necess√°rios para entender se h√° problemas e qual problema, ajudando em uma an√°lise pr√©via:
    
    - Applications Fail per Priority [total]
    - Applications Fail per Prioruty [historical]
    - Application fail Table [historical]
      

    | **Componente**                     | **Categoria**            | Vis√£o                         | **Tipo de Painel**        | **Nome da m√©trica**                           | **Unidade**         | **Descri√ß√£o**                                                                                                                                                             | **Query Metrica**                                                                                | **Fonte**
    |------------------------------------|--------------------------|-------------------------------|---------------------------|-----------------------------------------------|---------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|----------------------------
    | Aplica√ß√µes Spark por prioridade    | Totais de Falhas         | Display: Medidor de Barras    | Dashboard                 | Applications fail per priority [total]        | Numero Total        | Exibe total de aplica√ß√µes que falharam de acordo com o tipo de prioridade, que pode ir de 0 a 2 que poder√° ser listado no dashboard, quanto menor a prioridade (exemplo: 0), mais crit√≠co √© o impacto para a malha                                                         | ``                                                                                               | ElasticSearch
    | Aplica√ß√µes Spark por camada        | Totais de Falhas         | Display: S√©ries Temporais     | Dashboard                 | Applications fail per priority [historical]   | Numero Total        | Exibe total de aplica√ß√µes que falharam de acordo com o tipo de prioridade, que pode ir de 0 a 2 que poder√° ser listado no dashboard, quanto menor a prioridade (exemplo: 0), mais crit√≠co √© o impacto para a malha e de acordo com a camada (bronze, silver ou gold)                                                      | ``                                                                                               | ElasticSearch
    | Tabela de Falhas das aplica√ß√µes Spark | Detalhes das falhas   | Display: Tabela               | Dashboard                 | N/A                                           | Registro            | Tabela com os registros das aplica√ß√µes que falharam, exibindo: Timestamp, Layer, JOB, Priority, Projeto. Tower e Error                                                      | ``                                                                                               | ElasticSearch

  </details>

### 3.2 Aspectos T√©cnicos do Projeto Compass
---
Nesta se√ß√£o, ser√° apresentada a arquitetura t√©cnica do Projeto Compass, detalhando seu funcionamento desde a infraestrutura at√© a camada aplicacional. O objetivo √© fornecer uma vis√£o abrangente do que est√° sendo executado, como os processos acontecem e as raz√µes por tr√°s das escolhas feitas, garantindo uma compreens√£o clara sobre a opera√ß√£o e a arquitetura do sistema.

#### 3.2.1 Tecnologias Utilizadas

Como base principal, as tecnologias utilizadas foram necess√°rias para atender o fluxo de dados, desde a coleta at√© a disponibiliza√ß√£o das informa√ß√µes.

- **MongoDB:** Utilizado para duas finalidades principais:
    - Armazenamento de cole√ß√µes contendo dados brutos provenientes dos Canais Santander.
    - Manuten√ß√£o de cole√ß√µes estruturadas nas camadas silver e gold, que servem como base para an√°lises no Metabase.
- **Hadoop HDFS:** Respons√°vel pelo armazenamento hist√≥rico dos dados, abrangendo desde a camada bronze (ingest√£o) at√© a gold, al√©m de suportar servi√ßos de data quality.
- **ElasticSearch:** Utilizado para armazenamento de m√©tricas t√©cnicas e dados relacionados ao desempenho das aplica√ß√µes.
- **Apache Spark:** Ferramenta principal para processamento distribu√≠do de dados em larga escala.
- **Apache Airflow:** Respons√°vel pela orquestra√ß√£o das execu√ß√µes dos cont√™ineres Spark, garantindo o fluxo automatizado das cargas de trabalho.
- **Metabase:** Ferramenta de Business Intelligence utilizada pelo time de neg√≥cios para an√°lise de dados e gera√ß√£o de insights.
- **Grafana:** Solu√ß√£o dedicada √† observabilidade t√©cnica, permitindo o monitoramento detalhado dos sistemas e m√©tricas operacionais.
- **SerpApi:** API opcional na arquitetura, utilizada para extra√ß√£o de dados de avalia√ß√µes da Google Play Store.
- **iTunes API:** API externa utilizada para coleta de informa√ß√µes da Apple Store.
- **GitHub Actions:** Empregado para automa√ß√£o de testes unit√°rios, build de imagens e publica√ß√£o no Docker Hub.
- **Docker Hub:** Reposit√≥rio utilizado para armazenamento e versionamento das imagens Docker das aplica√ß√µes Spark e da infraestrutura.

> [!NOTE]
> O projeto Compass foi concebido para ser executado inicialmente em um ambiente on-premises. Embora solu√ß√µes em nuvem, como Azure e AWS, ofere√ßam vantagens significativas, como escalabilidade e alta disponibilidade, sua ado√ß√£o exclusiva pode gerar depend√™ncia de fornecedores espec√≠ficos. Para mitigar esse risco, a escolha por tecnologias open-source proporciona maior flexibilidade, permitindo a execu√ß√£o local e facilitando a migra√ß√£o para a nuvem quando necess√°rio, sem comprometer a autonomia do sistema.


#### 3.2.2 Caracteristicas da Execu√ß√£o do Projeto

O projeto Compass √© executado em uma infraestrutura on-premises, onde os servi√ßos s√£o instanciados localmente em cont√™ineres baseados em imagens Docker. Para garantir a gest√£o eficiente da execu√ß√£o desses cont√™ineres, foi necess√°ria a ado√ß√£o de uma ferramenta de orquestra√ß√£o, sendo o Docker Swarm a solu√ß√£o escolhida para este ambiente.

O Docker Swarm foi escolhido como ferramenta de orquestra√ß√£o no projeto Compass devido √† sua simplicidade operacional, integra√ß√£o nativa com Docker e adequa√ß√£o ao ambiente on-premises. Diferente de solu√ß√µes mais complexas, como Kubernetes, o Swarm permite a cria√ß√£o e o gerenciamento de clusters de forma mais direta, reduzindo o tempo de configura√ß√£o e facilitando a administra√ß√£o dos servi√ßos conteinerizados.

A escolha tamb√©m considerou a necessidade de baixa sobrecarga computacional, j√° que o Swarm √© mais leve e n√£o exige um alto consumo de recursos, tornando-se uma alternativa vi√°vel para infraestrutura local. Al√©m disso, seu mecanismo de balanceamento de carga autom√°tico e alta disponibilidade garante a distribui√ß√£o eficiente das cargas de trabalho, melhorando a resili√™ncia dos servi√ßos sem a necessidade de configura√ß√µes avan√ßadas.


#### 3.2.2.1 **Infraestrutura do Projeto Compass**

Nessa sess√£o, ser√° descrito a infraestrutura para atender a demanda do projeto Compass, utilizada para gerenciar um ambiente Hadoop distribu√≠do. A configura√ß√£o permite a orquestra√ß√£o dos servi√ßos essenciais do Hadoop, incluindo Namenode, Datanode, History Server, Resource Manager e Node Manager.


Configura√ß√£o Hadoop

| **Servi√ßo**            | **Imagem**                                                   | **Portas**           | **Volumes**                               | **Vari√°veis de Ambiente**      | **Replicas** | **Healthcheck**                                           |
|------------------------|--------------------------------------------------------------|----------------------|-------------------------------------------|---------------------------------|--------------|-----------------------------------------------------------|
| **Namenode**            | `iamgacarvalho/hadoop-namenode-data-in-compass:2.0.0`        | `32763:9870`         | `/mnt/hadoop/namenode:/data/hdfs/name`    | `CLUSTER_NAME: hadoop_cluster`  | 1            | `nc -z localhost 9870`                                    |
| **Datanode**            | `iamgacarvalho/hadoop-datanode-data-in-compass:2.0.0`        | `9854-9864:9864`     | `/mnt/hadoop/datanode:/data/hdfs/data`    | `SERVICE_PRECONDITION: namenode:9870` | 1            | `nc -z localhost 9864`                                    |
| **History Server**      | `iamgacarvalho/hadoop-historyserver-data-in-compass:2.0.0`   | `8188:8188`          | -                                         | `SERVICE_PRECONDITION: namenode:9870` | 1            | `nc -z localhost 8188`                                    |
| **Resource Manager**    | `iamgacarvalho/hadoop-resourcemanager-data-in-compass:2.0.0` | `8088:8088`          | -                                         | `SERVICE_PRECONDITION: namenode:9870` | 1            | `nc -z localhost 8088`                                    |
| **Node Manager**        | `iamgacarvalho/hadoop-nodemanager-data-in-compass:2.0.0`     | `8032-8042:8042`     | -                                         | `SERVICE_PRECONDITION: namenode:9870` | 3            | `nc -z localhost 8042`                                    |

---

Configura√ß√£o Spark

| **Servi√ßo**            | **Imagem**                                                   | **Portas**           | **Volumes**                               | **Vari√°veis de Ambiente**      | **Replicas** | **Healthcheck**                                           |
|------------------------|--------------------------------------------------------------|----------------------|-------------------------------------------|---------------------------------|--------------|-----------------------------------------------------------|
| **Spark Master**        | `iamgacarvalho/spark-master-data-in-compass:3.0.0`           | `8084:8082`<br>`7077:7077` | `/mnt/spark/apps:/opt/spark-apps`<br>`/mnt/spark/data:/opt/spark-data` | -                             | 1            | `nc -z localhost 8082`                                    |
| **Spark Worker**        | `iamgacarvalho/spark-worker-data-in-compass:3.0.0`           | `8090-8100:8081`     | `/mnt/spark/apps:/opt/spark-apps`<br>`/mnt/spark/data:/opt/spark-data`<br>`/mnt/spark/worker-logs:/opt/spark/logs` | `WORKER_PORT=8081`            | 2            | `nc -z localhost 8081`                                    |

---

Configura√ß√£o Grafana

| **Servi√ßo**            | **Imagem**                                                   | **Portas**           | **Volumes**                               | **Vari√°veis de Ambiente**      | **Replicas** | **Healthcheck**                                           |
|------------------------|--------------------------------------------------------------|----------------------|-------------------------------------------|---------------------------------|--------------|-----------------------------------------------------------|
| **Grafana**            | `grafana/grafana:latest`                                     | `4000:3000`          | `/mnt/grafana_data:/var/lib/grafana`      | `GF_SECURITY_ADMIN_USER=admin`<br>`GF_SECURITY_ADMIN_PASSWORD=admin123`<br>`GF_INSTALL_PLUGINS=grafana-mongodb-datasource`<br>`GF_PLUGINS_PREINSTALL=grafana-clock-panel` | 2            | N√£o configurado, mas a disponibilidade pode ser verificada pela porta `3000` |

---

Configura√ß√£o Elasticsearch e Kibana

| **Servi√ßo**            | **Imagem**                                                   | **Portas**           | **Volumes**                               | **Vari√°veis de Ambiente**      | **Replicas** | **Healthcheck**                                           |
|------------------------|--------------------------------------------------------------|----------------------|-------------------------------------------|---------------------------------|--------------|-----------------------------------------------------------|
| **Elasticsearch**       | `docker.elastic.co/elasticsearch/elasticsearch:8.16.1`       | `9200:9200`<br>`9300:9300` | `/mnt/es_data:/usr/share/elasticsearch/data`<br>`/mnt/certs:/usr/share/elasticsearch/config/certs` | `ES_JAVA_OPTS=-Xms4g -Xmx4g`<br>`ELASTIC_PASSWORD=data-@a1`<br>`xpack.security.enabled=true`<br>`xpack.security.transport.ssl.key=/usr/share/elasticsearch/config/certs/es-node.key`<br>`xpack.security.transport.ssl.certificate=/usr/share/elasticsearch/config/certs/es-node.crt`<br>`xpack.security.transport.ssl.certificate_authorities=/usr/share/elasticsearch/config/certs/ca.crt` | 1            | N√£o configurado, mas pode ser monitorado na porta `9200` |
| **Kibana**             | `docker.elastic.co/kibana/kibana:8.16.1`                    | `5601:5601`          | -                                         | `ELASTICSEARCH_HOSTS=http://elasticsearch:9200`<br>`ELASTICSEARCH_USERNAME=kibana_user_service`<br>`ELASTICSEARCH_PASSWORD=data-@a1`<br>`XPACK_SECURITY_ENCRYPTIONKEY=eqyW5iPqa8ghok7RqY7eFluG+dqvXBczFEU+HhlDLFM=`<br>`XPACK_ENCRYPTEDSAVEDOBJECTS_ENCRYPTIONKEY=eqyW5iPqa8ghok7RqY7eFluG+dqvXBczFEU+HhlDLFM=`<br>`XPACK_REPORTING_ENCRYPTIONKEY=eqyW5iPqa8ghok7RqY7eFluG+dqvXBczFEU+HhlDLFM=` | 1            | `curl -f http://localhost:5601` (intervalo: 30s, 3 tentativas) |

---

Configura√ß√£o MongoDB

| **Servi√ßo**            | **Imagem**                                                   | **Portas**           | **Volumes**                               | **Vari√°veis de Ambiente**      | **Replicas** | **Healthcheck**                                           |
|------------------------|--------------------------------------------------------------|----------------------|-------------------------------------------|---------------------------------|--------------|-----------------------------------------------------------|
| **MongoDB**             | `mongo:7`                                                    | `27017:27017`        | `/mnt/mongodb:/data/db`<br>`/mnt/mongodb_configData:/data/configdb`<br>`/mnt/mongodb_init/init-mongo.js:/docker-entrypoint-initdb.d/init-mongo.js` | `MONGO_INITDB_ROOT_USERNAME=${MONGO_USER_ADMIN}`<br>`MONGO_INITDB_ROOT_PASSWORD=${MONGO_PASS_ADMIN}` | 1            | N√£o configurado, mas pode ser monitorado na porta `27017` |

---

Configura√ß√£o Metabase

| **Servi√ßo**            | **Imagem**                                                   | **Portas**           | **Volumes**                               | **Vari√°veis de Ambiente**      | **Replicas** | **Healthcheck**                                           |
|------------------------|--------------------------------------------------------------|----------------------|-------------------------------------------|---------------------------------|--------------|-----------------------------------------------------------|
| **Metabase**            | `metabase/metabase:latest`                                    | `8085:3000`          | `/mnt/metabase:/metabase.db`             | `MB_PASSWORD_RESET=true`      | 1            | N√£o configurado, mas pode ser monitorado na porta `3000` |

---

**Configura√ß√£o de Rede:** A infraestrutura utiliza uma rede **overlay externa** para comunica√ß√£o entre os cont√™ineres:

```yaml
networks:
  hadoop_network:
    external: true
    driver: overlay
```

**Persist√™ncia de Dados:** Volumes persistentes para o Namenode e Datanode:

```yaml
volumes:
  infra-namenode:
  infra-datanode:
  infra-spark-master:
  infra-spark-worker:
  infra-spark-worker-logs:
  grafana_data:
  elasticsearch_yml:
  certs:
  es_data:
  mongodb_data:
  mongodb_configdb_data:
  business-metabase:
```
> [!IMPORTANT]
> * Reposit√≥rio do c√≥digo fonte da infraestrutura: https://github.com/gacarvalho/infra-data-master-compass. <br>
> * YAML do Docker Swarm das tecnologias citadas acima: https://github.com/gacarvalho/compass-deployment/tree/compass/infra-3.0.0/services/batch_layer


#### 3.2.2.2 **Aplica√ß√µes do Projeto Compass**

As aplica√ß√µes respons√°veis por realizar as ingest√µes, transforma√ß√µes e carga das informa√ß√µes est√£o desenvolvidas na tecnologia Apache Spark voltadas para arquitetura Batch. O Apache Spark foi escolhido devido √† sua alta performance e escalabilidade, caracter√≠sticas essenciais para lidar com grandes volumes de dados no ambiente do Projeto Compass. 

A arquitetura Batch foi escolhida para garantir alta confiabilidade, escalabilidade e efici√™ncia no processamento de grandes volumes de dados, executando em um schedule di√°rio. Embora o processamento em tempo real (Streaming) seja uma alternativa vi√°vel para outros cen√°rios, o foco do projeto √© consolidar dados de forma estruturada, assegurando a consist√™ncia necess√°ria para que os times de neg√≥cios possam acompanhar e analisar as necessidades e desafios dos clientes de forma precisa e estrat√©gica.

‚ô®Ô∏è **Aplica√ß√µes - Ingest√µes de dados**

As aplica√ß√µes para ingest√µes de dados foram desenvolvidas para realizar captura de informa√ß√µes em 2 ambientes, um deles √© o ambiente interno do Banco Santander, j√° o outro ambiente √© externo, obtendo informa√ß√µes de duas APIs distintas. 

---

`üì¶ artefato` `iamgacarvalho/dmc-app-ingestion-reviews-mongodb-hdfs-compass`
<details>
  <summary>Informa√ß√µes detalhada do artefato iamgacarvalho/dmc-app-ingestion-reviews-mongodb-hdfs-compass </summary> 
  
  - **Vers√£o:** `1.0.1`
  - **Fase do Projeto:** `V1`
  - **Reposit√≥rio:** [GitHub](https://github.com/gacarvalho/mongodb/)  
  - **Imagem Docker:** [Docker Hub](https://hub.docker.com/repository/docker/iamgacarvalho/dmc-app-ingestion-reviews-mongodb-hdfs-compass/tags/1.0.1/sha256-4b406055b4cabd7b2b2e5395eb6f7f1062f104f8080a2bef5d25f2c350bdf43f)  
  - **Descri√ß√£o:**  Coleta avalia√ß√µes de clientes do Banco Santander armazenadas no **MongoDB**, processa os dados e os armazena no **HDFS** em formato **Parquet**.
  - **Par√¢metros:** 

    ```shell
      /app/repo_extc_mongodb.py $CONFIG_ENV $PARAM1 $PARAM2 $PARAM3
    ```

      - `$CONFIG_ENV` (`Pre`, `Pro`) ‚Üí Define o ambiente: `Pre` (Pr√©-Produ√ß√£o), `Pro` (Produ√ß√£o).
      - `$PARAM1` (`nome-do-canal-ou-app`). ‚Üí Nome do canal/app no MongoDB. Para novos, use h√≠fen (-).
      - `$PARAM2` (`pf`,`pj`). ‚Üí Indicador do segmento do cliente. `PF` (Pessoa F√≠sica), `PJ` (Pessoa Juridica)
</details>

---

`üì¶ artefato` `iamgacarvalho/dmc-app-ingestion-reviews-apple-store-hdfs-compass` 
<details>
  <summary>Informa√ß√µes detalhada do artefato iamgacarvalho/dmc-app-ingestion-reviews-apple-store-hdfs-compass </summary> 
  
  - **Vers√£o:** `1.0.1`
  - **Fase do Projeto:** `V1`
  - **Reposit√≥rio:** [GitHub](https://github.com/gacarvalho/apple-store)  
  - **Imagem Docker:** [Docker Hub](https://hub.docker.com/repository/docker/iamgacarvalho/dmc-app-ingestion-reviews-apple-store-hdfs-compass/tags/1.0.1/sha256-8a038d0998e0cb11267936b87cb277f10dc210a928571feb14ccba20c8cd807b)  
  - **Descri√ß√£o:**  Coleta avalia√ß√µes de clientes nos canais via API do Itunes na **Apple Store**, realizando a ingest√£o e os armazenando no **HDFS** em formato **Parquet**.
  - **Par√¢metros:** 

    ```shell
      /app/repo_extc_apple_store.py $CONFIG_ENV $PARAM1 $PARAM2 $PARAM3
    ```

      - `$CONFIG_ENV` (`Pre`, `Pro`) ‚Üí Define o ambiente: `Pre` (Pr√©-Produ√ß√£o), `Pro` (Produ√ß√£o).
      - `$PARAM1` (`id-review-localizado-na-url-do-app`). ‚Üí Identificado (n√∫mero) do aplicativo na Apple Store, podendo ser localizado na URL da loja Apple Store, exemplo: `https://apps.apple.com/br/app/santander-way/id1154266372`, nesse caso, o ID que vai no parametro √©: `1154266372`.
      - `$PARAM2` (`nome-do-canal-ou-app`). ‚Üí Nome do canal/app na Apple Store. Para novos, use h√≠fen (-).
      - `$PARAM3` (`pf`,`pj`). ‚Üí Indicador do segmento do cliente. `PF` (Pessoa F√≠sica), `PJ` (Pessoa Juridica)

</details>

---

`üì¶ artefato` `iamgacarvalho/dmc-app-ingestion-reviews-google-play-hdfs-compass` 
<details>
  <summary>Informa√ß√µes detalhada do artefato iamgacarvalho/dmc-app-ingestion-reviews-google-play-hdfs-compass </summary> 
  
  - **Vers√£o:** `1.0.1`
  - **Fase do Projeto:** `V1`
  - **Reposit√≥rio:** [GitHub](https://github.com/gacarvalho/google-play)  
  - **Imagem Docker:** [Docker Hub](https://hub.docker.com/repository/docker/iamgacarvalho/dmc-app-ingestion-reviews-google-play-hdfs-compass/tags/1.0.1/sha256-df992cb185f7a17ed0d40306e91d50139553e17e5c2a4d900579a0d42b804d9e)  
  - **Descri√ß√£o:**  Coleta avalia√ß√µes de clientes do Banco Santander armazenadas no  **Google Play**, processa os dados e os armazena no **HDFS** em formato **Parquet**.
  - **Par√¢metros:** 

    ```shell
      /app/repo_extc_google_play.py $CONFIG_ENV $PARAM1 $PARAM2 $PARAM3
    ```

      - `$CONFIG_ENV` (`Pre`, `Pro`) ‚Üí Define o ambiente: `Pre` (Pr√©-Produ√ß√£o), `Pro` (Produ√ß√£o).
      - `$PARAM1` (`name-review-localizado-na-url-do-app`). ‚Üí Identificado (string) do aplicativo do Google Play, podendo ser localizado na URL na loja do Google Play, exemplo: `https://play.google.com/store/apps/details?id=br.com.santander.way&hl=pt_BR&pli=1`, nesse caso, o ID que vai no parametro √©: `br.com.santander.way`.
      - `$PARAM2` (`nome-do-canal-ou-app`). ‚Üí Nome do canal/app no Google Play. Para novos, use h√≠fen (-).
      - `$PARAM3` (`pf`,`pj`). ‚Üí Indicador do segmento do cliente. `PF` (Pessoa F√≠sica), `PJ` (Pessoa Juridica)

</details>

---

‚ô®Ô∏è **Aplica√ß√µes - Transforma√ß√µes de dados**

As aplica√ß√µes respons√°veis pela transforma√ß√£o dos dados realizar√£o a leitura conforme a fonte de extra√ß√£o. No caso do motor que alimenta a silver da Apple Store, ele processar√° apenas as ingest√µes relacionadas a essa plataforma. Por exemplo, suponha que haja 15 aplicativos sendo ingeridos e armazenados na bronze, 5 aplicativos da Apple Store, 5 provenientes do MongoDB (base interna) e 5 do Google Play. Nesse cen√°rio, a silver da Apple Store consumir√° exclusivamente os dados ingeridos da Apple Store, garantindo que apenas informa√ß√µes relevantes dessa fonte sejam processadas. 

`üì¶ artefato` `iamgacarvalho/dmc-app-silver-reviews-apple-store` 
<details>
  <summary>Informa√ß√µes detalhada do artefato iamgacarvalho/dmc-app-silver-reviews-apple-store </summary> 

  - **Vers√£o:** `1.0.1`
  - **Fase do Projeto:** `V1`
  - **Reposit√≥rio:** [GitHub](https://github.com/gacarvalho/apple-store-processing-historical)  
  - **Imagem Docker:** [Docker Hub](https://hub.docker.com/repository/docker/iamgacarvalho/dmc-app-silver-reviews-apple-store/tags/1.0.1/sha256-a35d88d3c69b78abcecfff0a53906201fab48bdd8b2e5579057e935f58b6fe41)  
  - **Descri√ß√£o:**  Coleta avalia√ß√µes de clientes nos canais via API do Itunes na **Apple Store** ingeridos no Data Lake, realizando a ingest√£o a partir da camada Bronze, processando e aplicando tratamento de dados e armazenando no **HDFS** em formato **Parquet**.

  - **Par√¢metros:** 
    ```shell
      /app/repo_trfmation_apple_store.py $CONFIG_ENV 
    ```
      - `$CONFIG_ENV` (`Pre`, `Pro`) ‚Üí Define o ambiente: `Pre` (Pr√©-Produ√ß√£o), `Pro` (Produ√ß√£o).
  - **Pipeline:**
    - **Descri√ß√£o:** Processar avalia√ß√µes de clientes da Apple Store (camada Bronze ‚Üí Silver), garantindo: filtro espec√≠fico para dados Apple Store, normaliza√ß√£o e enriquecimento de metadados, valida√ß√£o de qualidade conforme regras de neg√≥cio e rastreabilidade completa dos dados
    - **Fonte de Dados:** <br> `/santander/bronze/compass/reviews/appleStore/*_pf` 
                          <br> `/santander/bronze/compass/reviews/appleStore/*_pj`
                          <br> `/santander/silver/compass/reviews/appleStore/`
    - **Filtro:** Apenas dados com appleStore no path e terminados em _pf ou _pj.                   
    - **Destino:** `/santander/silver/compass/reviews/appleStore/` 
    - **Tipo de processo:** Batch (di√°rio)

  - **Fluxo de Dados:**
    - **Extra√ß√£o:** Leitura de dados PF/PJ particionados por `odate` em Parquet
    - **Transforma√ß√£o e Fun√ß√µes:** PySpark <br> 
      1.  `remove_accents(s)`: Remove acentos de uma string, utilizando a biblioteca unidecode. Esta fun√ß√£o √© registrada como uma UDF (User Defined Function) no Spark para ser aplicada em colunas de DataFrames. **Par√¢metros:** `s` (str): A string da qual os acentos ser√£o removidos. **Retorno:** (str): A string sem acentos.

        ```python
        remove_accents(s: str) -> str
        ```

        No exemplo abaixo √© poss√≠vel ver como a funcionalidade se aplica em um caso real:

        ```python
        Exemplo: remove_accents("S√£o Paulo") # Retorna: "Sao Paulo"
        ```

      2.  `processing_reviews(df: DataFrame)`: Realiza transforma√ß√µes no DataFrame de reviews, selecionando colunas espec√≠ficas, converte nomes para mai√∫sculas e removendo acentos. Renomeia colunas para um formato consistente. **Par√¢metros:** `df` (DataFrame): O DataFrame de reviews a ser processado. **Retorno:** (DataFrame): O DataFrame transformado.

          ```python
          processed_df = processing_reviews(df)
          processed_df.show()
          ```

      3.  `get_schema(df, schema)`: Assegura que o DataFrame esteja em conformidade com um esquema predefinido, convertendo os tipos das colunas para os tipos especificados no esquema. **Par√¢metros:** `df` (DataFrame): O DataFrame a ser ajustado. `schema` (StructType): O esquema de destino. **Retorno:** (DataFrame): O DataFrame em conformidade com o esquema.

          ```python
          aligned_df = get_schema(df, schema)
          aligned_df.printSchema()
          ```

      4.  `processing_old_new(spark: SparkSession, df: DataFrame)`: Compara os dados de reviews novos com os dados hist√≥ricos, identificando e registrando mudan√ßas nas avalia√ß√µes ao longo do tempo. Cria uma coluna chamada `historical_data` para armazenar o hist√≥rico de mudan√ßas. **Par√¢metros:** `spark` (SparkSession): A sess√£o Spark ativa. `df` (DataFrame): O DataFrame com os novos dados de reviews. **Retorno:** (DataFrame): O DataFrame com o hist√≥rico de mudan√ßas.

          ```python
          historical_df = processing_old_new(spark, df)
          historical_df.show()
          ```

      5.  `read_source_parquet(spark, path)`: L√™ um arquivo Parquet do caminho especificado, extraindo informa√ß√µes de "app" e "segmento" do nome do arquivo. Retorna `None` se o arquivo n√£o existir ou se n√£o houver dados. **Par√¢metros:** `spark` (SparkSession): A sess√£o Spark ativa. `path` (str): O caminho para o arquivo Parquet. **Retorno:** (DataFrame | None): O DataFrame lido ou `None` em caso de falha.

          ```python
          source_df = read_source_parquet(spark, file_path)
          if source_df:
              source_df.show()
          ```

      6.  `save_dataframe(df, path, label)`: Salva um DataFrame no formato Parquet no caminho especificado. Verifica se o DataFrame possui dados antes de salvar, e caso n√£o possua, envia um log de warning. Verifica e cria o diret√≥rio de destino se necess√°rio. Lida com poss√≠veis erros durante o processo de salvamento. **Par√¢metros:** `df` (DataFrame): O DataFrame a ser salvo. `path` (str): O caminho para salvar o DataFrame. `label` (str): Uma etiqueta para os logs. **Retorno:** None.

          ```python
          save_dataframe(df, save_path, data_label)
          ```

      7.  `path_exists() -> bool`: Verifica se um determinado caminho existe no HDFS. Verifica se o caminho possui parti√ß√µes no formato "odate=\*". **Retorno:** (bool): True caso o caminho exista, e false caso n√£o exista.

          ```python
          if path_exists():
              print("O caminho existe")
          else:
              print("O caminho n√£o existe")
          ```

      8.  `save_metrics(metrics_json, df)`: Salva m√©tricas no Elasticsearch. Conecta-se ao Elasticsearch usando vari√°veis de ambiente. Lida com erros de decodifica√ß√£o JSON e erros de conex√£o. **Par√¢metros:** `metrics_json` (str): As m√©tricas no formato JSON. `df` (DataFrame): O DataFrame associado √†s m√©tricas. **Retorno:** None.

          ```python
          save_metrics(metrics, data_df)
          ```

      9.  `save_metrics_job_fail(metrics_json)`: Salva m√©tricas de falhas de jobs no Elasticsearch. Similar a `save_metrics`, mas para um √≠ndice diferente. **Par√¢metros:** `metrics_json` (str): As m√©tricas de falha no formato JSON. **Retorno:** None.

          ```python
          save_metrics_job_fail(failure_metrics)
          ```

      10. `log_error(e, df)`: Gera e salva m√©tricas de erro no Elasticsearch. Extrai informa√ß√µes de segmento do DataFrame. Formata informa√ß√µes de erro e as envia para `save_metrics_job_fail`. **Par√¢metros:** `e` (Exception): A exce√ß√£o que ocorreu. `df` (DataFrame): O DataFrame associado ao erro. **Retorno:** None.

          ```python
          try:
              # C√≥digo que pode gerar um erro
          except Exception as error:
              log_error(error, df)
          ```

    - **Valida√ß√£o:** 
    
        1.  `validate_ingest(spark: SparkSession, df: DataFrame) -> tuple`: Valida dados de ingest√£o, comparando com hist√≥rico e verificando qualidade. **Retorna** DataFrames de dados v√°lidos e inv√°lidos, e resultados da valida√ß√£o. 
    
            - **Duplicatas:** Identifica registros duplicados por "id".
            - **Nulos:** Verifica nulos em colunas cr√≠ticas.
            - **Tipos:** Garante consist√™ncia de tipos.

            C√≥digo de retorno na valida√ß√£o:

            > `200`: Sucesso (Nenhum problema encontrado) <br>
            > `400`: Erro nos dados (Valores nulos ou tipos inv√°lidos) <br>
            > `409`: Conflito de dados (Registros duplicados encontrados)



    - **Carga:** Escrita em HDFS (Parquet):
    
      1. Caminho principal (dados v√°lidos) `/santander/silver/compass/reviews/appleStore/odate={datePath}/` 
      2. Caminho de falha `/santander/silver/compass/reviews_fail/appleStore/odate={datePath}/`

    - **M√©tricas:** A fun√ß√£o `collect_metrics` coleta um conjunto abrangente de m√©tricas para fornecer uma vis√£o detalhada do processo de ingest√£o e valida√ß√£o de dados. As m√©tricas s√£o estruturadas em um objeto JSON, facilitando o consumo por sistemas de monitoramento e an√°lise.


      * **Informa√ß√µes da Aplica√ß√£o:**
          * `application_id`: Identificador √∫nico da aplica√ß√£o Spark.
          * `owner`: Detalhes do propriet√°rio da aplica√ß√£o (sigla, projeto, camada do Lake).
          * `source`: Detalhes sobre a fonte dos dados (`app`, `search`).
      * **Contagem de Registros:**
          * `valid_data`: Contagem e porcentagem de registros v√°lidos.
          * `invalid_data`: Contagem e porcentagem de registros inv√°lidos.
          * `total_records`: Contagem total de registros processados.
      * **Desempenho do Processamento:**
          * `total_processing_time`: Tempo total de processamento em minutos.
          * `memory_used`: Uso de mem√≥ria em megabytes.
          * `stages`: M√©tricas detalhadas dos est√°gios de execu√ß√£o do Spark.
      * **Resultados da Valida√ß√£o:**
          * `validation_results`: Resultados detalhados de cada valida√ß√£o (duplicatas, nulos, tipos).
          * `success_count`: N√∫mero de valida√ß√µes bem-sucedidas.
          * `error_count`: N√∫mero de valida√ß√µes com erros.
          * `type_client`: Lista de segmentos √∫nicos dos clientes.
      * **Timestamps:**
          * `_ts`: Timestamps de in√≠cio e t√©rmino do processamento.
          * `timestamp`: Timestamp da gera√ß√£o das m√©tricas.

      **Formato do JSON:**

      As m√©tricas s√£o estruturadas em um objeto JSON com a seguinte estrutura geral:

      ```json
      {
        "application_id": "...",
        "owner": {
          "sigla": "...",
          "projeto": "...",
          "layer_lake": "..."
        },
        "valid_data": {
          "count": ...,
          "percentage": ...
        },
        "invalid_data": {
          "count": ...,
          "percentage": ...
        },
        "total_records": ...,
        "total_processing_time": "...",
        "memory_used": ...,
        "stages": { ... },
        "validation_results": { ... },
        "success_count": ...,
        "error_count": ...,
        "type_client": "...",
        "source": {
          "app": "...",
          "search": "..."
        },
        "_ts": {
          "compass_start_ts": "...",
          "compass_end_ts": "..."
        },
        "timestamp": "..."
      }
      ```

  Este JSON pode ser utilizado para monitorar o desempenho do pipeline de dados, identificar problemas de qualidade de dados e otimizar o processo de ingest√£o. J√° para as falhas o JSON √© estruturado e enviado para o indice no Elastic Search de aplica√ß√µes com falhas.

  * **Informa√ß√µes do erro:**
    * `timestamp`: Timestamp da gera√ß√£o das m√©tricas.
    * `layer`: Camada referencia onde ocorreu o erro.
    * `project`: Projeto respons√°vel pela aplica√ß√£o com erro.
    * `job`: Job da malha que est√° em execu√ß√£o e que falhou.
    * `priority`: Prioridade do erro, quanto menor, mais impacto na malha e na vis√£o cliente, considera que de 0 a 2 √© o imapacto cr√≠tico, superior a isso, h√° impacto mas o fluxo segue normal. Exemplo: `Falha de 0-2` -> Erro ao capturar dados da API ou erro ao gravar no path destino.  `Falha de 3-4` -> Erro ao enviar as m√©tricas.
    * `tower`: Torre da sigla respons√°vel pelo alerta.
    * `client`: Segmento impactado, considerando PF (pessoa f√≠sica) e/ou PJ (pessoa juridica).
    * `error`: log do erro da aplica√ß√£o.
            

      ```json
        {
            "timestamp": "...",
            "layer": "silver",
            "project": "compass",
            "job": "google_play_reviews",
            "priority": "0",
            "tower": "SBBR_COMPASS",
            "client": "[...]",
            "error": "..."
        }
      ```

</details>

---

`üì¶ artefato` `iamgacarvalho/dmc-app-silver-reviews-google-play` 
<details>
  <summary>Informa√ß√µes detalhada do artefato iamgacarvalho/dmc-app-silver-reviews-google-play </summary> 
  
  - **Vers√£o:** `1.0.1`
  - **Fase do Projeto:** `V1`
  - **Reposit√≥rio:** [GitHub](https://github.com/gacarvalho/google-play-processing-historical)  
  - **Imagem Docker:** [Docker Hub](https://hub.docker.com/repository/docker/iamgacarvalho/dmc-app-silver-reviews-google-play/tags/1.0.1/sha256-3b68861761c0059f6ecb60253086b0f9bef78fa079ea8e5b1a5f44b9da82b252)  
  - **Descri√ß√£o:**  Coleta avalia√ß√µes de clientes nos canais via API SERAPI que se origina do **Google Play** que foi ingerido no Data Lake, realizando a ingest√£o a partir da camada Bronze, processando e aplicando tratamento de dados e armazenando no HDFS em formato Parquet.

  - **Par√¢metros:** 
    ```shell
      /app/repo_trfmation_google_play.py.py $CONFIG_ENV 
    ```
      - `$CONFIG_ENV` (`Pre`, `Pro`) ‚Üí Define o ambiente: `Pre` (Pr√©-Produ√ß√£o), `Pro` (Produ√ß√£o).
  - **Pipeline:**
    - **Descri√ß√£o:** Processar avalia√ß√µes de clientes dao Google Play (camada Bronze ‚Üí Silver), garantindo: filtro espec√≠fico para dados Google Play, normaliza√ß√£o e enriquecimento de metadados, valida√ß√£o de qualidade conforme regras de neg√≥cio e rastreabilidade completa dos dados
    - **Fonte de Dados:** <br> `/santander/bronze/compass/reviews/googlePlay/*_pf` 
                          <br> `/santander/bronze/compass/reviews/googlePlay/*_pj`
                          <br> `/santander/silver/compass/reviews/googlePlay/`
    - **Filtro:** Apenas dados com google Play no path e terminados em _pf ou _pj.                   
    - **Destino:** `/santander/silver/compass/reviews/googlePlay/` 
    - **Tipo de processo:** Batch (di√°rio)

  - **Fluxo de Dados:**
    - **Extra√ß√£o:** Leitura de dados PF/PJ particionados por `odate` em Parquet
    - **Transforma√ß√£o e Fun√ß√µes:** PySpark <br> 
      1.  `remove_accents(s)`: Remove acentos de uma string, utilizando a biblioteca unidecode. Esta fun√ß√£o √© registrada como uma UDF (User Defined Function) no Spark para ser aplicada em colunas de DataFrames. **Par√¢metros:** `s` (str): A string da qual os acentos ser√£o removidos. **Retorno:** (str): A string sem acentos.

        ```python
        remove_accents(s: str) -> str
        ```

        No exemplo abaixo √© poss√≠vel ver como a funcionalidade se aplica em um caso real:

        ```python
        Exemplo: remove_accents("S√£o Paulo") # Retorna: "Sao Paulo"
        ```

      2.  `processing_reviews(df: DataFrame)`: Realiza transforma√ß√µes no DataFrame de reviews, selecionando colunas espec√≠ficas, converte nomes para mai√∫sculas e removendo acentos. Renomeia colunas para um formato consistente. **Par√¢metros:** `df` (DataFrame): O DataFrame de reviews a ser processado. **Retorno:** (DataFrame): O DataFrame transformado.

          ```python
          processed_df = processing_reviews(df)
          processed_df.show()
          ```

      3.  `get_schema(df, schema)`: Assegura que o DataFrame esteja em conformidade com um esquema predefinido, convertendo os tipos das colunas para os tipos especificados no esquema. **Par√¢metros:** `df` (DataFrame): O DataFrame a ser ajustado. `schema` (StructType): O esquema de destino. **Retorno:** (DataFrame): O DataFrame em conformidade com o esquema.

          ```python
          aligned_df = get_schema(df, schema)
          aligned_df.printSchema()
          ```

      4.  `processing_old_new(spark: SparkSession, df: DataFrame)`: Compara os dados de reviews novos com os dados hist√≥ricos, identificando e registrando mudan√ßas nas avalia√ß√µes ao longo do tempo. Cria uma coluna chamada `historical_data` para armazenar o hist√≥rico de mudan√ßas. **Par√¢metros:** `spark` (SparkSession): A sess√£o Spark ativa. `df` (DataFrame): O DataFrame com os novos dados de reviews. **Retorno:** (DataFrame): O DataFrame com o hist√≥rico de mudan√ßas.

          ```python
          historical_df = processing_old_new(spark, df)
          historical_df.show()
          ```

      5.  `read_source_parquet(spark, path)`: L√™ um arquivo Parquet do caminho especificado, extraindo informa√ß√µes de "app" e "segmento" do nome do arquivo. Retorna `None` se o arquivo n√£o existir ou se n√£o houver dados. **Par√¢metros:** `spark` (SparkSession): A sess√£o Spark ativa. `path` (str): O caminho para o arquivo Parquet. **Retorno:** (DataFrame | None): O DataFrame lido ou `None` em caso de falha.

          ```python
          source_df = read_source_parquet(spark, file_path)
          if source_df:
              source_df.show()
          ```

      6.  `save_dataframe(df, path, label)`: Salva um DataFrame no formato Parquet no caminho especificado. Verifica se o DataFrame possui dados antes de salvar, e caso n√£o possua, envia um log de warning. Verifica e cria o diret√≥rio de destino se necess√°rio. Lida com poss√≠veis erros durante o processo de salvamento. Um tratamento adicional que a fun√ß√£o realiza √© verificar se o dataframe tem a coluna `historical_data`, se n√£o tiver, a fun√ß√£o cria a coluna com o schema correto com dado nulo.
      ```python
        if "historical_data" not in df.columns:
            df = df.withColumn(
                "historical_data",
                lit(None).cast("array<struct<title:string,snippet:string,app:string,rating:string,iso_date:string>>")
            )
      ```
      
      **Par√¢metros:** `df` (DataFrame): O DataFrame a ser salvo. `path` (str): O caminho para salvar o DataFrame. `label` (str): Uma etiqueta para os logs. **Retorno:** None.

          ```python
          save_dataframe(df, save_path, data_label)
          ```

      7.  `path_exists() -> bool`: Verifica se um determinado caminho existe no HDFS. Verifica se o caminho possui parti√ß√µes no formato "odate=\*". **Retorno:** (bool): True caso o caminho exista, e false caso n√£o exista.

          ```python
          if path_exists():
              print("O caminho existe")
          else:
              print("O caminho n√£o existe")
          ```

      8.  `save_metrics(metrics_json, df)`: Salva m√©tricas no Elasticsearch. Conecta-se ao Elasticsearch usando vari√°veis de ambiente. Lida com erros de decodifica√ß√£o JSON e erros de conex√£o. **Par√¢metros:** `metrics_json` (str): As m√©tricas no formato JSON. `df` (DataFrame): O DataFrame associado √†s m√©tricas. **Retorno:** None.

          ```python
          save_metrics(metrics, data_df)
          ```

      9.  `save_metrics_job_fail(metrics_json)`: Salva m√©tricas de falhas de jobs no Elasticsearch. Similar a `save_metrics`, mas para um √≠ndice diferente. **Par√¢metros:** `metrics_json` (str): As m√©tricas de falha no formato JSON. **Retorno:** None.

          ```python
          save_metrics_job_fail(failure_metrics)
          ```

      10. `log_error(e, df)`: Gera e salva m√©tricas de erro no Elasticsearch. Extrai informa√ß√µes de segmento do DataFrame. Formata informa√ß√µes de erro e as envia para `save_metrics_job_fail`. **Par√¢metros:** `e` (Exception): A exce√ß√£o que ocorreu. `df` (DataFrame): O DataFrame associado ao erro. **Retorno:** None.

          ```python
          try:
              # C√≥digo que pode gerar um erro
          except Exception as error:
              log_error(error, df)
          ```

    - **Valida√ß√£o:** 
    
        1.  `validate_ingest(spark: SparkSession, df: DataFrame) -> tuple`: Valida dados de ingest√£o, comparando com hist√≥rico e verificando qualidade. **Retorna** DataFrames de dados v√°lidos e inv√°lidos, e resultados da valida√ß√£o. 
    
            - **Duplicatas:** Identifica registros duplicados por "id".
            - **Nulos:** Verifica nulos em colunas cr√≠ticas.
            - **Tipos:** Garante consist√™ncia de tipos.

            C√≥digo de retorno na valida√ß√£o:

            > `200`: Sucesso (Nenhum problema encontrado) <br>
            > `400`: Erro nos dados (Valores nulos ou tipos inv√°lidos) <br>
            > `409`: Conflito de dados (Registros duplicados encontrados)



    - **Carga:** Escrita em HDFS (Parquet):
    
      1. Caminho principal (dados v√°lidos) `/santander/silver/compass/reviews/appleStore/odate={datePath}/` 
      2. Caminho de falha `/santander/silver/compass/reviews_fail/appleStore/odate={datePath}/`

    - **M√©tricas:** A fun√ß√£o `collect_metrics` coleta um conjunto abrangente de m√©tricas para fornecer uma vis√£o detalhada do processo de ingest√£o e valida√ß√£o de dados. As m√©tricas s√£o estruturadas em um objeto JSON, facilitando o consumo por sistemas de monitoramento e an√°lise.


      * **Informa√ß√µes da Aplica√ß√£o:**
          * `application_id`: Identificador √∫nico da aplica√ß√£o Spark.
          * `owner`: Detalhes do propriet√°rio da aplica√ß√£o (sigla, projeto, camada do Lake).
          * `source`: Detalhes sobre a fonte dos dados (`app`, `search`).
      * **Contagem de Registros:**
          * `valid_data`: Contagem e porcentagem de registros v√°lidos.
          * `invalid_data`: Contagem e porcentagem de registros inv√°lidos.
          * `total_records`: Contagem total de registros processados.
      * **Desempenho do Processamento:**
          * `total_processing_time`: Tempo total de processamento em minutos.
          * `memory_used`: Uso de mem√≥ria em megabytes.
          * `stages`: M√©tricas detalhadas dos est√°gios de execu√ß√£o do Spark.
      * **Resultados da Valida√ß√£o:**
          * `validation_results`: Resultados detalhados de cada valida√ß√£o (duplicatas, nulos, tipos).
          * `success_count`: N√∫mero de valida√ß√µes bem-sucedidas.
          * `error_count`: N√∫mero de valida√ß√µes com erros.
          * `type_client`: Lista de segmentos √∫nicos dos clientes.
      * **Timestamps:**
          * `_ts`: Timestamps de in√≠cio e t√©rmino do processamento.
          * `timestamp`: Timestamp da gera√ß√£o das m√©tricas.

      **Formato do JSON:**

      As m√©tricas s√£o estruturadas em um objeto JSON com a seguinte estrutura geral:

      ```json
      {
        "application_id": "...",
        "owner": {
          "sigla": "...",
          "projeto": "...",
          "layer_lake": "..."
        },
        "valid_data": {
          "count": ...,
          "percentage": ...
        },
        "invalid_data": {
          "count": ...,
          "percentage": ...
        },
        "total_records": ...,
        "total_processing_time": "...",
        "memory_used": ...,
        "stages": { ... },
        "validation_results": { ... },
        "success_count": ...,
        "error_count": ...,
        "type_client": "...",
        "source": {
          "app": "...",
          "search": "..."
        },
        "_ts": {
          "compass_start_ts": "...",
          "compass_end_ts": "..."
        },
        "timestamp": "..."
      }
      ```

    Este JSON pode ser utilizado para monitorar o desempenho do pipeline de dados, identificar problemas de qualidade de dados e otimizar o processo de ingest√£o. J√° para as falhas o JSON √© estruturado e enviado para o indice no Elastic Search de aplica√ß√µes com falhas.

      * **Informa√ß√µes do erro:**
        * `timestamp`: Timestamp da gera√ß√£o das m√©tricas.
        * `layer`: Camada referencia onde ocorreu o erro.
        * `project`: Projeto respons√°vel pela aplica√ß√£o com erro.
        * `job`: Job da malha que est√° em execu√ß√£o e que falhou.
        * `priority`: Prioridade do erro, quanto menor, mais impacto na malha e na vis√£o cliente, considera que de 0 a 2 √© o imapacto cr√≠tico, superior a isso, h√° impacto mas o fluxo segue normal. Exemplo: `Falha de 0-2` -> Erro ao capturar dados da API ou erro ao gravar no path destino.  `Falha de 3-4` -> Erro ao enviar as m√©tricas.
        * `tower`: Torre da sigla respons√°vel pelo alerta.
        * `client`: Segmento impactado, considerando PF (pessoa f√≠sica) e/ou PJ (pessoa juridica).
        * `error`: log do erro da aplica√ß√£o.
            

      ```json
        {
            "timestamp": "...",
            "layer": "silver",
            "project": "compass",
            "job": "google_play_reviews",
            "priority": "0",
            "tower": "SBBR_COMPASS",
            "client": "[...]",
            "error": "..."
        }
      ```

</details>

---

`üì¶ artefato` `iamgacarvalho/dmc-app-silver-reviews-mongodb` 
<details>
  <summary>Informa√ß√µes detalhada do artefato iamgacarvalho/dmc-app-silver-reviews-mongodb </summary> 

  - **Vers√£o:** `1.0.1`
  - **Fase do Projeto:** `V1`
  - **Reposit√≥rio:** [GitHub](https://github.com/gacarvalho/mongodb-processing-historical)  
  - **Imagem Docker:** [Docker Hub](https://hub.docker.com/repository/docker/iamgacarvalho/dmc-app-silver-reviews-mongodb/tags/1.0.1/sha256-6138a44faa031c50a8f8b7b4e75db092a8d03a62a0124b9e4414f999788e0d69)  
  - **Descri√ß√£o:**  Coleta avalia√ß√µes de clientes nos canais via base de dados **MongoDB** ingeridos no Data Lake, realizando a ingest√£o a partir da camada Bronze, processando e aplicando tratamento de dados e armazenando no HDFS em formato Parquet.

    ```shell
      /app/repo_trfmation_mongodb.py $CONFIG_ENV 
    ```
      - `$CONFIG_ENV` (`Pre`, `Pro`) ‚Üí Define o ambiente: `Pre` (Pr√©-Produ√ß√£o), `Pro` (Produ√ß√£o).
  - **Pipeline:**
    - **Descri√ß√£o:** Processar avalia√ß√µes de clientes dos canais Santander que ser√° armazenados na base interna Santander (camada Bronze ‚Üí Silver), garantindo: filtro espec√≠fico para dados da base interna Santander (MongoDB), normaliza√ß√£o e enriquecimento de metadados, valida√ß√£o de qualidade conforme regras de neg√≥cio e rastreabilidade completa dos dados
    - **Fonte de Dados:** <br> `/santander/bronze/compass/reviews/mongodb/*_pf` 
                          <br> `/santander/bronze/compass/reviews/mongodb/*_pj`
                          <br> `/santander/silver/compass/reviews/mongodb/`
    - **Filtro:** Apenas dados com mongodb no path e terminados em _pf ou _pj.                   
    - **Destino:** `/santander/silver/compass/reviews/mongodb/` 
    - **Tipo de processo:** Batch (di√°rio)

  - **Fluxo de Dados:**
    - **Extra√ß√£o:** Leitura de dados PF/PJ particionados por `odate` em Parquet
    - **Transforma√ß√£o e Fun√ß√µes:** PySpark <br> 
      1.  `remove_accents(s)`: Remove acentos de uma string, utilizando a biblioteca unidecode. Esta fun√ß√£o √© registrada como uma UDF (User Defined Function) no Spark para ser aplicada em colunas de DataFrames. **Par√¢metros:** `s` (str): A string da qual os acentos ser√£o removidos. **Retorno:** (str): A string sem acentos.

        ```python
        remove_accents(s: str) -> str
        ```

        No exemplo abaixo √© poss√≠vel ver como a funcionalidade se aplica em um caso real:

        ```python
        Exemplo: remove_accents("S√£o Paulo") # Retorna: "Sao Paulo"
        ```

      2.  `processing_reviews(df: DataFrame)`: Realiza transforma√ß√µes no DataFrame de reviews, selecionando colunas espec√≠ficas, converte nomes para mai√∫sculas e removendo acentos. Renomeia colunas para um formato consistente. **Par√¢metros:** `df` (DataFrame): O DataFrame de reviews a ser processado. **Retorno:** (DataFrame): O DataFrame transformado.

          ```python
          processed_df = processing_reviews(df)
          processed_df.show()
          ```

      3.  `get_schema(df, schema)`: Assegura que o DataFrame esteja em conformidade com um esquema predefinido, convertendo os tipos das colunas para os tipos especificados no esquema. **Par√¢metros:** `df` (DataFrame): O DataFrame a ser ajustado. `schema` (StructType): O esquema de destino. **Retorno:** (DataFrame): O DataFrame em conformidade com o esquema.

          ```python
          aligned_df = get_schema(df, schema)
          aligned_df.printSchema()
          ```

      4.  `processing_old_new(spark: SparkSession, df: DataFrame)`: Compara os dados de reviews novos com os dados hist√≥ricos, identificando e registrando mudan√ßas nas avalia√ß√µes ao longo do tempo. Cria uma coluna chamada `historical_data` para armazenar o hist√≥rico de mudan√ßas. **Par√¢metros:** `spark` (SparkSession): A sess√£o Spark ativa. `df` (DataFrame): O DataFrame com os novos dados de reviews. **Retorno:** (DataFrame): O DataFrame com o hist√≥rico de mudan√ßas.

          ```python
          historical_df = processing_old_new(spark, df)
          historical_df.show()
          ```

      5.  `read_source_parquet(spark, path)`: L√™ um arquivo Parquet do caminho especificado, extraindo informa√ß√µes de "app" e "segmento" do nome do arquivo. Retorna `None` se o arquivo n√£o existir ou se n√£o houver dados. **Par√¢metros:** `spark` (SparkSession): A sess√£o Spark ativa. `path` (str): O caminho para o arquivo Parquet. **Retorno:** (DataFrame | None): O DataFrame lido ou `None` em caso de falha.

          ```python
          source_df = read_source_parquet(spark, file_path)
          if source_df:
              source_df.show()
          ```

      6.  `save_dataframe(df, path, label)`: Salva um DataFrame no formato Parquet no caminho especificado. Verifica se o DataFrame possui dados antes de salvar, e caso n√£o possua, envia um log de warning. Verifica e cria o diret√≥rio de destino se necess√°rio. Lida com poss√≠veis erros durante o processo de salvamento. **Par√¢metros:** `df` (DataFrame): O DataFrame a ser salvo. `path` (str): O caminho para salvar o DataFrame. `label` (str): Uma etiqueta para os logs. **Retorno:** None.

          ```python
          save_dataframe(df, save_path, data_label)
          ```

      7.  `path_exists() -> bool`: Verifica se um determinado caminho existe no HDFS. Verifica se o caminho possui parti√ß√µes no formato "odate=\*". **Retorno:** (bool): True caso o caminho exista, e false caso n√£o exista.

          ```python
          if path_exists():
              print("O caminho existe")
          else:
              print("O caminho n√£o existe")
          ```

      8.  `save_metrics(metrics_json, df)`: Salva m√©tricas no Elasticsearch. Conecta-se ao Elasticsearch usando vari√°veis de ambiente. Lida com erros de decodifica√ß√£o JSON e erros de conex√£o. **Par√¢metros:** `metrics_json` (str): As m√©tricas no formato JSON. `df` (DataFrame): O DataFrame associado √†s m√©tricas. **Retorno:** None.

          ```python
          save_metrics(metrics, data_df)
          ```

      9.  `save_metrics_job_fail(metrics_json)`: Salva m√©tricas de falhas de jobs no Elasticsearch. Similar a `save_metrics`, mas para um √≠ndice diferente. **Par√¢metros:** `metrics_json` (str): As m√©tricas de falha no formato JSON. **Retorno:** None.

          ```python
          save_metrics_job_fail(failure_metrics)
          ```

      10. `log_error(e, df)`: Gera e salva m√©tricas de erro no Elasticsearch. Extrai informa√ß√µes de segmento do DataFrame. Formata informa√ß√µes de erro e as envia para `save_metrics_job_fail`. **Par√¢metros:** `e` (Exception): A exce√ß√£o que ocorreu. `df` (DataFrame): O DataFrame associado ao erro. **Retorno:** None.

          ```python
          try:
              # C√≥digo que pode gerar um erro
          except Exception as error:
              log_error(error, df)
          ```

    - **Valida√ß√£o:** 
    
        1.  `validate_ingest(spark: SparkSession, df: DataFrame) -> tuple`: Valida dados de ingest√£o, comparando com hist√≥rico e verificando qualidade. **Retorna** DataFrames de dados v√°lidos e inv√°lidos, e resultados da valida√ß√£o. 
    
            - **Duplicatas:** Identifica registros duplicados por "id".
            - **Nulos:** Verifica nulos em colunas cr√≠ticas.
            - **Tipos:** Garante consist√™ncia de tipos.

            C√≥digo de retorno na valida√ß√£o:

            > `200`: Sucesso (Nenhum problema encontrado) <br>
            > `400`: Erro nos dados (Valores nulos ou tipos inv√°lidos) <br>
            > `409`: Conflito de dados (Registros duplicados encontrados)



    - **Carga:** Escrita em HDFS (Parquet):
    
      1. Caminho principal (dados v√°lidos) `/santander/silver/compass/reviews/mongodb/odate={datePath}/` 
      2. Caminho de falha `/santander/silver/compass/reviews_fail/mongodb/odate={datePath}/`

    - **M√©tricas:** A fun√ß√£o `collect_metrics` coleta um conjunto abrangente de m√©tricas para fornecer uma vis√£o detalhada do processo de ingest√£o e valida√ß√£o de dados. As m√©tricas s√£o estruturadas em um objeto JSON, facilitando o consumo por sistemas de monitoramento e an√°lise.


      * **Informa√ß√µes da Aplica√ß√£o:**
          * `application_id`: Identificador √∫nico da aplica√ß√£o Spark.
          * `owner`: Detalhes do propriet√°rio da aplica√ß√£o (sigla, projeto, camada do Lake).
          * `source`: Detalhes sobre a fonte dos dados (`app`, `search`).
      * **Contagem de Registros:**
          * `valid_data`: Contagem e porcentagem de registros v√°lidos.
          * `invalid_data`: Contagem e porcentagem de registros inv√°lidos.
          * `total_records`: Contagem total de registros processados.
      * **Desempenho do Processamento:**
          * `total_processing_time`: Tempo total de processamento em minutos.
          * `memory_used`: Uso de mem√≥ria em megabytes.
          * `stages`: M√©tricas detalhadas dos est√°gios de execu√ß√£o do Spark.
      * **Resultados da Valida√ß√£o:**
          * `validation_results`: Resultados detalhados de cada valida√ß√£o (duplicatas, nulos, tipos).
          * `success_count`: N√∫mero de valida√ß√µes bem-sucedidas.
          * `error_count`: N√∫mero de valida√ß√µes com erros.
          * `type_client`: Lista de segmentos √∫nicos dos clientes.
      * **Timestamps:**
          * `_ts`: Timestamps de in√≠cio e t√©rmino do processamento.
          * `timestamp`: Timestamp da gera√ß√£o das m√©tricas.

      **Formato do JSON:**

      As m√©tricas s√£o estruturadas em um objeto JSON com a seguinte estrutura geral:

      ```json
      {
        "application_id": "...",
        "owner": {
          "sigla": "...",
          "projeto": "...",
          "layer_lake": "..."
        },
        "valid_data": {
          "count": ...,
          "percentage": ...
        },
        "invalid_data": {
          "count": ...,
          "percentage": ...
        },
        "total_records": ...,
        "total_processing_time": "...",
        "memory_used": ...,
        "stages": { ... },
        "validation_results": { ... },
        "success_count": ...,
        "error_count": ...,
        "type_client": "...",
        "source": {
          "app": "...",
          "search": "..."
        },
        "_ts": {
          "compass_start_ts": "...",
          "compass_end_ts": "..."
        },
        "timestamp": "..."
      }
      ```

    Este JSON pode ser utilizado para monitorar o desempenho do pipeline de dados, identificar problemas de qualidade de dados e otimizar o processo de ingest√£o. J√° para as falhas o JSON √© estruturado e enviado para o indice no Elastic Search de aplica√ß√µes com falhas.

      * **Informa√ß√µes do erro:**
        * `timestamp`: Timestamp da gera√ß√£o das m√©tricas.
        * `layer`: Camada referencia onde ocorreu o erro.
        * `project`: Projeto respons√°vel pela aplica√ß√£o com erro.
        * `job`: Job da malha que est√° em execu√ß√£o e que falhou.
        * `priority`: Prioridade do erro, quanto menor, mais impacto na malha e na vis√£o cliente, considera que de 0 a 2 √© o imapacto cr√≠tico, superior a isso, h√° impacto mas o fluxo segue normal. Exemplo: `Falha de 0-2` -> Erro ao capturar dados da API ou erro ao gravar no path destino.  `Falha de 3-4` -> Erro ao enviar as m√©tricas.
        * `tower`: Torre da sigla respons√°vel pelo alerta.
        * `client`: Segmento impactado, considerando PF (pessoa f√≠sica) e/ou PJ (pessoa juridica).
        * `error`: log do erro da aplica√ß√£o.
            


      ```json
        {
            "timestamp": "...",
            "layer": "silver",
            "project": "compass",
            "job": "mongodb_reviews",
            "priority": "0",
            "tower": "SBBR_COMPASS",
            "client": "[...]",
            "error": "..."
        }
      ```

</details>

---

‚ô®Ô∏è **Aplica√ß√µes - Dados Agregados**


A aplica√ß√£o respons√°vel por realizar os dados agregados √© a encarregada de alimentar a camada Gold do Data Lake. Seu principal objetivo √© consumir os dados tratados da camada Silver, provenientes de diferentes origens de ingest√£o, como a Base Interna Santander (MongoDB), Google Play e Apple Store.

A agrega√ß√£o tem como prop√≥sito oferecer ao time de neg√≥cio uma vis√£o consolidada e estrat√©gica que permita responder a perguntas-chave, tais como:

  - Qual a m√©dia de experi√™ncia do cliente nos √∫ltimos 3 a 9 meses?
  - Tivemos evolu√ß√µes na experi√™ncia do cliente ap√≥s a disponibiliza√ß√£o de uma nova feature para o segmento X?
  - Qual fonte de origem (Google Play, Apple Store, Base Interna) possui maior volume de reclama√ß√µes?
  - O volume de avalia√ß√µes aumentou ap√≥s uma a√ß√£o de marketing ou lan√ßamento de um novo canal?
  - Como est√° o desempenho dos canais digitais (ex: Santander Way, Santander Select) em termos de avalia√ß√£o?
  - Qual segmento de cliente (PF ou PJ) est√° mais engajado nas avalia√ß√µes?
  - Houve melhora na nota m√©dia ap√≥s a√ß√µes corretivas ou atualiza√ß√µes espec√≠ficas nos aplicativos?
  - Em quais meses tivemos picos negativos de avalia√ß√£o e o que pode ter causado isso?
  - Qual canal apresenta maior volume de intera√ß√µes negativas e pode demandar aten√ß√£o priorit√°ria?
  - A experi√™ncia do cliente est√° acima ou abaixo da meta institucional (ex: meta 5.0)?
  - Qual foi o impacto de determinada campanha ou evento no volume e na nota das avalia√ß√µes?
  - Estamos evoluindo de forma consistente ou estagnada na percep√ß√£o do cliente ao longo dos anos?
  - A distribui√ß√£o de avalia√ß√µes por canal est√° equilibrada ou concentrada em poucos aplicativos?
  - Existe correla√ß√£o entre a origem da avalia√ß√£o (ex: Google Play) e a nota atribu√≠da?
  - Quais s√£o os per√≠odos com baixa volumetria de avalia√ß√µes que podem indicar falta de engajamento?
  - Os clientes que avaliam via App Store tendem a dar notas mais baixas do que os do Google Play?
  - Qual a tend√™ncia de crescimento do volume de avalia√ß√µes nos √∫ltimos trimestres?
  - Os dados internos (MongoDB) refletem a mesma percep√ß√£o dos clientes que usam as plataformas externas?
  - Existe sazonalidade nas avalia√ß√µes que pode influenciar a an√°lise (ex: final de ano, datas comerciais)?


`üì¶ artefato` `iamgacarvalho/dmc-reviews-aggregate-apps-santander` 
<details>
  <summary>Informa√ß√µes detalhada do artefato iamgacarvalho/dmc-reviews-aggregate-apps-santander </summary> 

  - **Vers√£o:** `1.0.1`
  - **Fase do Projeto:** `V1`
  - **Reposit√≥rio:** [GitHub](https://github.com/gacarvalho/reviews-aggregate-apps-santander)  
  - **Imagem Docker:** [Docker Hub](https://hub.docker.com/repository/docker/iamgacarvalho/dmc-reviews-aggregate-apps-santander/tags/1.0.1/sha256-58173fc5e2bc379e19dc5496c1da79f1ccaac0535a5ab5ae27430f64050f98ac)  
  - **Descri√ß√£o:**  Coleta avalia√ß√µes de clientes de diversos  canais ingeridos no Data Lake, realizando a ingest√£o a partir da camada Silver, processando, agregando as informa√ß√µes e armazenando no **HDFS** em formato **Parquet**.

  - **Par√¢metros:** 
    ```shell
      /app/repo_agg_all_apps_gold.py $CONFIG_ENV 
    ```
      - `$CONFIG_ENV` (`Pre`, `Pro`) ‚Üí Define o ambiente: `Pre` (Pr√©-Produ√ß√£o), `Pro` (Produ√ß√£o).
  - **Pipeline:**
    - **Descri√ß√£o:** Processar avalia√ß√µes de clientes de diversos canais (camada Silver ‚Üí Gold), garantindo: agrega√ß√£o dos dados conforme regras de neg√≥cio.

    - **Fonte de Dados:** <br> `/santander/silver/compass/reviews/googlePlay` 
                          <br> `/santander/silver/compass/reviews/mongodb`
                          <br> `/santander/silver/compass/reviews/appleStore`
    - **Destino:** `/santander/gold/compass/reviews/apps_santander_aggregate/` 
    - **Tipo de processo:** Batch (di√°rio)

  - **Fluxo de Dados:**
    - **Extra√ß√£o:** Leitura de dados particionados por `odate` em Parquet
    - **Transforma√ß√£o e Fun√ß√µes:** PySpark <br> 

      1.  `processing_reviews(df)`: 
      
      Realiza a leitura e transforma√ß√£o do DataFrame de reviews, executando as seguintes etapas:

        * Sele√ß√£o de colunas espec√≠ficas relevantes para o processamento.
        * Convers√£o dos nomes das colunas para mai√∫sculas, garantindo uniformidade.
        * Adi√ß√£o de novas colunas utilizando express√µes regulares (regex) para extrair informa√ß√µes relevantes dos dados.
        * Uni√£o de DataFrames provenientes de diferentes origens em um √∫nico DataFrame consolidado.

      **Par√¢metros:**

      * `df` (DataFrame): O DataFrame de reviews a ser processado.

      **Retorno:**

      * (DataFrame): O DataFrame transformado, pronto para as pr√≥ximas etapas de processamento.

          ```python
          processed_df = processing_reviews(df)
          processed_df.show()
          ```


      2. `get_schema(df, schema)`: Assegura que o DataFrame esteja em conformidade com um esquema predefinido, convertendo os tipos das colunas para os tipos especificados no esquema. **Par√¢metros:** `df` (DataFrame): O DataFrame a ser ajustado. `schema` (StructType): O esquema de destino. **Retorno:** (DataFrame): O DataFrame em conformidade com o esquema.

          ```python
          aligned_df = get_schema(df, schema)
          aligned_df.printSchema()
          ```

      3. `save_reviews(reviews_df, directory)`: Salva os dados do DataFrame no formato Parquet no diret√≥rio que foi passado via `directory` **Par√¢metros:** `reviews_df` (DataFrame): O DataFrame a ser ajustado. `directory` diret√≥rio a ser gravado.

          ```python
          save_reviews(df, path)
          ```

      4. `write_to_mongo(dados_feedback, table_id, overwrite=False)`:Escreve dados em uma cole√ß√£o MongoDB, com a op√ß√£o de sobrescrever a cole√ß√£o. **Par√¢metros:** `dados_feedback` (dict): Dados a ser gravados na collections do MongoDB,  `table_id` collections destino a ser gravada e `overwrite` Se True, sobrescreve a cole√ß√£o, excluindo todos os documentos antes de inserir novos dados. 

          ```python
          # Converte o DataFrame do PySpark em uma lista de dicion√°rios (JSON)
          data = [json.loads(row) for row in df.toJSON().collect()]
          collection_name = "dt_d_view_gold_agg_compass"
          write_to_mongo(data, collection_name, overwrite=True)
          ```
      
    - **Valida√ß√£o:** 
    
        1.  `validate_ingest(spark: SparkSession, df: DataFrame) -> tuple`: Valida dados de ingest√£o, comparando com hist√≥rico e verificando qualidade. **Retorna** DataFrames de dados v√°lidos e inv√°lidos, e resultados da valida√ß√£o. 
    
            - **Duplicatas:** Identifica registros duplicados por "id".
            - **Nulos:** Verifica nulos em colunas cr√≠ticas.
            - **Tipos:** Garante consist√™ncia de tipos.

            C√≥digo de retorno na valida√ß√£o:

            > `200`: Sucesso (Nenhum problema encontrado) <br>
            > `400`: Erro nos dados (Valores nulos ou tipos inv√°lidos) <br>
            > `409`: Conflito de dados (Registros duplicados encontrados)



    - **Carga:** Escrita em HDFS (Parquet):
    
      1. Caminho principal (dados v√°lidos) `/santander/gold/compass/reviews/apps_santander_aggregate/odate={datePath}/` 
      2. Caminho de falha `/santander/gold/compass/reviews_fail/apps_santander_aggregate/odate={datePath}/`

    - **M√©tricas:** A fun√ß√£o `collect_metrics` coleta um conjunto abrangente de m√©tricas para fornecer uma vis√£o detalhada do processo de ingest√£o e valida√ß√£o de dados. As m√©tricas s√£o estruturadas em um objeto JSON, facilitando o consumo por sistemas de monitoramento e an√°lise.


      * **Informa√ß√µes da Aplica√ß√£o:**
          * `application_id`: Identificador √∫nico da aplica√ß√£o Spark.
          * `owner`: Detalhes do propriet√°rio da aplica√ß√£o (sigla, projeto, camada do Lake).
          * `source`: Detalhes sobre a fonte dos dados (`app`, `search`).
      * **Contagem de Registros:**
          * `valid_data`: Contagem e porcentagem de registros v√°lidos.
          * `invalid_data`: Contagem e porcentagem de registros inv√°lidos.
          * `total_records`: Contagem total de registros processados.
      * **Desempenho do Processamento:**
          * `total_processing_time`: Tempo total de processamento em minutos.
          * `memory_used`: Uso de mem√≥ria em megabytes.
          * `stages`: M√©tricas detalhadas dos est√°gios de execu√ß√£o do Spark.
      * **Resultados da Valida√ß√£o:**
          * `validation_results`: Resultados detalhados de cada valida√ß√£o (duplicatas, nulos, tipos).
          * `success_count`: N√∫mero de valida√ß√µes bem-sucedidas.
          * `error_count`: N√∫mero de valida√ß√µes com erros.
          * `type_client`: Lista de segmentos √∫nicos dos clientes.
      * **Timestamps:**
          * `_ts`: Timestamps de in√≠cio e t√©rmino do processamento.
          * `timestamp`: Timestamp da gera√ß√£o das m√©tricas.

      **Formato do JSON:**

      As m√©tricas s√£o estruturadas em um objeto JSON com a seguinte estrutura geral:

      ```json
      {
        "application_id": "...",
        "owner": {
          "sigla": "...",
          "projeto": "...",
          "layer_lake": "..."
        },
        "valid_data": {
          "count": ...,
          "percentage": ...
        },
        "invalid_data": {
          "count": ...,
          "percentage": ...
        },
        "total_records": ...,
        "total_processing_time": "...",
        "memory_used": ...,
        "stages": { ... },
        "validation_results": { ... },
        "success_count": ...,
        "error_count": ...,
        "type_client": "...",
        "source": {
          "app": "...",
          "search": "..."
        },
        "_ts": {
          "compass_start_ts": "...",
          "compass_end_ts": "..."
        },
        "timestamp": "..."
      }
      ```

  Este JSON pode ser utilizado para monitorar o desempenho do pipeline de dados, identificar problemas de qualidade de dados e otimizar o processo de ingest√£o. J√° para as falhas o JSON √© estruturado e enviado para o indice no Elastic Search de aplica√ß√µes com falhas.

  * **Informa√ß√µes do erro:**
    * `timestamp`: Timestamp da gera√ß√£o das m√©tricas.
    * `layer`: Camada referencia onde ocorreu o erro.
    * `project`: Projeto respons√°vel pela aplica√ß√£o com erro.
    * `job`: Job da malha que est√° em execu√ß√£o e que falhou.
    * `priority`: Prioridade do erro, quanto menor, mais impacto na malha e na vis√£o cliente, considera que de 0 a 2 √© o imapacto cr√≠tico, superior a isso, h√° impacto mas o fluxo segue normal. Exemplo: `Falha de 0-2` -> Erro ao capturar dados da API ou erro ao gravar no path destino.  `Falha de 3-4` -> Erro ao enviar as m√©tricas.
    * `tower`: Torre da sigla respons√°vel pelo alerta.
    * `client`: Segmento impactado, considerando PF (pessoa f√≠sica) e/ou PJ (pessoa juridica).
    * `error`: log do erro da aplica√ß√£o.
            

      ```json
        {
            "timestamp": "...",
            "layer": "gold",
            "project": "compass",
            "job": "aggregate_apps_reviews",
            "priority": "0",
            "tower": "SBBR_COMPASS",
            "client": "[PF, PJ, NA]",
            "error": "..."
        }
      ```

</details>


---

‚ô®Ô∏è **Aplica√ß√µes - Valida√ß√µes de Qualidade**


A aplica√ß√£o respons√°vel por realizar as qualidade de dados operam como um agente de qualidade do pipeline para reviews de aplicativos, provenientes de diferentes fontes (Google Play, MongoDB e Apple Store). Ele realiza as seguintes tarefas principais:

  - Volumetria
  - Schema
  - Pattern


No exemplo abaixo, √© poss√≠vel observar que a valida√ß√£o de volumetria foi realizada com sucesso, por√©m, caiu em rejeitados no schema, exibindo o schema atual e o schema que deveria ser estruturado, al√©m de apontar o caminho no HDFS que o dado foi rejeitado por odate.

![<data-master-compass>](https://github.com/gacarvalho/compass-deployment/blob/compass/infra-3.0.0/img/validador_data_quality.png?raw=true)

`üì¶ artefato` `iamgacarvalho/dmc-quality-pipeline-compass` 
<details>
  <summary>Informa√ß√µes detalhada do artefato iamgacarvalho/dmc-quality-pipeline-compass </summary> 

  - **Vers√£o:** `1.0.1`
  - **Fase do Projeto:** `V1`
  - **Reposit√≥rio:** [GitHub](https://github.com/gacarvalho/quality-pipeline-compass)  
  - **Imagem Docker:** [Docker Hub](hhttps://hub.docker.com/repository/docker/iamgacarvalho/dmc-quality-pipeline-compass/tags/1.0.1/sha256-a089704d2d12d1816d85246347e9604d082d605229d95116aaff145f1be990ba)  

    ```shell
      /app/app-code-compass-quality-pipeline.py $CONFIG_ENV $PARAM1
    ```
      - `$CONFIG_ENV` (`Pre`, `Pro`) ‚Üí Define o ambiente: `Pre` (Pr√©-Produ√ß√£o), `Pro` (Produ√ß√£o).
      - `$PARAM1` (`bronze`, `SILVER`) ‚Üí Define a camada do data laker a ser validado: `bronze` (Camada do Data Lake com dados brutos), `silver` (Camada do Data Lake com dados j√° tratados).
  - **Pipeline:**
    - **Descri√ß√£o:** Este pipeline de dados realiza a valida√ß√£o e processamento de reviews de aplicativos, coletadas de diversas fontes (Google Play, MongoDB e Apple Store), com o objetivo de garantir a qualidade e consist√™ncia dos dados. O processo inicia com a leitura dos dados brutos (camada Bronze) ou pr√©-processados (camada Silver) armazenados no HDFS em formato Parquet. Em seguida, os dados s√£o validados em rela√ß√£o a esquemas predefinidos e padr√µes espec√≠ficos para cada fonte, identificando e segregando registros inv√°lidos. Os dados validados s√£o ent√£o transformados e enriquecidos, preparando-os para an√°lise posterior. As m√©tricas de processamento e os registros inv√°lidos s√£o persistidos no HDFS, respectivamente, para monitoramento e rastreabilidade.
    - **Fonte de Dados:** 
    Definindo caminhos para cada camada. Vari√°vel wildcard:

      - Para `"bronze"`, wildcard recebe o valor `*/`.
      - Para `"silver"`, wildcard recebe uma string vazia `("")`.

      - **Caminhos em paths:** Substitu√≠ `*/` por `{wildcard}` nos caminhos das fontes. Isso permite que o comportamento do caminho mude dinamicamente conforme o valor de type_processing. Exemplo de Caminhos Gerados:

          - Se `type_processing` for `bronze` e date_ref for "2024-12-08", os caminhos ser√£o:
        
            `/santander/bronze/compass/reviews/googlePlay/*/odate=2024-12-08`
            
          - Se type_processing for `silver` e date_ref for "2024-12-08", os caminhos ser√£o:            

            `/santander/silver/compass/reviews/googlePlay/odate=2024-12-08`

    ```python
      paths = {
            "google_play": f"{base_path}/{type_processing}/compass/reviews/googlePlay/{wildcard}odate={date_ref}",
            "mongodb": f"{base_path}/{type_processing}/compass/reviews/mongodb/{wildcard}odate={date_ref}",
            "apple_store": f"{base_path}/{type_processing}/compass/reviews/appleStore/{wildcard}odate={date_ref}",
        }
    ```
    - **Destino:** <br>
    
      `/santander/quality/compass/reviews/schema/odate={datePath}` <br>
      `/santander/quality/compass/reviews/pattern/google_play/odate={datePath}` <br>
      `/santander/quality/compass/reviews/pattern/apple_store/odate={datePath}` <br>
      `/santander/quality/compass/reviews/pattern/internal_databases/odate={datePath}` <br>

    - **Tipo de processo:** Batch (di√°rio)

  - **Fluxo de Dados:**
    - **Extra√ß√£o:** Leitura de dados PF/PJ particionados por `odate` em Parquet
    - **Valida√ß√£o leitura da origem e carga:** PySpark

      1.  `read_parquet_data(spark, path)`: L√™ dados de um arquivo Parquet e trata erros de leitura.
          ```python
          read_parquet_data(spark: SparkSession, path: str) -> DataFrame
          ```
          **Par√¢metros:**
          * `spark` (SparkSession): A sess√£o Spark utilizada para ler o arquivo.
          * `path` (str): O caminho do arquivo Parquet a ser lido.
          **Retorno:**
          * (DataFrame): Um DataFrame contendo os dados lidos do arquivo Parquet.
          **Exce√ß√µes:**
          * Levanta uma exce√ß√£o `Exception` se ocorrer um erro durante a leitura do arquivo Parquet.
          ```python
          Exemplo: df = read_parquet_data(spark, "/caminho/para/arquivo.parquet")
          ```

      2.  `validate_dataframes(dataframes, layer)`: Valida se todos os DataFrames em um dicion√°rio possuem dados e realiza a uni√£o deles.
          ```python
          validate_dataframes(dataframes: dict, layer: str) -> tuple[DataFrame, DataFrame, DataFrame]
          ```
          **Par√¢metros:**
          * `dataframes` (dict): Um dicion√°rio onde as chaves s√£o os nomes das fontes de dados e os valores s√£o os DataFrames correspondentes.
          * `layer` (str): A camada de processamento ("bronze" ou "silver").
          **Retorno:**
          * (tuple[DataFrame, DataFrame, DataFrame]): Uma tupla contendo os DataFrames unidos para google_play, mongodb e apple_store.
          **Exce√ß√µes:**
          * Levanta uma exce√ß√£o `ValueError` se alguma das fontes de dados estiver vazia.
          ```python
          Exemplo: google_df, mongo_df, apple_df = validate_dataframes(dataframes, "bronze")
          ```

      3.  `validate_source_load(spark, date_ref, type_processing)`: Valida o processo de carga de dados de diferentes fontes (Google Play, MongoDB, Apple Store).
          ```python
          validate_source_load(spark: SparkSession, date_ref: str, type_processing: str) -> tuple[DataFrame, DataFrame, DataFrame]
          ```
          **Par√¢metros:**
          * `spark` (SparkSession): A sess√£o Spark utilizada para processar os dados.
          * `date_ref` (str): A data de refer√™ncia para os dados.
          * `type_processing` (str): O tipo de processamento ("bronze" ou "silver").
          **Retorno:**
          * (tuple[DataFrame, DataFrame, DataFrame]): Uma tupla contendo os DataFrames unidos para google_play, mongodb e apple_store.
          **Exce√ß√µes:**
          * Levanta uma exce√ß√£o `ValueError` se o `type_processing` for inv√°lido ou se ocorrer um erro de valida√ß√£o.
          * Levanta uma exce√ß√£o `Exception` se ocorrer um erro inesperado durante o processamento dos dados.
          ```python
          Exemplo: google_df, mongo_df, apple_df = validate_source_load(spark, "2024-12-08", "bronze")
          ```

      -   **Valida√ß√£o de schemas:** PySpark

      4.  `simplify_schema(schema)`: Simplifica um esquema de DataFrame, tratando tipos compostos.
          ```python
          simplify_schema(schema: StructType or ArrayType or DataType) -> StructType or ArrayType or DataType
          ```
          **Par√¢metros:**
          * `schema` (StructType or ArrayType or DataType): O esquema a ser simplificado.
          **Retorno:**
          * (StructType or ArrayType or DataType): O esquema simplificado.
          ```python
          Exemplo: simplified_schema = simplify_schema(df.schema)
          ```

      5.  `compare_schemas(actual_schema, expected_schema)`: Compara dois esquemas de DataFrame, levando em conta tipos compostos.
          ```python
          compare_schemas(actual_schema: StructType, expected_schema: StructType) -> bool
          ```
          **Par√¢metros:**
          * `actual_schema` (StructType): O esquema real do DataFrame.
          * `expected_schema` (StructType): O esquema esperado do DataFrame.
          **Retorno:**
          * (bool): `True` se os esquemas forem iguais, `False` caso contr√°rio.
          ```python
          Exemplo: schemas_match = compare_schemas(df.schema, expected_schema)
          ```

      6.  `validate_schema(spark, df, source_name)`: Valida o esquema de um DataFrame comparando com o esquema esperado para uma fonte espec√≠fica.
          ```python
          validate_schema(spark: SparkSession, df: DataFrame, source_name: str) -> DataFrame
          ```
          **Par√¢metros:**
          * `spark` (SparkSession): A sess√£o Spark utilizada para criar o DataFrame de resultados.
          * `df` (DataFrame): O DataFrame a ser validado.
          * `source_name` (str): O nome da fonte de dados.
          **Retorno:**
          * (DataFrame): Um DataFrame contendo os resultados da valida√ß√£o do esquema.
          **Exce√ß√µes:**
          * Levanta uma exce√ß√£o `ValueError` se a fonte fornecida n√£o estiver no dicion√°rio de esquemas esperados ou se o esquema for inv√°lido.
          ```python
          Exemplo: schema_validation_result = validate_schema(spark, df, "google_play_bronze")
          ```

      -   **Valida√ß√£o Pattern:** PySpark

      7.  `validated_pattern_google_play(df)`: Valida o DataFrame com base na estrutura e padr√µes fornecidos para o Google Play.
          ```python
          validated_pattern_google_play(df: DataFrame) -> DataFrame
          ```
          **Par√¢metros:**
          * `df` (DataFrame): O DataFrame a ser validado.
          **Retorno:**
          * (DataFrame): O DataFrame com as colunas "validation" e "failed_Columns".
          ```python
          Exemplo: validated_df = validated_pattern_google_play(df)
          ```

      8.  `validated_pattern_apple_store(df)`: Valida o DataFrame com base na estrutura e padr√µes fornecidos para a Apple Store.
          ```python
          validated_pattern_apple_store(df: DataFrame) -> DataFrame
          ```
          **Par√¢metros:**
          * `df` (DataFrame): O DataFrame a ser validado.
          **Retorno:**
          * (DataFrame): O DataFrame com as colunas "validation" e "failed_columns".
          ```python
          Exemplo: validated_df = validated_pattern_apple_store(df)
          ```

      9.  `validated_pattern_mongodb(df)`: Valida o DataFrame com base na estrutura e padr√µes fornecidos para o MongoDB.
          ```python
          validated_pattern_mongodb(df: DataFrame) -> DataFrame
          ```
          **Par√¢metros:**
          * `df` (DataFrame): O DataFrame a ser validado.
          **Retorno:**
          * (DataFrame): O DataFrame com as colunas "validation" e "failed_columns".
          ```python
          Exemplo: validated_df = validated_pattern_mongodb(df)
          ```

      -   **Persist√™ncia de dados:** PySpark e MongoDB

      10. `save_reviews(reviews_df, directory)`: Salva os dados do DataFrame no formato Parquet no diret√≥rio especificado.
          ```python
          save_reviews(reviews_df: DataFrame, directory: str) -> None
          ```
          **Par√¢metros:**
          * `reviews_df` (DataFrame): DataFrame PySpark contendo as avalia√ß√µes.
          * `directory` (str): Caminho do diret√≥rio onde os dados ser√£o salvos.
          **Retorno:**
          * `None`
          ```python
          Exemplo: save_reviews(df, "/caminho/para/salvar")
          ```

      11. `save_dataframe(df, path, label)`: Salva o DataFrame em formato parquet e loga a opera√ß√£o.
          ```python
          save_dataframe(df: DataFrame, path: str, label: str) -> None
          ```
          **Par√¢metros:**
          * `df` (DataFrame): DataFrame a ser salvo.
          * `path` (str): Caminho do diret√≥rio onde os dados ser√£o salvos.
          * `label` (str): Label para o log.
          **Retorno:**
          * `None`
          ```python
          Exemplo: save_dataframe(df, "/caminho/para/salvar", "reviews")
          ```

      12. `write_to_mongo(dados_feedback, table_id, overwrite=False)`: Escreve dados em uma cole√ß√£o MongoDB, com a op√ß√£o de sobrescrever a cole√ß√£o.
          ```python
          write_to_mongo(dados_feedback: dict or list, table_id: str, overwrite: bool = False) -> None
          ```
          **Par√¢metros:**
          * `dados_feedback` (dict or list): Dados a serem inseridos na cole√ß√£o (um √∫nico dicion√°rio ou uma lista de dicion√°rios).
          * `table_id` (str): Nome da cole√ß√£o onde os dados ser√£o inseridos.
          * `overwrite` (bool): Se True, sobrescreve a cole√ß√£o, excluindo todos os documentos antes de inserir novos dados.
          **Retorno:**
          * `None`
          ```python
          Exemplo: write_to_mongo(metrics, "dt_datametrics_compass")
          ```

      13. `save_metrics(metrics_json)`: Salva as m√©tricas no MongoDB.
          ```python
          save_metrics(metrics_json: str) -> None
          ```
          **Par√¢metros:**
          * `metrics_json` (str): String JSON contendo as m√©tricas.
          **Retorno:**
          * `None`
          ```python
          Exemplo: save_metrics('{"metric": "value"}')
          ```

      14. `save_metrics_job_fail(metrics_json)`: Salva as m√©tricas de falha no MongoDB.
          ```python
          save_metrics_job_fail(metrics_json: str) -> None
          ```
          **Par√¢metros:**
          * `metrics_json` (str): String JSON contendo as m√©tricas de falha.
          **Retorno:**
          * `None`
          ```python
          Exemplo: save_metrics_job_fail('{"error": "message"}')
          ```

</details>

---

‚ô®Ô∏è **Aplica√ß√£o - Renten√ß√£o/expurgo de dados**


A aplica√ß√£o respons√°vel por realizar o expurgo dos dados √© uma aplica√ß√£o Spark que realiza a limpeza autom√°tica de parti√ß√µes antigas no HDFS com base em uma data limite configur√°vel. Ele identifica parti√ß√µes no formato odate=YYYYMMDD e remove aquelas fora do intervalo de dias desejado. Em caso de erro durante qualquer etapa (Spark, HDFS ou MongoDB), o script envia m√©tricas detalhadas de falha para uma base MongoDB, incluindo timestamp, contexto e mensagem do erro.


`üì¶ artefato` `iamgacarvalho/iamgacarvalho/dmc-expurge-partitions-hdfs` 
<details>
  <summary>Informa√ß√µes detalhada do artefato iamgacarvalho/iamgacarvalho/dmc-expurge-partitions-hdfs </summary> 

  - **Vers√£o:** `1.0.1`
  - **Fase do Projeto:** `V1`
  - **Reposit√≥rio:** [GitHub](https://github.com/gacarvalho/expurge-partitions-hdfs-compass)  
  - **Imagem Docker:** [Docker Hub](https://hub.docker.com/repository/docker/iamgacarvalho/dmc-expurge-partitions-hdfs/tags/1.0.0/sha256-e78cdb9d002ec2273ef464606b8b7e7d6d6a7dc4136a66868be703315201cac4)  

    ```shell
      /app/app-code-compass-expurge-partitions-hdfs.py $CONFIG_ENV $PARAM1 $PARAM2"
    ```
      - `$CONFIG_ENV` (`Pre`, `Pro`) ‚Üí Define o ambiente: `Pre` (Pr√©-Produ√ß√£o), `Pro` (Produ√ß√£o).
      - `$PARAM1` (`/santander/bronze/compass/reviews/appleStore/banco-santander-br/`, <br> `/santander/gold/compass/reviews/apps_santander_aggregate/`) ‚Üí Define o path que ter√° o expurgo dos dados. 
      - `$PARAM2` (`7`, `1825`) ‚Üí Define o n√∫mero de dias que manter√° os dados dentro do Data Lake.

  - **Pipeline:**
    - **Descri√ß√£o:** A aplica√ß√£o em Spark, foi desenvolvido com o prop√≥sito de realizar o expurgo automatizado de parti√ß√µes antigas armazenadas em um diret√≥rio HDFS. Sua fun√ß√£o √© identificar e remover parti√ß√µes que estejam fora de um intervalo de datas definido pelo usu√°rio, com o objetivo de liberar espa√ßo e manter a estrutura do HDFS organizada e eficiente. A aplica√ß√£o inicia criando uma sess√£o Spark configurada para suportar leitura de arquivos Parquet e a inclus√£o de depend√™ncias externas. Em seguida, ela valida os par√¢metros de entrada fornecidos via linha de comando, que incluem o ambiente de execu√ß√£o, o diret√≥rio base no HDFS e a quantidade de dias cujos dados devem ser preservados. Com essas informa√ß√µes, o script calcula a data limite com base na data atual e no n√∫mero de dias a manter, e utiliza comandos HDFS para listar todas as parti√ß√µes existentes dentro do diret√≥rio especificado. Cada parti√ß√£o √© avaliada de acordo com seu nome, que deve seguir o padr√£o odate=YYYYMMDD. Se a data extra√≠da estiver fora do intervalo permitido, a parti√ß√£o √© removida do HDFS por meio de um comando hdfs dfs -rm -r, sempre com tratamento de exce√ß√µes para garantir a estabilidade da execu√ß√£o. Al√©m disso, em caso de qualquer erro durante o processo ‚Äî seja na cria√ß√£o da sess√£o Spark, na leitura das parti√ß√µes ou na tentativa de remo√ß√£o ‚Äî, o script registra a falha em uma estrutura de m√©tricas com informa√ß√µes detalhadas, como timestamp, nome do job, grupo respons√°vel e mensagem do erro. Esses dados s√£o salvos em uma cole√ß√£o espec√≠fica dentro do MongoDB, cuja conex√£o √© configurada por vari√°veis de ambiente seguras, com usu√°rio, senha, host, porta e nome do banco. Ao final da execu√ß√£o, o HDFS permanece apenas com as parti√ß√µes desejadas, e qualquer falha ocorrida durante o processo √© devidamente registrada para rastreabilidade e monitoramento operacional.


    - **Fonte de Dados:** 
    Pode ser definido pelo par√¢metro `$PARM1`

      - `/santander/bronze/compass/reviews/appleStore/banco-santander-br/`
      - `/santander/bronze/compass/reviews/appleStore/santander-way/`
      - `/santander/bronze/compass/reviews/appleStore/santander-selectglobal/`
      - `/santander/bronze/compass/reviews/googlePlay/banco-santander-br/`
      - `/santander/bronze/compass/reviews/googlePlay/santander-way/`
      - `/santander/bronze/compass/reviews/googlePlay/santander-selectglobal/`
      - `/santander/bronze/compass/reviews/mongodb/banco-santander-br/`
      - `/santander/bronze/compass/reviews/mongodb/reviews-santander-way/`
      - `/santander/bronze/compass/reviews/mongodb/santander-selectGlobal/`
      - ` /santander/silver/compass/reviews/appleStore/`
      - `/santander/silver/compass/reviews/googlePlay/`
      - `/santander/silver/compass/reviews/mongodb/`
      - `/santander/gold/compass/reviews/apps_santander_aggregate/`


    - **Tipo de processo:** Batch (Semanal)

  - **Fluxo de Dados:**
    - **Extra√ß√£o:** Leitura de dados PF/PJ particionados por `odate` em Parquet
    - **Valida√ß√£o leitura da origem e carga:** PySpark

      1. `read_parquet_data(spark, path)`

      L√™ dados de um diret√≥rio Parquet e trata falhas de leitura.

      ```python
      read_parquet_data(spark: SparkSession, path: str) -> DataFrame
      ```

      **Par√¢metros:**

      - `spark` (SparkSession): Sess√£o Spark usada para processar os dados.
      - `path` (str): Caminho no HDFS para leitura do diret√≥rio particionado.

      **Retorno:**

      - (DataFrame): Retorna um DataFrame com os dados do diret√≥rio informado.

      **Exce√ß√µes:**

      - Lan√ßa uma `Exception` em caso de falha na leitura.

      ```python
      Exemplo: df = read_parquet_data(spark, "/santander/bronze/compass/reviews/appleStore/")
      ```

      2. `get_partition_folders(path)`

      Retorna a lista de parti√ß√µes v√°lidas dentro de um diret√≥rio do HDFS.

      ```python
      get_partition_folders(path: str) -> List[str]
      ```

      **Par√¢metros:**

      - `path` (str): Caminho base do diret√≥rio particionado.

      **Retorno:**

      - (List[str]): Lista de parti√ß√µes no formato `odate=YYYYMMDD`.

      **Exce√ß√µes:**

      - Retorna lista vazia se ocorrer erro ao listar parti√ß√µes.

      ```python
      Exemplo: partitions = get_partition_folders("/santander/bronze/compass/reviews/googlePlay/")
      ```

      3. `filter_old_partitions(partitions, days_to_keep)`

      Filtra parti√ß√µes com data anterior √† data limite.

      ```python
      filter_old_partitions(partitions: List[str], days_to_keep: int) -> List[str]
      ```

      **Par√¢metros:**

      - `partitions` (List[str]): Lista de parti√ß√µes no formato `odate=YYYYMMDD`.
      - `days_to_keep` (int): Quantidade de dias a serem mantidos.

      **Retorno:**

      - (List[str]): Lista de parti√ß√µes que devem ser expurgadas.

      ```python
      Exemplo: expired = filter_old_partitions(partitions, 7)
      ```

      4. `delete_partition(partition_path)`

      Deleta parti√ß√µes expiradas diretamente do HDFS.

      ```python
      delete_partition(partition_path: str) -> bool
      ```

      **Par√¢metros:**

      - `partition_path` (str): Caminho completo da parti√ß√£o a ser removida.

      **Retorno:**

      - (bool): Retorna `True` se a remo√ß√£o for bem-sucedida, `False` caso contr√°rio.

      **Exce√ß√µes:**

      - Erros s√£o capturados e logados, mas n√£o interrompem o processo.

      ```python
      Exemplo: delete_partition("/santander/bronze/compass/reviews/appleStore/odate=20230101")
      ```


      5. `log_error_to_mongo(data)`

      Persiste erro ocorrido durante o processo no MongoDB.

      ```python
      log_error_to_mongo(data: Dict[str, Any]) -> None
      ```

      **Par√¢metros:**

      - `data` (dict): Estrutura contendo o erro, nome do job, timestamp, grupo e outros metadados.

      **Retorno:**

      - None. O erro √© salvo na cole√ß√£o Mongo definida pelas vari√°veis de ambiente.

      ```python
      Exemplo:
      log_error_to_mongo({
          "timestamp": "2024-09-08T23:45:00",
          "job_name": "EXPURGE_BRONZE",
          "path": "/santander/bronze/compass/reviews/appleStore/",
          "message": "Erro ao ler Parquet",
          "status": "FAIL"
      })
      ```


      **Fluxo:**

      - L√™ argumentos (`env`, `path`, `days_to_keep`) via `sys.argv`.
      - Cria uma sess√£o Spark.
      - L√™ os dados do diret√≥rio informado.
      - Identifica parti√ß√µes a serem expurgadas.
      - Remove parti√ß√µes expiradas.
      - Em caso de erro, registra no MongoDB com metadados.


</details>

---
#### 3.2.2.3 **Malha do Projeto Compass**

A orquestra√ß√£o dos fluxos de ingest√£o, transforma√ß√£o e carga das informa√ß√µes √© realizada por meio do Apache Airflow, ferramenta escolhida pela sua flexibilidade, escalabilidade e capacidade de monitoramento de pipelines de dados. A malha desenvolvida no Airflow permite o agendamento e controle dos jobs Spark, garantindo a execu√ß√£o ordenada e confi√°vel das etapas do processo de dados dentro do Projeto Compass.

Cada DAG (Directed Acyclic Graph) representa um pipeline espec√≠fico de neg√≥cio, contendo tarefas interdependentes que asseguram o tratamento correto dos dados desde a origem at√© os destinos finais, como o Data Lake ou sistemas consumidores. Essa abordagem permite maior governan√ßa, rastreabilidade e facilidade de manuten√ß√£o da arquitetura de dados, al√©m de suportar a integra√ß√£o com outras ferramentas e sistemas do ecossistema Big Data.

| Nome da DAG                              | Descri√ß√£o                                                                                                                                          | JOBS                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |
|------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| `dag_d_pipeline_compass_reviews`         | Pipeline di√°ria respons√°vel por manter a malha principal do Projeto Compass, garantindo que a ingest√£o at√© a disponibiliza√ß√£o da carga final seja entregue ao cliente final. | `MONGO_INGESTION_SANTANDER-WAY`<br>`MONGO_INGESTION_BANCO-SANTANDER-BR`<br>`MONGO_INGESTION_SANTANDER-SELECT-GLOBAL`<br>`APPLE_INGESTION_SANTANDER-WAY`<br>`APPLE_INGESTION_BANCO-SANTANDER-BR`<br>`APPLE_INGESTION_SANTANDER-SELECT-GLOBAL`<br>`GOOGLE_INGESTION_BR.COM.SANTANDER.WAY`<br>`GOOGLE_INGESTION_COM.SANTANDER.APP`<br>`GOOGLE_INGESTION_COM.SANTANDER.SELECTGLOBAL`<br>`SILVER_APP_SILVER_APPLE_STORE`<br>`SILVER_APP_SILVER_GOOGLE_PLAY`<br>`SILVER_APP_SILVER_INTERNAL_BASE`<br>`GOLD_APP_GOLD_AGGREGATE_REVIEWS_SANTANDER`<br>`B_QUALITY_PIPELINE_APP_REVIEWS_SANTANDER`<br>`S_QUALITY_PIPELINE_APP_REVIEWS_SANTANDER` |
| `dag_s_pipeline_expurge_compass_reviews` | Pipeline semanal respons√°vel por realizar expurgo dos dados nas camadas Bronze, Silver e Gold.                                                      | `B_EXPURGE_APPLE_STORE_HDFS_HISTORY_BRONZE_APPLE_STORE_APP_SANTANDER_BR`<br>`B_EXPURGE_APPLE_STORE_HDFS_HISTORY_BRONZE_APPLE_STORE_APP_SANTANDER_WAY`<br>`B_EXPURGE_APPLE_STORE_HDFS_HISTORY_BRONZE_APPLE_STORE_APP_SANTANDER_SELECT_GLOBAL`<br>`B_EXPURGE_GOOGLE_PLAY_HDFS_HISTORY_BRONZE_GOOGLE_PLAY_APP_SANTANDER_BR`<br>`B_EXPURGE_GOOGLE_PLAY_HDFS_HISTORY_BRONZE_GOOGLE_PLAY_APP_SANTANDER_WAY`<br>`B_EXPURGE_GOOGLE_PLAY_HDFS_HISTORY_BRONZE_GOOGLE_PLAY_APP_SANTANDER_SELECT_GLOBAL`<br>`B_EXPURGE_MONGODB_HDFS_HISTORY_BRONZE_INTERNAL_BASE_APP_SANTANDER_BR`<br>`B_EXPURGE_MONGODB_HDFS_HISTORY_BRONZE_INTERNAL_BASE_APP_SANTANDER_WAY`<br>`B_EXPURGE_MONGODB_HDFS_HISTORY_BRONZE_INTERNAL_BASE_APP_SANTANDER_SELECT_GLOBAL`<br>`S_EXPURGE_APP_HDFS_HISTORY_SILVER_APPLE_STORE`<br>`S_EXPURGE_APP_HDFS_HISTORY_SILVER_GOOGLE_PLAY`<br>`S_EXPURGE_APP_HDFS_HISTORY_SILVER_INTERNAL_BASE`<br>`G_EXPURGE_APP_HDFS_HISTORY_GOLD_AGGREGATE` |


## 4. Fluxo Funcional e Jornada do Cliente

A solu√ß√£o foi projetada para atender ao time de neg√≥cios do Santander, proporcionando uma vis√£o estrat√©gica das principais dores dos clientes e da concorr√™ncia. Ela permite an√°lises em diferentes n√≠veis de granularidade, desde indicadores agregados, como a distribui√ß√£o das avalia√ß√µes e notas (de 0 a 5) por segmento e canal, at√© um n√≠vel mais detalhado, possibilitando o acompanhamento do hist√≥rico de avalia√ß√µes de clientes espec√≠ficos dentro de um determinado segmento. 


![<fluxo-funcional>](https://github.com/gacarvalho/compass-deployment/blob/compass/infra-3.0.0/img/fluxo%20de%20negocios.jpg?raw=true)


Como princ√≠pio fundamental da estrutura de Experi√™ncia do Usu√°rio, foi levantada a quest√£o sobre qual √© o fluxo atualmente utilizado para coletar, analisar e aplicar melhorias com base nas dores dos clientes. Abaixo, detalhamos esse processo:

> Atualmente, monitoramos alguns indicadores por meio de um dashboard para identificar as principais dores dos clientes. A partir desses dados, realizamos um diagn√≥stico que nos permite entender se o caso se trata de um incidente (INC) ou de um ponto de fric√ß√£o na jornada do cliente. Com base nessa an√°lise, encaminhamos as informa√ß√µes para o time de produto, classificando-as como incidentes ou oportunidades de melhoria.

No entanto, ao aprofundarmos a an√°lise do fluxo atual, identificamos que essas avalia√ß√µes s√£o realizadas `exclusivamente com dados internos`, desconsiderando feedbacks externos, como os coment√°rios e avalia√ß√µes deixados por clientes em plataformas como a Apple Store e o Google Play.

Com os dados de extra√ß√£o pelo Projeto Compass, ser√° poss√≠vel unificar e enriquecer as principais dores dos clientes com dados externos ‚Äî como avalia√ß√µes, coment√°rios e feedbacks coletados em plataformas p√∫blicas, como Apple Store, Google Play, Reclame Aqui, entre outras.

Essa integra√ß√£o permitir√° uma vis√£o mais hol√≠stica da experi√™ncia do usu√°rio, combinando dados internos (transacionais, comportamentais e operacionais) com insumos externos, possibilitando:

  - Identifica√ß√£o mais precisa de pontos de fric√ß√£o ao longo da jornada do cliente;
  - Prioriza√ß√£o de melhorias com base na percep√ß√£o real dos usu√°rios;
  - Antecipa√ß√£o de problemas recorrentes, mesmo antes de serem reportados via canais formais;
  - Alinhamento estrat√©gico com o time de Produto, garantindo que evolu√ß√µes sejam orientadas por dados e focadas em gerar valor;
  - Monitoramento cont√≠nuo da reputa√ß√£o da marca nas plataformas externas, refor√ßando a governan√ßa da experi√™ncia do cliente.

Com isso, o Projeto Compass se posiciona como uma iniciativa estrat√©gica, permitindo que a companhia avance para uma atua√ß√£o proativa, centrada no cliente e orientada por dados.

## 5. Compass como produto analytics Santander

---

O projeto Compass como Produto tem como objetivo fornecer uma solu√ß√£o robusta e escal√°vel para o Santander, utilizando Engenharia de Dados para desenvolver um fluxo que permita identificar as principais necessidades e desafios dos seus clientes. Esse fluxo busca n√£o apenas atender as demandas internas do banco, mas tamb√©m possui o potencial de expandir sua abrang√™ncia, permitindo escalar a busca para entender as "dores" dos concorrentes do Santander no mercado.


### 5.1 Regras de Neg√≥cio

Como premissa central do Projeto Compass, o objetivo √© consolidar uma base estruturada com as principais dores dos clientes em rela√ß√£o aos produtos do Santander. Essa base permitir√° a gera√ß√£o de insights valiosos e a an√°lise de oportunidades de melhoria nos diferentes canais de atendimento e relacionamento, contribuindo diretamente para o aumento da principalidade do cliente com a institui√ß√£o.

A seguir, est√£o descritas em formato de tabela as principais regras de neg√≥cio e crit√©rios de aceite que orientam a execu√ß√£o do Projeto Compass.

> [!NOTE]
> A maior parte das regras funcionais implementadas neste pipeline dizem respeito √† estrutura final dos dados e aos filtros aplicados para garantir integridade m√≠nima. 
> Como estamos lidando com dados semi-estruturados (coment√°rios, avalia√ß√µes, etc.), n√£o h√° muitas outras regras funcionais a serem aplicadas. 
> O tratamento √© limitado pela aus√™ncia de um esquema r√≠gido, o que impede a cria√ß√£o de regras mais espec√≠ficas como joins complexos, valida√ß√µes por dom√≠nio ou integridade referencial.


---
<details>
  <summary> üè∑Ô∏è Regras de Neg√≥cios - Apple Store </summary>

  | **ID**    | **Fonte de Origem** | **Vers√£o do Projeto** | **Regra de Neg√≥cio**                                               | **Descri√ß√£o**                                                                                                                                                             | **Objetivo**                                                                                     | **√öltima Atualiza√ß√£o** |
  |----------|----------------------|------------------------|---------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------|-------------------------|
  | **RN001** | Google Play          | v1                     | Uso de dados hist√≥ricos (`historical_data`)                         | Utiliza a fun√ß√£o `historical_data` para obter a parti√ß√£o anterior e realizar atualiza√ß√£o incremental.                                                                     | Evitar reprocessamento completo e permitir atualiza√ß√£o incremental.                             | 2025-04-06              |
  | **RN002** | Apple Store          | v1                     | Remo√ß√£o de acentos e padroniza√ß√£o de texto                          | Os textos dos campos `author_name`, `title` e `content` devem ser convertidos para letras mai√∫sculas e ter acentos removidos.                                              | Uniformizar dados textuais para an√°lises e buscas.                                               | 2025-04-06              |
  | **RN003** | Apple Store          | v1                     | Gera√ß√£o de m√©tricas de erro                                         | Em caso de falha no processamento, uma m√©trica detalhada contendo o erro e informa√ß√µes do cliente ser√° salva no Elasticsearch.                                            | Permitir rastreabilidade e visibilidade de falhas.                                               | 2025-04-06              |
  | **RN004** | Apple Store          | v1                     | Padroniza√ß√£o de schema antes da escrita                             | Antes da persist√™ncia, os dados devem ser reestruturados conforme o schema definido para a camada silver (`apple_store_schema_silver`).                                  | Garantir consist√™ncia da estrutura dos dados armazenados.                                        | 2025-04-06              |
  | **RN005** | Apple Store          | v1                     | Extra√ß√£o de metadados a partir do nome do arquivo                   | Os campos `app` e `segmento` devem ser extra√≠dos a partir do caminho do arquivo no HDFS com express√µes regulares.                                                          | Enriquecer os dados com metadados √∫teis sem depender de colunas expl√≠citas.                     | 2025-04-06              |
  | **RN006** | Apple Store          | v1                     | Valida√ß√£o da exist√™ncia de parti√ß√µes no HDFS                        | A execu√ß√£o s√≥ continuar√° se houver parti√ß√µes no formato `odate=*` no caminho hist√≥rico `/santander/silver/compass/reviews/appleStore/`.                                  | Evitar falhas por aus√™ncia de dados e otimizar a execu√ß√£o.                                       | 2025-04-06              |
  | **RN007** | Apple Store          | v1                     | Salvamento de m√©tricas da aplica√ß√£o                                 | M√©tricas de execu√ß√£o bem-sucedida devem ser enviadas ao √≠ndice `compass_dt_datametrics` no Elasticsearch, usando autentica√ß√£o b√°sica.                                     | Garantir observabilidade da execu√ß√£o e indicadores de sucesso.                                  | 2025-04-06              |
  | **RN008** | Apple Store          | v1                     | Verifica√ß√£o de duplicidade de registros                             | Verifica se h√° duplicidade de registros com base na coluna `id`. Caso existam, retorna erro de conflito e bloqueia a execu√ß√£o.                                             | Evitar dados duplicados e garantir unicidade dos registros.                                     | 2025-04-06              |
  | **RN009** | Apple Store          | v1                     | Valida√ß√£o de campos nulos em colunas obrigat√≥rias                   | Valida se colunas essenciais como `id`, `content`, `im_rating`, `im_version` est√£o preenchidas. Caso contr√°rio, gera erro e encerra o processo.                           | Garantir integridade dos dados antes da persist√™ncia.                                            | 2025-04-06              |
  | **RN010** | Apple Store          | v1                     | Consist√™ncia de tipo para campos num√©ricos                          | Garante que os valores na coluna `im_rating` sejam num√©ricos v√°lidos (por exemplo, inteiros ou floats). Registros inv√°lidos s√£o descartados ou tratados conforme regra. | Evitar erros de tipo e assegurar qualidade para an√°lise quantitativa.                           | 2025-04-06              |

</details>

<details>
  <summary> üè∑Ô∏è Regras de Neg√≥cios - Google Play </summary>

  | **ID** | Fonte de Origem| Vers√£o do Projeto | Regra de Neg√≥cio                             | Descri√ß√£o                                                                                                                                              | **Objetivo**                                                                 | √öltima Atualiza√ß√£o                    |
  |--------|----------------|-------------------|------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------|-----------------------------------|
  | **RN001**  | Google Play    | v1                | Uso de dados hist√≥ricos (`historical_data`)    | Utiliza a fun√ß√£o `historical_data` para obter a parti√ß√£o anterior e realizar atualiza√ß√£o incremental.                                                      | Evitar reprocessamento completo e permitir atualiza√ß√£o incremental.         | 2025-04-06      |
  | **RN002**  | Google Play    | v1                |Filtragem por dados v√°lidos (`validate_ingest`) | Aplica regras de valida√ß√£o de schema, campos obrigat√≥rios, tipos de dados e padr√µes esperados.                                                             | Separar dados v√°lidos e inv√°lidos para rastreabilidade.                     | 2025-04-06        |
  | **RN003**  | Google Play    | v1                |Normaliza√ß√£o de texto (`unidecode`)             | Remove acentua√ß√£o e converte para caixa alta nos campos `title` e `snippet`.                                                                               | Uniformizar texto para an√°lise textual.                                     | 2025-04-06          |
  | **RN004**  | Google Play    | v1                |Identifica√ß√£o de segmenta√ß√£o (PF/PJ)            | Classifica os dados de entrada como pessoa f√≠sica ou jur√≠dica com base no caminho do arquivo.                                                              | Enriquecer o dado com a informa√ß√£o de segmento.                             | 2025-04-06                     |
  | **RN005**  | Google Play    | v1                |Extra√ß√£o do nome do app                         | A partir do caminho do arquivo (`input_file_name`), extrai dinamicamente o nome do aplicativo.                                                             | Associar corretamente o review ao seu aplicativo.                           | 2025-04-06                      |
  | **RN006**  | Google Play    | v1                |Cria√ß√£o de colunas t√©cnicas                     | Adiciona colunas como `job_datetime` e `partition_column` para rastreabilidade da execu√ß√£o e particionamento por data.                                    | Permitir auditoria e facilitar consultas particionadas.                      | 2025-04-06      |
  | **RN007**  | Google Play    | v1                |Particionamento por data (`partition_column`)   | Os dados s√£o particionados por data da execu√ß√£o extra√≠da do nome do arquivo (`odate`).                                                                     | Melhorar performance de leitura e escrita no lake.                          | 2025-04-06             |
  | **RN008**  | Google Play    | v1                |Rejei√ß√£o de dados inconsistentes                | Dados com inconsist√™ncias, como tipos errados ou campos vazios obrigat√≥rios, s√£o separados e salvos no caminho de *falhas*.                                | Garantir integridade da camada Silver.                                      | 2025-04-06                   |
  | **RN009**  | Google Play    | v1                |Envio de m√©tricas para observabilidade          | Em caso de erro, envia um documento JSON para Elasticsearch com os detalhes do job.                                                                        | Monitorar falhas em tempo real.                                             | 2025-04-06   |
</details>

<details>
  <summary> üè∑Ô∏è Regras de Neg√≥cios - Base Interna | MongoDB </summary>

  | ID       | Fonte de Origem | Vers√£o do Projeto | Regra de Neg√≥cio Funcional                    | Descri√ß√£o                                                                                                                        | Objetivo                                                                                      | √öltima Atualiza√ß√£o |
  |----------|------------------|--------------------|-----------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------|---------------------|
  | **RN001**   | MongoDB          | v1                 | Filtro por colunas obrigat√≥rias               | Remove registros que n√£o possuem `id`, `rating`, `snippet` ou `date`.                                                           | Garantir integridade m√≠nima dos dados antes do enriquecimento.                              | 2025-04-06          |
  | **RN002**   | MongoDB          | v1                 | Tratamento de acentos                         | Aplica fun√ß√£o para remover acentos do campo `comment`.                                                                          | Padronizar texto para facilitar an√°lise textual.                                              | 2025-04-06          |
  | **RN003**   | MongoDB          | v1                 | Convers√£o para caixa alta                     | Converte os coment√°rios (`comment`) para letras mai√∫sculas.                                                                     | Evitar distin√ß√µes entre palavras com mesmas letras em diferentes casos.                     | 2025-04-06          |
  | **RN004**   | MongoDB          | v1                 | Adi√ß√£o da coluna `app`                        | Extrai o nome do app a partir do nome do arquivo/parquet lido.                                                                  | Enriquecer os dados com a aplica√ß√£o de origem.                                                | 2025-04-06          |
  | **RN005**   | MongoDB          | v1                 | Adi√ß√£o da coluna `segmento`                   | Extrai o segmento (`pf` ou `pj`) do nome do arquivo/parquet lido.                                                               | Permitir segmenta√ß√£o dos dados por tipo de cliente.                                           | 2025-04-06          |
  | **RN006**   | MongoDB          | v1                 | Cria√ß√£o da coluna `historical_data`           | Compara os dados atuais com dados anteriores e adiciona campo indicando altera√ß√µes.                                             | Rastrear modifica√ß√µes nos coment√°rios ou avalia√ß√µes ao longo do tempo.                      | 2025-04-06          |
  | **RN007**   | MongoDB          | v1                 | Remo√ß√£o de colunas desnecess√°rias             | Remove campos como `avatar`, `iso_date`, entre outros ap√≥s transforma√ß√£o.                                                       | Reduzir tamanho do dataset e manter apenas colunas relevantes.                               | 2025-04-06          |
  | **RN008**   | MongoDB          | v1                 | Padroniza√ß√£o do schema final (`Silver`)       | Aplica `withColumn` e `select` para garantir colunas fixas: `id`, `title`, `rating`, `comment`, `likes`, `date`, `app`, etc.   | Garantir compatibilidade com camadas posteriores e contratos de dados.                       | 2025-04-06          |
  | **RN009**   | MongoDB          | v1                 | Cria√ß√£o da coluna `dt_partition`              | Adiciona uma parti√ß√£o de data (`dt_partition`) baseada na data de execu√ß√£o.                                                     | Otimizar queries futuras e organiza√ß√£o no HDFS.                                               | 2025-04-06          |
  | **RN010**   | MongoDB          | v1                 | Convers√£o de tipos                            | Campos como `likes` e `rating` s√£o convertidos explicitamente para `IntegerType` e `FloatType`.                                | Evitar erros de tipo e garantir consist√™ncia na leitura e escrita.                          | 2025-04-06          |
  | **RN011**   | MongoDB          | v1                 | Unifica√ß√£o dos dados `pf` e `pj`              | Dados s√£o lidos separadamente por segmento e unidos em um √∫nico DataFrame.                                                      | Obter um dataset consolidado para uso anal√≠tico.                                              | 2025-04-06          |

</details>


---

### 5.2 Dicion√°rio de Dados

Este dicion√°rio de dados tem como objetivo documentar e padronizar a estrutura dos dados utilizados ao longo das esteiras de ingest√£o, transforma√ß√£o e disponibiliza√ß√£o. Ele serve como uma refer√™ncia clara e objetiva para desenvolvedores, analistas e squads que atuam com os dados descritos.

A estrutura apresentada foi definida para garantir consist√™ncia, rastreabilidade e governan√ßa dos dados, al√©m de facilitar o entendimento t√©cnico-funcional sobre a origem e o destino de cada informa√ß√£o.

Cada tabela est√° organizada com os seguintes campos:

| Campo              | Descri√ß√£o |
|--------------------|-----------|
| **DIRETORIO**       | Caminho onde os dados s√£o armazenados no Data Lake. |
| **PARTICIONAMENTO** | Padr√£o de particionamento utilizado, visando performance de leitura e organiza√ß√£o dos dados. |
| **CAMPO**           | Nome da coluna. |
| **TYPE**            | Tipo de dado (string, int, double, etc.). |
| **PATTERN**         | Express√£o ou formato esperado (ex: regex, padr√£o ISO, etc.). |
| **OBRIGATORIO**     | Indica se o campo √© obrigat√≥rio ou n√£o. |
| **EXEMPLO**         | Um valor de exemplo para facilitar a interpreta√ß√£o. |
| **DESCRI√á√ÉO**       | Explica√ß√£o clara e funcional da regra de neg√≥cio atrelada ao campo. |


> [!NOTE]
> A maior parte das regras funcionais est√° associada √† estrutura final do dado e aos filtros aplicados durante a transforma√ß√£o. Por se tratar de dados **semiestruturados ou n√£o estruturados**, n√£o √© poss√≠vel aplicar todas as valida√ß√µes convencionais com rigidez. Assim, o foco deste dicion√°rio est√° em garantir a vis√£o **mais pr√≥xima poss√≠vel do modelo de sa√≠da**, com √™nfase na **estrutura de schema**, padr√µes m√≠nimos esperados e crit√©rios funcionais j√° implementados.

Este documento ser√° atualizado continuamente conforme novas regras forem implementadas ou alteradas nos pipelines. Ele deve ser utilizado como **refer√™ncia oficial** para an√°lises e desenvolvimento do projeto Compass.

---

<details>
<summary><strong>üé≤ Mostrar dicion√°rio de dados:</strong> Apple Store {application ingestion}  </summary>

<br>

| DIRETORIO                                                                 | PARTICIONAMENTO | ORIGEM      | CAMPO                    | TYPE      | PATTERN                                           | OBRIGATORIO | EXEMPLO                                       | DESCRI√á√ÉO                                              | LOCALIZA√á√ÉO DAG/JOB                           |
|---------------------------------------------------------------------------|------------------|-------------|---------------------------|-----------|---------------------------------------------------|--------------|-----------------------------------------------|---------------------------------------------------------|------------------------------------------------|
| /santander/bronze/compass/reviews/appleStore/banco-santander-br_pf/      | odate=yyyyMMdd   | Apple Store | author_name              | string    | ^.+$                                              | S            | Flavia Lemes                                  | Campo do nome da avalia√ß√£o.                             | group_jobs_apple ‚Üí APPLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/appleStore/banco-santander-br_pf/      | odate=yyyyMMdd   | Apple Store | author_uri               | string    | .*                                                | S            | https://itunes.apple.com/br/reviews/id12083758426 | Campo da URI do autor da avalia√ß√£o.                    | group_jobs_apple ‚Üí APPLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/appleStore/banco-santander-br_pf/      | odate=yyyyMMdd   | Apple Store | content                  | string    | .*                                                | S            | app n√£o cair notifica√ß√£o                       | Campo com o conte√∫do da avalia√ß√£o.                      | group_jobs_apple ‚Üí APPLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/appleStore/banco-santander-br_pf/      | odate=yyyyMMdd   | Apple Store | content_attributes_label | string    | .*                                                | S            | Aplicativo                                     | Categoria atribu√≠da ao conte√∫do da avalia√ß√£o.          | group_jobs_apple ‚Üí APPLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/appleStore/banco-santander-br_pf/      | odate=yyyyMMdd   | Apple Store | content_attributes_term  | string    | .*                                                | S            | Application                                    | Termo relacionado ao conte√∫do da avalia√ß√£o.            | group_jobs_apple ‚Üí APPLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/appleStore/banco-santander-br_pf/      | odate=yyyyMMdd   | Apple Store | id                       | string    | ^\d+$                                             | S            | 12118476144                                   | Identificador √∫nico da avalia√ß√£o.                      | group_jobs_apple ‚Üí APPLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/appleStore/banco-santander-br_pf/      | odate=yyyyMMdd   | Apple Store | im_rating                | integer   | ^[1-5]$                                           | S            | 1                                              | Nota da avalia√ß√£o (1 a 5).                              | group_jobs_apple ‚Üí APPLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/appleStore/banco-santander-br_pf/      | odate=yyyyMMdd   | Apple Store | im_version               | string    | .*                                                | S            | 24.10.2                                       | Vers√£o do aplicativo avaliado.                         | group_jobs_apple ‚Üí APPLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/appleStore/banco-santander-br_pf/      | odate=yyyyMMdd   | Apple Store | im_votecount             | integer   | ^\d+$                                             | S            | 0                                              | Quantidade de votos recebidos.                         | group_jobs_apple ‚Üí APPLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/appleStore/banco-santander-br_pf/      | odate=yyyyMMdd   | Apple Store | im_votesum               | integer   | ^\d+$                                             | S            | 0                                              | Soma total dos votos recebidos.                        | group_jobs_apple ‚Üí APPLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/appleStore/banco-santander-br_pf/      | odate=yyyyMMdd   | Apple Store | link_attributes_href     | string    | .*                                                | S            | https://itunes.apple.com/br/reviews/id12083758426 | URL do link da avalia√ß√£o.                              | group_jobs_apple ‚Üí APPLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/appleStore/banco-santander-br_pf/      | odate=yyyyMMdd   | Apple Store | link_attributes_related  | string    | .*                                                | S            | related                                       | Tipo de relacionamento do link.                        | group_jobs_apple ‚Üí APPLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/appleStore/banco-santander-br_pf/      | odate=yyyyMMdd   | Apple Store | title                    | string    | .*                                                | S            | App Santander                                 | T√≠tulo da avalia√ß√£o.                                   | group_jobs_apple ‚Üí APPLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/appleStore/banco-santander-br_pf/      | odate=yyyyMMdd   | Apple Store | updated                  | timestamp | ^\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}.*$           | S            | 2024-12-30T02:59:00+00:00                    | Data e hora da √∫ltima atualiza√ß√£o da avalia√ß√£o.        | group_jobs_apple ‚Üí APPLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/appleStore/banco-santander-br_pf/      | odate=yyyyMMdd   | Apple Store | odate                    | string    | ^\d{8}$                                           | S            | 20250307                                     | Data de extra√ß√£o no formato yyyyMMdd.                  | group_jobs_apple ‚Üí APPLE_INGESTION_BANCO-SANTANDER-BR |


</details>


<details>
<summary><strong>üé≤ Mostrar dicion√°rio de dados:</strong> Google Play {application ingestion}  </summary>

<br>

| DIRETORIO                                                               | PARTICIONAMENTO | ORIGEM      | CAMPO       | TYPE    | PATTERN                                           | OBRIGATORIO | EXEMPLO                                       | DESCRI√á√ÉO                                              | LOCALIZA√á√ÉO DAG/JOB                           |
|------------------------------------------------------------------------|------------------|-------------|-------------|---------|---------------------------------------------------|--------------|-----------------------------------------------|---------------------------------------------------------|------------------------------------------------|
| /santander/bronze/compass/reviews/googlePlay/banco-santander-br_pf/    | odate=yyyyMMdd   | Google Play | avatar      | string  | ^https:\/\/.*$                                    | N            | https://play-lh.googleusercontent.com/...     | URL da imagem de perfil do autor da avalia√ß√£o.         | group_jobs_google ‚Üí GOOGLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/googlePlay/banco-santander-br_pf/    | odate=yyyyMMdd   | Google Play | date        | string  | ^[A-Za-z]+ \d{2}, \d{4}$                          | S            | March 10, 2019                                 | Data textual da avalia√ß√£o (formato Play Store).         | group_jobs_google ‚Üí GOOGLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/googlePlay/banco-santander-br_pf/    | odate=yyyyMMdd   | Google Play | id          | string  | ^[a-f0-9\-]{36}$                                  | S            | ca9a8eca-ee30-43c2-aaaa-bb10a7b0c774           | Identificador √∫nico da avalia√ß√£o.                       | group_jobs_google ‚Üí GOOGLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/googlePlay/banco-santander-br_pf/    | odate=yyyyMMdd   | Google Play | iso_date    | string  | ^\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}Z$            | S            | 2019-03-10T10:00:02Z                           | Data da avalia√ß√£o em formato ISO 8601.                  | group_jobs_google ‚Üí GOOGLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/googlePlay/banco-santander-br_pf/    | odate=yyyyMMdd   | Google Play | likes       | long    | ^\d+$                                             | N            | 85                                            | Quantidade de curtidas na avalia√ß√£o.                    | group_jobs_google ‚Üí GOOGLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/googlePlay/banco-santander-br_pf/    | odate=yyyyMMdd   | Google Play | rating      | double  | ^[1-5](\.0)?$                                     | S            | 1.0                                           | Nota atribu√≠da √† avalia√ß√£o (de 1.0 a 5.0).               | group_jobs_google ‚Üí GOOGLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/googlePlay/banco-santander-br_pf/    | odate=yyyyMMdd   | Google Play | response    | map     | {date -> .*?, text -> .*?}                        | N            | {date -> March 12, 2019, text -> Obrigado!}    | Resposta do app √† avalia√ß√£o, contendo data e texto.     | group_jobs_google ‚Üí GOOGLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/googlePlay/banco-santander-br_pf/    | odate=yyyyMMdd   | Google Play | snippet     | string  | ^.+$                                              | S            | Aplicativo super inst√°vel                      | Texto da avalia√ß√£o feita pelo usu√°rio.                  | group_jobs_google ‚Üí GOOGLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/googlePlay/banco-santander-br_pf/    | odate=yyyyMMdd   | Google Play | title       | string  | ^.*$                                              | S            | Um usu√°rio do Google                           | Nome do autor da avalia√ß√£o (ou pseud√¥nimo do sistema).  | group_jobs_google ‚Üí GOOGLE_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/googlePlay/banco-santander-br_pf/    | odate=yyyyMMdd   | Google Play | odate       | integer | ^\d{8}$                                           | S            | 20250307                                      | Data da coleta da avalia√ß√£o no formato yyyyMMdd.         | group_jobs_google ‚Üí GOOGLE_INGESTION_BANCO-SANTANDER-BR |


</details>


<details>
<summary><strong>üé≤ Mostrar dicion√°rio de dados:</strong> MongoDB, internal database {application ingestion}  </summary>

<br>

| DIRETORIO                                                                 | PARTICIONAMENTO | ORIGEM   | CAMPO         | TYPE    | PATTERN                                           | OBRIGATORIO | EXEMPLO            | DESCRI√á√ÉO                                         | LOCALIZA√á√ÉO DAG/JOB                            |
|---------------------------------------------------------------------------|------------------|----------|----------------|---------|---------------------------------------------------|--------------|---------------------|----------------------------------------------------|-------------------------------------------------|
| /santander/bronze/compass/reviews/mongodb/banco-santander-br_pf/         | odate=yyyyMMdd   | MongoDB  | id             | string  | ^[a-zA-Z0-9]+$                                    | S            | 67c693b10f4ffb0e6...| Identificador √∫nico da avalia√ß√£o.                | group_jobs_mongo ‚Üí MONGO_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/mongodb/banco-santander-br_pf/         | odate=yyyyMMdd   | MongoDB  | comment        | string  | ^.+$                                              | S            | FALTAM INFORMA√á√ïES | Texto da avalia√ß√£o.                              | group_jobs_mongo ‚Üí MONGO_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/mongodb/banco-santander-br_pf/         | odate=yyyyMMdd   | MongoDB  | votes_count    | int     | ^\d+$                                             | N            | 6                   | Quantidade de votos na avalia√ß√£o.                | group_jobs_mongo ‚Üí MONGO_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/mongodb/banco-santander-br_pf/         | odate=yyyyMMdd   | MongoDB  | os             | string  | ^.+$                                              | N            | IOS                 | Sistema operacional do usu√°rio.                  | group_jobs_mongo ‚Üí MONGO_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/mongodb/banco-santander-br_pf/         | odate=yyyyMMdd   | MongoDB  | os_version     | string  | ^[\d\.]+$                                         | N            | 18.04               | Vers√£o do sistema operacional.                   | group_jobs_mongo ‚Üí MONGO_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/mongodb/banco-santander-br_pf/         | odate=yyyyMMdd   | MongoDB  | country        | string  | ^[A-Z]{2}$                                        | N            | BR                  | Pa√≠s do usu√°rio.                                 | group_jobs_mongo ‚Üí MONGO_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/mongodb/banco-santander-br_pf/         | odate=yyyyMMdd   | MongoDB  | age            | int     | ^\d+$                                             | N            | 68                  | Idade do usu√°rio.                                | group_jobs_mongo ‚Üí MONGO_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/mongodb/banco-santander-br_pf/         | odate=yyyyMMdd   | MongoDB  | customer_id    | string  | ^\d+$                                             | S            | 6461                | ID do cliente no sistema.                        | group_jobs_mongo ‚Üí MONGO_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/mongodb/banco-santander-br_pf/         | odate=yyyyMMdd   | MongoDB  | cpf            | string  | ^\d{3}\.\d{3}\.\d{3}-\d{2}$                       | S            | 129.048.657-30      | CPF do cliente.                                  | group_jobs_mongo ‚Üí MONGO_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/mongodb/banco-santander-br_pf/         | odate=yyyyMMdd   | MongoDB  | app_version    | string  | ^\d+\.\d+\.\d+$                                   | N            | 1.0.0               | Vers√£o do aplicativo.                            | group_jobs_mongo ‚Üí MONGO_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/mongodb/banco-santander-br_pf/         | odate=yyyyMMdd   | MongoDB  | rating         | int     | ^[1-5]$                                           | S            | 4                   | Nota atribu√≠da pelo usu√°rio.                     | group_jobs_mongo ‚Üí MONGO_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/mongodb/banco-santander-br_pf/         | odate=yyyyMMdd   | MongoDB  | timestamp      | string  | ^\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}.*$           | S            | 2025-03-04T05:45:...| Data e hora da avalia√ß√£o.                        | group_jobs_mongo ‚Üí MONGO_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/mongodb/banco-santander-br_pf/         | odate=yyyyMMdd   | MongoDB  | app            | string  | ^.+$                                              | S            | banco-santander-br  | Nome do aplicativo.                              | group_jobs_mongo ‚Üí MONGO_INGESTION_BANCO-SANTANDER-BR |
| /santander/bronze/compass/reviews/mongodb/banco-santander-br_pf/         | odate=yyyyMMdd   | MongoDB  | odate          | int     | ^\d{8}$                                           | S            | 20250308            | Data da parti√ß√£o no formato yyyyMMdd.            | group_jobs_mongo ‚Üí MONGO_INGESTION_BANCO-SANTANDER-BR |


</details>

---

<details>
<summary><strong>üé≤ Mostrar dicion√°rio de dados:</strong> Apple Store {application Silver}  </summary>

<br>

| DIRET√ìRIO                                         | PARTICIONAMENTO | ORIGEM      | CAMPO                      | TYPE               | PATTERN                                                | OBRIGAT√ìRIO | EXEMPLO                                                                                                                           | DESCRI√á√ÉO                                                           | LOCALIZA√á√ÉO                             |
|--------------------------------------------------|------------------|-------------|----------------------------|--------------------|--------------------------------------------------------|-------------|------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------|------------------------------------------|
| /santander/silver/compass/reviews/appleStore/    | odate=yyyyMMdd   | Apple Store | id                         | string             | ^\d{8,}$                                               | S           | 10660374634                                                                                                                      | Identificador √∫nico do review                                              | group_jobs_mongo ‚Üí SILVER_APP_SILVER_APPLE_STORE |
| /santander/silver/compass/reviews/appleStore/    | odate=yyyyMMdd   | Apple Store | name_client                | string             | ^[A-Z0-9 ]{2,}$                                        | S           | GABRIELALVESJ                                                                                                                    | Nome do cliente (em caixa alta)                                           | group_jobs_mongo ‚Üí SILVER_APP_SILVER_APPLE_STORE |
| /santander/silver/compass/reviews/appleStore/    | odate=yyyyMMdd   | Apple Store | app                        | string             | ^[a-z0-9\-_.]+$                                        | S           | santander-select-global_pf                                                                                                       | Nome do aplicativo                                                        | group_jobs_mongo ‚Üí SILVER_APP_SILVER_APPLE_STORE |
| /santander/silver/compass/reviews/appleStore/    | odate=yyyyMMdd   | Apple Store | im_version                 | string             | ^\d{2}\.\d{2}(\.\d+)?$                                 | S           | 23.12.2                                                                                                                           | Vers√£o do aplicativo                                                      | group_jobs_mongo ‚Üí SILVER_APP_SILVER_APPLE_STORE |
| /santander/silver/compass/reviews/appleStore/    | odate=yyyyMMdd   | Apple Store | im_rating                  | string             | ^[1-5]$                                                | S           | 5                                                                                                                                | Avalia√ß√£o num√©rica do usu√°rio (1 a 5)                                     | group_jobs_mongo ‚Üí SILVER_APP_SILVER_APPLE_STORE |
| /santander/silver/compass/reviews/appleStore/    | odate=yyyyMMdd   | Apple Store | title                      | string             | ^.{1,100}$                                             | S           | RECONHECIMENTO FACIAL NAO FUNCIONA                                                                                               | T√≠tulo do review                                                          | group_jobs_mongo ‚Üí SILVER_APP_SILVER_APPLE_STORE |
| /santander/silver/compass/reviews/appleStore/    | odate=yyyyMMdd   | Apple Store | content                    | string             | ^.{1,1000}$                                            | S           | TENHO BIOMETRIA FACIAL CADASTRADA NO APP...                                                                                      | Conte√∫do completo do review                                               | group_jobs_mongo ‚Üí SILVER_APP_SILVER_APPLE_STORE |
| /santander/silver/compass/reviews/appleStore/    | odate=yyyyMMdd   | Apple Store | updated                    | string             | ^\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}-\d{2}:\d{2}$       | S           | 2023-12-12T20:35:52-07:00                                                                                                         | Data e hora da √∫ltima atualiza√ß√£o (formato ISO 8601)                     | group_jobs_mongo ‚Üí SILVER_APP_SILVER_APPLE_STORE |
| /santander/silver/compass/reviews/appleStore/    | odate=yyyyMMdd   | Apple Store | segmento                   | string             | ^(pf|pj)$                                              | S           | pf                                                                                                                               | Segmento do cliente (pf = pessoa f√≠sica, pj = pessoa jur√≠dica)          | group_jobs_mongo ‚Üí SILVER_APP_SILVER_APPLE_STORE |
| /santander/silver/compass/reviews/appleStore/    | odate=yyyyMMdd   | Apple Store | historical_data.title      | array.struct.string| -                                                      | N           | []                                                                                                                               | Hist√≥rico de t√≠tulos de reviews anteriores                                | group_jobs_mongo ‚Üí SILVER_APP_SILVER_APPLE_STORE |
| /santander/silver/compass/reviews/appleStore/    | odate=yyyyMMdd   | Apple Store | historical_data.content    | array.struct.string| -                                                      | N           | []                                                                                                                               | Hist√≥rico de conte√∫dos de reviews anteriores                             | group_jobs_mongo ‚Üí SILVER_APP_SILVER_APPLE_STORE |
| /santander/silver/compass/reviews/appleStore/    | odate=yyyyMMdd   | Apple Store | historical_data.app        | array.struct.string| -                                                      | N           | []                                                                                                                               | Hist√≥rico de nomes de aplicativos                                          | group_jobs_mongo ‚Üí SILVER_APP_SILVER_APPLE_STORE |
| /santander/silver/compass/reviews/appleStore/    | odate=yyyyMMdd   | Apple Store | historical_data.segmento   | array.struct.string| -                                                      | N           | []                                                                                                                               | Hist√≥rico de segmentos                                                    | group_jobs_mongo ‚Üí SILVER_APP_SILVER_APPLE_STORE |
| /santander/silver/compass/reviews/appleStore/    | odate=yyyyMMdd   | Apple Store | historical_data.im_version | array.struct.string| -                                                      | N           | []                                                                                                                               | Hist√≥rico de vers√µes do aplicativo                                        | group_jobs_mongo ‚Üí SILVER_APP_SILVER_APPLE_STORE |
| /santander/silver/compass/reviews/appleStore/    | odate=yyyyMMdd   | Apple Store | historical_data.im_rating  | array.struct.string| -                                                      | N           | []                                                                                                                               | Hist√≥rico de avalia√ß√µes num√©ricas                                          | group_jobs_mongo ‚Üí SILVER_APP_SILVER_APPLE_STORE |
| /santander/silver/compass/reviews/appleStore/    | odate=yyyyMMdd   | Apple Store | odate                      | integer            | ^\d{8}$                                                | S           | 20250409                                                                                                                         | Data de particionamento da carga (formato yyyymmdd)                      | group_jobs_mongo ‚Üí SILVER_APP_SILVER_APPLE_STORE |


</details>

<details>
<summary><strong>üé≤ Mostrar dicion√°rio de dados:</strong> Google Play {application Silver}  </summary>

<br>

  | DIRET√ìRIO                                                | PARTICIONAMENTO | ORIGEM      | CAMPO                        | TYPE                  | PATTERN                             | OBRIGAT√ìRIO | EXEMPLO                                                                                                                                                                                                                                   | DESCRI√á√ÉO                                                                                                           | LOCALIZA√á√ÉO                                |
  |-----------------------------------------------------------|------------------|-------------|------------------------------|------------------------|--------------------------------------|--------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------|---------------------------------------------|
  | /santander/silver/compass/reviews/googlePlay/             | odate=yyyyMMdd   | Google Play | id                           | string                 | [0-9a-f\-]{36}                       | S            | 0027bfd3-465b-4dec-a7d2-d8467f4751dc                                                                                                                                                                                                     | Identificador √∫nico da avalia√ß√£o                                                                                   | group_jobs_mongo ‚Üí SILVER_APP_SILVER_GOOGLE_PLAY |
  | /santander/silver/compass/reviews/googlePlay/             | odate=yyyyMMdd   | Google Play | app                          | string                 | [a-z0-9\-_]+                         | S            | santander-way_pf                                                                                                                                                                                                                          | Identificador √∫nico do aplicativo                                                                                  | group_jobs_mongo ‚Üí SILVER_APP_SILVER_GOOGLE_PLAY |
  | /santander/silver/compass/reviews/googlePlay/             | odate=yyyyMMdd   | Google Play | segmento                     | string                 | pf|pj                                | S            | pf                                                                                                                                                                                                                                        | Segmento do cliente                                                                                                 | group_jobs_mongo ‚Üí SILVER_APP_SILVER_GOOGLE_PLAY |
  | /santander/silver/compass/reviews/googlePlay/             | odate=yyyyMMdd   |  Google Play | rating                       | string                 | [1-5]                                | S            | 5                                                                                                                                                                                                                                         | Avalia√ß√£o atribu√≠da ao app                                                                                          | group_jobs_mongo ‚Üí SILVER_APP_SILVER_GOOGLE_PLAY |
  | /santander/silver/compass/reviews/googlePlay/             | odate=yyyyMMdd   | Google Play | iso_date                     | string                 | \d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}Z | S            | 2025-02-27T19:18:26Z                                                                                                                                                                                                                      | Data e hora no formato ISO 8601                                                                                      | group_jobs_mongo ‚Üí SILVER_APP_SILVER_GOOGLE_PLAY |
  | /santander/silver/compass/reviews/googlePlay/             | odate=yyyyMMdd   | Google Play | title                        | string                 | .+                                   | S            | GABRIEL CAVALCANTE                                                                                                                                                                                                                         | Nome do usu√°rio que avaliou                                                                                          | group_jobs_mongo ‚Üí SILVER_APP_SILVER_GOOGLE_PLAY |
  | /santander/silver/compass/reviews/googlePlay/             | odate=yyyyMMdd   | Google PLay | snippet                      | string                 | .+                                   | S            | USEI O APP POR MAIS DE DOIS ANOS...                                                                                                                                                                                                       | Texto da avalia√ß√£o fornecida pelo usu√°rio                                                                            | group_jobs_mongo ‚Üí SILVER_APP_SILVER_GOOGLE_PLAY |
  | /santander/silver/compass/reviews/googlePlay/             | odate=yyyyMMdd   | Google Play | historical_data.title        | array.struct.string    | \[.*\]                               | N            | []                                                                                                                                                                                                                                        | Lista de t√≠tulos hist√≥ricos da avalia√ß√£o                                                                             | group_jobs_mongo ‚Üí SILVER_APP_SILVER_GOOGLE_PLAY |
  | /santander/silver/compass/reviews/googlePlay/             | odate=yyyyMMdd   | Google Play | historical_data.snippet      | array.struct.string    | \[.*\]                               | N            | []                                                                                                                                                                                                                                        | Lista de trechos hist√≥ricos da avalia√ß√£o                                                                             | group_jobs_mongo ‚Üí SILVER_APP_SILVER_GOOGLE_PLAY |
  | /santander/silver/compass/reviews/googlePlay/             | odate=yyyyMMdd   | Google Play | historical_data.app          | array.struct.string    | \[.*\]                               | N            | []                                                                                                                                                                                                                                        | Lista de identificadores hist√≥ricos de apps                                                                           | group_jobs_mongo ‚Üí SILVER_APP_SILVER_GOOGLE_PLAY |
  | /santander/silver/compass/reviews/googlePlay/             | odate=yyyyMMdd   | Google Play | historical_data.segmento     | array.struct.string    | \[.*\]                               | N            | []                                                                                                                                                                                                                                        | Lista de segmentos hist√≥ricos                                                                                        | group_jobs_mongo ‚Üí SILVER_APP_SILVER_GOOGLE_PLAY |
  | /santander/silver/compass/reviews/googlePlay/             | odate=yyyyMMdd   | Google Play | historical_data.rating       | array.struct.string    | \[.*\]                               | N            | []                                                                                                                                                                                                                                        | Lista de ratings hist√≥ricos                                                                                          | group_jobs_mongo ‚Üí SILVER_APP_SILVER_GOOGLE_PLAY |
  | /santander/silver/compass/reviews/googlePlay/             | odate=yyyyMMdd   | Google Play | historical_data.iso_date     | array.struct.string    | \[.*\]                               | N            | []                                                                                                                                                                                                                                        | Lista de datas hist√≥ricas no formato ISO 8601                                                                         | group_jobs_mongo ‚Üí SILVER_APP_SILVER_GOOGLE_PLAY |
  | /santander/silver/compass/reviews/googlePlay/             | odate=yyyyMMdd   | Google Play | odate                        | integer               | \d{8}                              | S            | 20250409                                                                                                                                                                                                                                  | Data de parti√ß√£o no formato yyyyMMdd                                                                                 | group_jobs_mongo ‚Üí SILVER_APP_SILVER_GOOGLE_PLAY |

</details>



</details>

<details>
<summary><strong>üé≤ Mostrar dicion√°rio de dados:</strong> Mongo DB (internal Database) {application Silver}  </summary>

<br>

| DIRET√ìRIO                                              | PARTICIONAMENTO   | ORIGEM                    | CAMPO                        | TYPE                 | PATTERN                  | OBRIGAT√ìRIO | EXEMPLO                                                  | DESCRI√á√ÉO                                                                                         | LOCALIZA√á√ÉO                                        |
|--------------------------------------------------------|--------------------|----------------------------|------------------------------|----------------------|---------------------------|-------------|----------------------------------------------------------|---------------------------------------------------------------------------------------------------|---------------------------------------------------|
| /santander/silver/compass/reviews/mongodb/            | odate=yyyyMMdd     | Mongo DB (internal database) | id                           | string               | [a-f0-9]{24}              | S           | 67c69308ca13ea1488ad2812                                 | Identificador √∫nico do registro no MongoDB                                                      | group_jobs_mongo ‚Üí SILVER_APP_SILVER_INTERNAL_BASE |
| /santander/silver/compass/reviews/mongodb/            | odate=yyyyMMdd     | Mongo DB (internal database) | customer_id                  | string               | \d+                       | S           | 5436                                                     | Identificador do cliente                                                                         | group_jobs_mongo ‚Üí SILVER_APP_SILVER_INTERNAL_BASE |
| /santander/silver/compass/reviews/mongodb/            | odate=yyyyMMdd     | Mongo DB (internal database) | cpf                          | string               | \d{3}\.\d{3}\.\d{3}-\d{2} | S           | 471.962.380-87                                           | CPF do cliente                                                                                   | group_jobs_mongo ‚Üí SILVER_APP_SILVER_INTERNAL_BASE |
| /santander/silver/compass/reviews/mongodb/            | odate=yyyyMMdd     | Mongo DB (internal database) | app                          | string               | [a-z\-_.]+                | S           | santander-way_pf                                         | Nome do aplicativo                                                                               | group_jobs_mongo ‚Üí SILVER_APP_SILVER_INTERNAL_BASE |
| /santander/silver/compass/reviews/mongodb/            | odate=yyyyMMdd     | Mongo DB (internal database) | segmento                     | string               | pf|pj                     | pf,            | pf                                                       | Segmento do cliente                                                                              | group_jobs_mongo ‚Üí SILVER_APP_SILVER_INTERNAL_BASE |
| /santander/silver/compass/reviews/mongodb/            | odate=yyyyMMdd     | Mongo DB (internal database) | rating                       | string               | [1-5]                     | S           | 1                                                        | Avalia√ß√£o do aplicativo pelo cliente (1 a 5)                                                    | group_jobs_mongo ‚Üí SILVER_APP_SILVER_INTERNAL_BASE |
| /santander/silver/compass/reviews/mongodb/            | odate=yyyyMMdd     | Mongo DB (internal database) | timestamp                    | string               | \d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2} | S     | 2025-03-04T05:42:06                                    | Data e hora do coment√°rio                                                                       | group_jobs_mongo ‚Üí SILVER_APP_SILVER_INTERNAL_BASE |
| /santander/silver/compass/reviews/mongodb/            | odate=yyyyMMdd     | Mongo DB (internal database) | comment                      | string               | .*                       | S           | EXCELENTE, MAS A INTERFACE...                             | Coment√°rio textual do cliente sobre o app                                                       | group_jobs_mongo ‚Üí SILVER_APP_SILVER_INTERNAL_BASE |
| /santander/silver/compass/reviews/mongodb/            | odate=yyyyMMdd     | Mongo DB (internal database) | app_version                  | string               | \d+\.\d+\.\d+             | S           | 1.0.0                                                    | Vers√£o do aplicativo                                                                             | group_jobs_mongo ‚Üí SILVER_APP_SILVER_INTERNAL_BASE |
| /santander/silver/compass/reviews/mongodb/            | odate=yyyyMMdd     | Mongo DB (internal database) | os_version                   | string               | \d+(\.\d+)*               | S           | 10.0                                                     | Vers√£o do sistema operacional                                                                   | group_jobs_mongo ‚Üí SILVER_APP_SILVER_INTERNAL_BASE |
| /santander/silver/compass/reviews/mongodb/            | odate=yyyyMMdd     | Mongo DB (internal database) | os                           | string               | Android|IOS              | S           | IOS                                                      | Sistema operacional do dispositivo                                                             | group_jobs_mongo ‚Üí SILVER_APP_SILVER_INTERNAL_BASE |
| /santander/silver/compass/reviews/mongodb/            | odate=yyyyMMdd     | Mongo DB (internal database) | historical_data.customer_id  | array.struct.string  | \[.*\]                   | N           | []                                                       | Hist√≥rico de customer_id relacionados                                                           | group_jobs_mongo ‚Üí SILVER_APP_SILVER_INTERNAL_BASE |
| /santander/silver/compass/reviews/mongodb/            | odate=yyyyMMdd     | Mongo DB (internal database) | historical_data.cpf          | array.struct.string  | \[.*\]                   | N           | []                                                       | Hist√≥rico de CPFs relacionados                                                                 | group_jobs_mongo ‚Üí SILVER_APP_SILVER_INTERNAL_BASE |
| /santander/silver/compass/reviews/mongodb/            | odate=yyyyMMdd     | Mongo DB (internal database) | historical_data.app          | array.struct.string  | \[.*\]                   | N           | []                                                       | Hist√≥rico de apps utilizados                                                                   | group_jobs_mongo ‚Üí SILVER_APP_SILVER_INTERNAL_BASE |
| /santander/silver/compass/reviews/mongodb/            | odate=yyyyMMdd     | Mongo DB (internal database) | historical_data.comment      | array.struct.string  | \[.*\]                   | N           | []                                                       | Hist√≥rico de coment√°rios feitos                                                                | group_jobs_mongo ‚Üí SILVER_APP_SILVER_INTERNAL_BASE |
| /santander/silver/compass/reviews/mongodb/            | odate=yyyyMMdd     | Mongo DB (internal database) | historical_data.segmento     | array.struct.string  | \[.*\]                   | N           | []                                                       | Hist√≥rico de segmentos associados                                                              | group_jobs_mongo ‚Üí SILVER_APP_SILVER_INTERNAL_BASE |
| /santander/silver/compass/reviews/mongodb/            | odate=yyyyMMdd     | Mongo DB (internal database) | historical_data.rating       | array.struct.string  | \[.*\]                   | N           | []                                                       | Hist√≥rico de avalia√ß√µes feitas                                                                 | group_jobs_mongo ‚Üí SILVER_APP_SILVER_INTERNAL_BASE |
| /santander/silver/compass/reviews/mongodb/            | odate=yyyyMMdd     | Mongo DB (internal database) | historical_data.timestamp    | array.struct.string  | \[.*\]                   | N           | []                                                       | Hist√≥rico de timestamps de reviews                                                             | group_jobs_mongo ‚Üí SILVER_APP_SILVER_INTERNAL_BASE |
| /santander/silver/compass/reviews/mongodb/            | odate=yyyyMMdd     | Mongo DB (internal database) | historical_data.app_version  | array.struct.string  | \[.*\]                   | N           | []                                                       | Hist√≥rico de vers√µes do aplicativo                                                             | group_jobs_mongo ‚Üí SILVER_APP_SILVER_INTERNAL_BASE |
| /santander/silver/compass/reviews/mongodb/            | odate=yyyyMMdd     | Mongo DB (internal database) | historical_data.os_version   | array.struct.string  | \[.*\]                   | N           | []                                                       | Hist√≥rico de vers√µes do sistema operacional                                                    | group_jobs_mongo ‚Üí SILVER_APP_SILVER_INTERNAL_BASE |
| /santander/silver/compass/reviews/mongodb/            | odate=yyyyMMdd     | Mongo DB (internal database) | odate                        | integer              | \d{8}                    | S           | 20250409                                                 | Data de refer√™ncia da parti√ß√£o (formato yyyyMMdd)                                               | group_jobs_mongo ‚Üí SILVER_APP_SILVER_INTERNAL_BASE |

</details>

---

<details>
<summary><strong>üé≤ Mostrar dicion√°rio de dados:</strong> Dados Agregados {application Gold}  </summary>

<br>

| DIRET√ìRIO                                                        | PARTICIONAMENTO | ORIGEM                                                                 | CAMPO                  | TYPE    | PATTERN          | OBRIGAT√ìRIO | EXEMPLO                 | DESCRI√á√ÉO                                                                                  | LOCALIZA√á√ÉO                                       |
|------------------------------------------------------------------|------------------|------------------------------------------------------------------------|------------------------|---------|------------------|-------------|--------------------------|---------------------------------------------------------------------------------------------|--------------------------------------------------|
| /santander/gold/compass/reviews/apps_santander_aggregate         | odate=yyyyMMdd   | /santander/silver/compass/reviews/googlePlay, mongodb, appleStore     | app_nome               | string  | .*               | S           | BANCO-SANTANDER-BR       | Nome do aplicativo analisado                                                                | group_jobs_mongo ‚Üí GOLD_APP_GOLD_AGGREGATE_REVIEWS_SANTANDER |
| /santander/gold/compass/reviews/apps_santander_aggregate         | odate=yyyyMMdd   | /santander/silver/compass/reviews/googlePlay, mongodb, appleStore     | app_source             | string  | GOOGLE_PLAY,MONGODB,APPLE_STORE | S           | GOOGLE_PLAY              | Fonte da avalia√ß√£o: loja de apps onde a review foi feita                                   | group_jobs_mongo ‚Üí GOLD_APP_GOLD_AGGREGATE_REVIEWS_SANTANDER |
| /santander/gold/compass/reviews/apps_santander_aggregate         | odate=yyyyMMdd   | /santander/silver/compass/reviews/googlePlay, mongodb, appleStore     | periodo_referencia     | string  | \d{4}-\d{2}      | S           | 2025-02                  | Per√≠odo de refer√™ncia da avalia√ß√£o (formato YYYY-MM)                                       | group_jobs_mongo ‚Üí GOLD_APP_GOLD_AGGREGATE_REVIEWS_SANTANDER |
| /santander/gold/compass/reviews/apps_santander_aggregate         | odate=yyyyMMdd   | /santander/silver/compass/reviews/googlePlay, mongodb, appleStore     | segmento               | string  | PF|PJ             | S           | PF                       | Segmento de clientes (PF = Pessoa F√≠sica, PJ = Pessoa Jur√≠dica)                            | group_jobs_mongo ‚Üí GOLD_APP_GOLD_AGGREGATE_REVIEWS_SANTANDER |
| /santander/gold/compass/reviews/apps_santander_aggregate         | odate=yyyyMMdd   | /santander/silver/compass/reviews/googlePlay, mongodb, appleStore     | nota_media             | double  | \d+(\.\d+)?       | S           | 2.2                      | Nota m√©dia das avalia√ß√µes dos usu√°rios                                                     | group_jobs_mongo ‚Üí GOLD_APP_GOLD_AGGREGATE_REVIEWS_SANTANDER |
| /santander/gold/compass/reviews/apps_santander_aggregate         | odate=yyyyMMdd   | /santander/silver/compass/reviews/googlePlay, mongodb, appleStore     | avaliacoes_total       | long    | \d+              | S           | 449                      | Quantidade total de avalia√ß√µes recebidas                                                   | group_jobs_mongo ‚Üí GOLD_APP_GOLD_AGGREGATE_REVIEWS_SANTANDER |
| /santander/gold/compass/reviews/apps_santander_aggregate         | odate=yyyyMMdd   | /santander/silver/compass/reviews/googlePlay, mongodb, appleStore     | comentarios_positivos  | long    | \d+              | S           | 38                        | Quantidade de coment√°rios positivos          | group_jobs_mongo ‚Üí GOLD_APP_GOLD_AGGREGATE_REVIEWS_SANTANDER |
| /santander/gold/compass/reviews/apps_santander_aggregate         | odate=yyyyMMdd   | /santander/silver/compass/reviews/googlePlay, mongodb, appleStore     | comentarios_negativos  | long    | \d+              | S           | 27                       | Quantidade de coment√°rios negativos                                                        | group_jobs_mongo ‚Üí GOLD_APP_GOLD_AGGREGATE_REVIEWS_SANTANDER |

</details>

---


### 5.3 Produtos Compass



üß≠ Dashboard Funcional - Ger√™ncia

![<metabase-metricas-funcionais>](https://github.com/gacarvalho/compass-deployment/blob/compass/infra-3.0.0/img/metabase-metricas-funcionais.gif?raw=true)

üß≠ Dashboard T√©cnico - Aplica√ß√µes e Dashboard T√©cnico - Sustenta√ß√£o  

<p align="center">
  <img src="https://github.com/gacarvalho/compass-deployment/blob/compass/infra-3.0.0/img/grafana_apps.png?raw=true" width="49%">
  <img src="https://github.com/gacarvalho/compass-deployment/blob/compass/infra-3.0.0/img/grafana_sustentacao.png?raw=true" width="49%">
</p>


## 6. Instru√ß√µes para Configura√ß√£o e Execu√ß√£o do Projeto Compass

## 7. Melhorias do projeto e Considera√ß√µes Finais





---


